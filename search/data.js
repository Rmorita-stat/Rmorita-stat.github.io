

var data = [
  {
    url: "https://sucre-stat.com/stat/",
    title: "Stats",
    date: "2021-12-19T00:00:00Z",
    body: "Stats"
  },
  {
    url: "https://sucre-stat.com/tags/",
    title: "Tags",
    date: "2021-12-19T00:00:00Z",
    body: "Tags"
  },
  {
    url: "https://sucre-stat.com/tags/%E3%83%99%E3%82%A4%E3%82%BA%E3%83%95%E3%82%A1%E3%82%AF%E3%82%BF%E3%83%BC/",
    title: "ベイズファクター",
    date: "2021-12-19T00:00:00Z",
    body: "ベイズファクター"
  },
  {
    url: "https://sucre-stat.com/2021/12/bayesian-hypothesis-testing-4theory/",
    title: "ベイズファクターを用いた仮説検定～相関の検定～",
    date: "2021-12-19T00:00:00Z",
    body: "ベイズファクターを用いた仮説検定～相関の検定～ 今回は、ベイズファクターを使った相関の検定について理論を整理します。 ベイズファクターとはなんぞや？という方はこちらを参照のこと。 参考文献は\rこちら\rです。 相関係数について おさらい 確率変数$X$、$Y$はそれぞれ平均$\\mu_X$、$\\mu_Y$、標準偏差$\\sigma_X$、$\\sigma_Y$をパラメータにもつ確率分布に従うとします。 このとき、確率変数$X$、$Y$の相関係数$\\rho$は下記のとおり定義されます。 $$ \\rho = \\cfrac{\\mathrm{Cov}\\left( XY \\right)}{\\sqrt{\\mathrm{Var}\\left(X\\right)}\\sqrt{\\mathrm{Var}\\left(Y\\right)}} = \\cfrac{\\mathrm{E}\\left(XY\\right) - \\mu_X \\mu_Y}{\\sigma_X \\sigma_Y} \\tag{1} $$ $(1)$式より、相関係数$\\rho$は$X$、$Y$に対する線形変換の影響を受けないことが確認できます。 この性質により、平均値の差の検定や線形回帰のときとは異なり、モデル設計において$\\rho$を他の平均・分散・共分散等のパラメータから独立させるための再パラメータ化の必要が無いことが、今回のトピックのひとつの特徴です。 相関を考慮した2変量発生過程のモデル化 では、相関を考慮して2変数の発生過程をモデル化します。 ◆相関を考慮した2変量発生過程モデル\r確率変数$\\boldsymbol{X}^n = \\left( X_1, \\ldots, X_n \\right)$、$\\boldsymbol{Y}^n = \\left( Y_1, \\ldots, Y_n \\right)$について、$X_i$、$Y_i$$(i = 1,2,\\ldots,n)$の同時確率分布が独立同分布の2変量正規分布であると仮定する。 $$ p\\left( \\boldsymbol{X}^n, \\boldsymbol{Y}^n\\right) = \\prod_{i=1}^{n} \\mathrm{Normal}\\left( X_i,Y_i | \\mathrm{\\boldsymbol{\\mu},\\boldsymbol{\\Sigma}}\\right) \\tag{2} $$ ここで、$\\boldsymbol{\\mu} = \\left( \\mu_X, \\mu_Y \\right)^T $、$\\boldsymbol{\\Sigma} = \\left( \\begin{array}{ccc} \\sigma_X^2 \u0026amp; \\rho\\sigma_X\\sigma_Y \\\\ \\rho\\sigma_X\\sigma_Y \u0026amp; \\sigma_Y^2 \\end{array} \\right)$である。 ここでは参考文献どおりに2変数の正規性を仮定したモデルのみを取り上げますが、ガンマ分布等他の分布でも同様に相関係数を組み込んだ2変量化で対応できそうですネ。誰かやってみてください。 事前分布 周辺尤度、ベイズファクターはモデルの事前分布の影響を強く受けるので、例によって理想的な性質をもつ事前分布の取り方を紹介します。 ◆Jeffreysの理論に則った相関パラメータの事前分布\rJeffreysの理論に従い、相関パラメータ$\\rho$の事前分布$\\pi(\\rho)$を、伸長した対称ベータ分布(stretched symmetric beta function)とする。 $$ \\pi(\\rho | \\kappa) = \\cfrac{2^{\\cfrac{\\kappa - 2}{\\kappa}}}{\\mathrm{B}\\left(\\cfrac{1}{\\kappa},\\cfrac{1}{\\kappa}\\right)}\\left( 1 - \\rho ^ 2\\right)^\\cfrac{1-\\kappa}{\\kappa} \\tag{3} $$ 伸長した対称ベータ分布の導出\r（第1種）ベータ分布の確率密度は下記である。\r$$\rf(x | \\alpha, \\beta) = \\cfrac{x^{\\alpha - 1}\\left(1 - x\\right)^{\\beta - 1}}{\\mathrm{B}\\left(\\alpha, \\beta\\right)}\r$$\rベータ分布に従う確率変数$X$について考える。\r$X$の$k$次の積率$\\mu_{X,k}^{'}$は、\r$$\r\\begin{split}\r\\mu_{X,k}^{'} \u0026= \\mathbb{E}[X^k] \\\\\\\\\r\u0026= \\int _{0}^{1} \\cfrac{x^{\\alpha - 1}\\left( 1 - x \\right)^{\\beta-1}}{\\mathrm{B}\\left(\\alpha, \\beta\\right)} x^k dx \\\\\\\\\r\u0026= \\int _{0}^{1} \\cfrac{x^{\\alpha + k - 1}\\left( 1 - x \\right)^{\\beta-1}}{\\mathrm{B}\\left(\\alpha, \\beta\\right)} dx \\\\\\\\\r\u0026= \\int _{0}^{1} \\cfrac{x^{\\alpha^{'} - 1}\\left( 1 - x \\right)^{\\beta-1}}{\\mathrm{B}\\left(\\alpha^{'}-k, \\beta\\right)} dx　~~~ (\\alpha + k - 1 = \\alpha^{'} - 1 と置換) \\\\\\\\\r\u0026= \\cfrac{\\prod_{i=1}^{k}\\left(\\alpha^{'} - i\\right)}{\\prod_{i=1}^{k}\\left(\\alpha^{'} + \\beta - i\\right)} \\int _{0}^{1} \\cfrac{x^{\\alpha^{'} - 1}\\left( 1 - x \\right)^{\\beta-1}}{\\mathrm{B}\\left(\\alpha^{'}, \\beta\\right)} dx \\\\\\\\\r\u0026= \\cfrac{\\prod_{i=1}^{k}\\left(\\alpha + k - i\\right)}{\\prod_{i=1}^{k}\\left(\\alpha + \\beta + k - i\\right)} (\\alpha^{'} = \\alpha + k と置換しなおす)\r\\end{split}\r$$\rmemo\r\r定理$\\mathrm{B}\\left( \\alpha+1, \\beta \\right) = \\cfrac{\\alpha}{\\alpha + \\beta}\\mathrm{B}\\left(\\alpha, \\beta\\right)$より、\r$$\r\\mathrm{B}\\left( \\alpha^{'}-k, \\beta \\right) = \\cfrac{\\prod_{i=1}^{k}\\left(\\alpha^{'} + \\beta - i\\right)}{\\prod_{i=1}^{k}\\left(\\alpha^{'} - i\\right)} \\mathrm{B}\\left( \\alpha^{'},\\beta \\right)\r$$\r\rよって、$X$の平均$\\mu_X$、分散$\\sigma_X$はそれぞれ\r$$\r\\mu_X = \\mu_{X,1}^{'} = \\mathbb{E}[X] = \\cfrac{\\alpha}{\\alpha + \\beta}\r$$\r$$\r\\sigma_X = \\mu_{X,2} = \\mathbb{E}[\\left( X - \\mu_X\\right)^2] = \\mu_{X,2}^{'} - \\mu_X^2 = \\cfrac{\\alpha\\beta}{\\left(\\alpha + \\beta\\right)^2\\left(\\alpha + \\beta + 1\\right)}\r$$\rだから、ベータ分布の歪度$\\gamma_{X,1}$は、\r$$\r\\begin{split}\r\\gamma_{X,1} \u0026= \\alpha_{X,3} = \\mathbb{E} \\left[ \\left(\\cfrac{X - \\mu_X}{\\sigma_X}\\right)^3 \\right] \\\\\\\\\r\u0026= \\cfrac{\\mu_{X,3}^{'} - 3\\mu_X \\mu_{X,2}^{'} + 2\\mu_X^3}{\\sigma_X^3} \\\\\\\\\r\u0026= \\cfrac{\\left(\\alpha + \\beta\\right)^2\\left(\\alpha + \\beta + 1\\right)}{\\alpha\\beta} \\left( \\cfrac{\\alpha(\\alpha+2)(\\alpha+1)}{(\\alpha+\\beta+2)(\\alpha+\\beta+1)(\\alpha+\\beta)} -3\\cfrac{\\alpha}{\\alpha+\\beta}\\cfrac{\\alpha(\\alpha+1)}{(\\alpha+\\beta+1)(\\alpha+\\beta)} + 2\\cfrac{\\alpha^2}{(\\alpha+\\beta)^2} \\right) \\\\\\\\\r\u0026= \\cfrac{\\left(\\alpha + \\beta\\right)\\left(\\alpha + \\beta + 1\\right)}{\\beta} \\left( \\cfrac{(\\alpha+2)(\\alpha+1)}{(\\alpha+\\beta+2)(\\alpha+\\beta+1)}-3\\cfrac{\\alpha(\\alpha+1)}{(\\alpha+\\beta+1)(\\alpha+\\beta)} + 2\\cfrac{\\alpha}{\\alpha+\\beta} \\right)\r\\end{split}\r$$\rまた$\\alpha = \\beta = \\cfrac{1}{\\kappa}$の対称ベータ分布を台$[-1,1]$に変換しなおした拡張分布への変換には、下記定理を用いる。\r確率変数の変換公式\r確率密度$f_{X}$の確率変数$X$に一対一の写像$\\phi$で$X = \\phi(Y)$と対応付けされる確率変数$Y$の確率密度$g_{Y}$は、 $$ g_{Y}(y) = f_{X}(\\phi(y),\\ldots,\\phi_n(y_1,\\ldots,y_n)) || J_{\\phi} || $$ ここで、$|| J_{\\phi} ||$はヤコビアンであり $$ || J_{\\phi} || = \\cfrac{dy}{dx} $$ である。 いま、$\\phi : X = \\cfrac{Y + 1}{2}$とすると\r$$\r|| J_{\\phi} || = \\cfrac{dy}{dx} = \\cfrac{1}{2}\r$$\rだから、\r$$\rg_{Y}(y) = \\cfrac{x^{\\alpha - 1}\\left(1 - x\\right)^{\\beta - 1}}{\\mathrm{B}\\left(\\alpha, \\beta\\right)}\r$$\r\r その他のパラメータ$\\mu_X$、$\\mu_Y$、$\\sigma_X$、$\\sigma_Y$は比較するモデルに共通して存在するパラメータなので、それらの事前分布の設定が$\\rho$に対する周辺尤度の値にほとんど影響しませんが、平均値の差の検定のときと同様に、Jeffreysの事前分布を設定します。 ◆平均パラメータ、分散パラメータの事前分布\r平均パラメータ$\\mu_X$、$\\mu_Y$、分散パラメータ$\\sigma_X^2$、$\\sigma_Y^2$の事前分布$\\pi(\\mu_X)$、$\\pi(\\mu_Y)$、$\\pi(\\sigma_X^2)$、$\\pi(\\sigma_Y^2)$はJeffreysの事前分布を適用する。 $$ \\pi(\\mu_X) \\propto 1 \\tag{4} $$ $$ \\pi(\\mu_Y) \\propto 1 \\tag{5} $$ $$ \\pi(\\sigma_X^2) \\propto \\cfrac{1}{\\sigma_X^2} \\tag{6} $$ $$ \\pi(\\sigma_Y^2) \\propto \\cfrac{1}{\\sigma_Y^2} \\tag{7} $$ まとめ 本記事では以下の内容について整理しました。 相関係数のおさらいと性質の確認 相関係数を考慮した2変量のモデル化 相関パラメータの事前分布は拡張対称ベータ分布 実践編はこちらです。ベイズファクターを実際に算出し、モデルをどのように評価できるのか見ていきます。 さらにこちらの記事ではベイズファクターを推定するための手法を複数実践しているので、読んでみてください。"
  },
  {
    url: "https://sucre-stat.com/r/",
    title: "Rs",
    date: "2021-10-23T00:00:00Z",
    body: "Rs"
  },
  {
    url: "https://sucre-stat.com/tags/stan/",
    title: "Stan",
    date: "2021-10-23T00:00:00Z",
    body: "Stan"
  },
  {
    url: "https://sucre-stat.com/2021/10/regressionbf-comparing/",
    title: "線形回帰モデルのベイズファクター計算手法を検討する",
    date: "2021-10-23T00:00:00Z",
    body: "線形回帰モデルのベイズファクター計算手法を検討する はじめに 本記事では線形回帰モデルを例にベイズファクターの計算手法を複数実践します。また結果を比較しそれぞれの手法の特徴をみていきます。 実践する手法は以下の通り。ガウス求積法のみ解析的な手法（積分の推定を含む）で、他の手法はMCMCの結果を使った推定手法となります。上2つの手法はこちらの記事で詳しく説明しています。 ガウス求積法 Savage-Dickey法 BridgeSampling法 線形回帰モデル 線形回帰モデルを以下のようにおきます。数式中の文字はこれ以降こちらの記事に従います。 $$ p(\\boldsymbol{Y}) = \\mathrm{Normal}\\left(\\boldsymbol{\\mu}, \\sigma^2 \\boldsymbol{I}_N\\right) = \\cfrac{1}{(2\\pi)^{n/2}\\sigma^N}\\exp\\left( -\\cfrac{1}{2\\sigma^{2}}\\left( \\boldsymbol{Y} - \\boldsymbol{\\mu} \\right)^T\\left(\\boldsymbol{Y} - \\boldsymbol{\\mu}\\right) \\right) \\tag{1} $$ 事前分布は客観ベイズの考えに基づきZellner-Siow\u0026rsquo;s Priorsを採用します。 ◆Zellner-Siow\u0026#39;s Priors\r$(1)$、$(2)$式の$\\boldsymbol{\\beta}_\\boldsymbol{{\\gamma}}$、$\\alpha$、$\\sigma^2$に対する事前分布である下記$(8)$～$(10)$式を、Zellner-Siow\u0026rsquo;s Priorsとよぶ。 $$ \\alpha,\\sigma^2 \\propto \\cfrac{1}{\\sigma^2} \\tag{2} $$ $$ \\boldsymbol{\\beta}_ \\boldsymbol{{\\gamma}} | \\sigma^2, g \\sim \\mathrm{Normal}\\left(\\boldsymbol{0}, g\\sigma^2\\left( \\cfrac{\\boldsymbol{X}_ \\boldsymbol{{\\gamma}}^{T} \\boldsymbol{X}_ \\boldsymbol{{\\gamma}}}{N} \\right)^{-1}\\right) \\tag{3} $$ $$ g \\sim \\mathrm{InvGamma}\\left( \\cfrac{1}{2}, \\cfrac{r}{2} \\right) \\tag{4} $$ ガウス求積法 これは解析的にベイズファクターを求める手法です。算出には BayesFactor::regressionBF()を使います。 この関数では下記の積分を含む式を、ガウス求積法を使って高精度に推定することでベイズファクターを算出します。 ◆1変数積分近似による推定方法\rベイズファクター$BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack$ は下記の通り計算できる。 $$ BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack = \\int _{0} ^{∞}(1 + g)^{(N - 1 - p _\\boldsymbol{\\gamma})/2} \\left( 1 + \\left( 1 - R _\\boldsymbol{\\gamma}^2 \\right) g \\right)^{-(n-1)/2} \\pi(g) dg \\tag{5} $$ ここで、$\\pi(g)$は$g$の事前分布を、$R_ \\boldsymbol{\\gamma}^2$は$\\mathcal{\\boldsymbol{M}}_ \\boldsymbol{\\gamma}$での通常の線形回帰における残差の平方和、決定係数を示す。 スクリプトは以下の通り。 # data preparation -------------------------------------------------------- library(tidyverse) d \u0026lt;- attitude response_variable \u0026lt;- d$rating predictors \u0026lt;- d %\u0026gt;% select(-rating) %\u0026gt;% mutate_all(center) %\u0026gt;% as_tibble() # regressionBF ------------------------------------------------------------ library(BayesFactor) bf \u0026lt;- regressionBF(rating ~ ., data=d, rscaleCont = \u0026#34;medium\u0026#34;) bf # Bayes factor analysis # -------------- # [1] complaints : 417938.6 ±0.01% # [2] privileges : 3.177784 ±0% # [3] learning : 103.393 ±0% # [4] raises : 47.00917 ±0.01% # [5] critical : 0.4493186 ±0% # [6] advance : 0.4472295 ±0% # [7] complaints + privileges : 75015.23 ±0% # [8] complaints + learning : 207271.9 ±0% # [9] complaints + raises : 77498.99 ±0% # [10] complaints + critical : 70087.3 ±0% # [11] complaints + advance : 72759.76 ±0% # [12] privileges + learning : 42.16342 ±0.01% # [13] privileges + raises : 25.89924 ±0% # [14] privileges + critical : 1.382939 ±0% # [15] privileges + advance : 1.234018 ±0% # [16] learning + raises : 100.5111 ±0.01% # [17] learning + critical : 33.96788 ±0% # [18] learning + advance : 68.89183 ±0.01% # [19] raises + critical : 15.70954 ±0% # [20] raises + advance : 35.60357 ±0% # [21] critical + advance : 0.2393626 ±0.01% # [22] complaints + privileges + learning : 56341.12 ±0% # [23] complaints + privileges + raises : 18230.79 ±0% # [24] complaints + privileges + critical : 16235.87 ±0% # [25] complaints + privileges + advance : 16482.37 ±0% # [26] complaints + learning + raises : 42847.98 ±0% # [27] complaints + learning + critical : 42374.73 ±0% # [28] complaints + learning + advance : 88041.54 ±0% # [29] complaints + raises + critical : 16913.97 ±0% # [30] complaints + raises + advance : 20641.12 ±0% # [31] complaints + critical + advance : 15821.13 ±0% # [32] privileges + learning + raises : 39.02367 ±0% # [33] privileges + learning + critical : 16.31662 ±0% # [34] privileges + learning + advance : 38.47538 ±0% # [35] privileges + raises + critical : 10.2571 ±0% # [36] privileges + raises + advance : 28.71547 ±0% # [37] privileges + critical + advance : 0.6451984 ±0% # [38] learning + raises + critical : 33.4565 ±0% # [39] learning + raises + advance : 313.3885 ±0% # [40] learning + critical + advance : 35.08545 ±0% # [41] raises + critical + advance : 13.36863 ±0% # [42] complaints + privileges + learning + raises : 13707.57 ±0% # [43] complaints + privileges + learning + critical : 13604.67 ±0% # [44] complaints + privileges + learning + advance : 24141.94 ±0% # [45] complaints + privileges + raises + critical : 4737.976 ±0% # [46] complaints + privileges + raises + advance : 5450.104 ±0% # [47] complaints + privileges + critical + advance : 4280.874 ±0% # [48] complaints + learning + raises + critical : 10520.62 ±0% # [49] complaints + learning + raises + advance : 23334 ±0% # [50] complaints + learning + critical + advance : 22169.3 ±0% # [51] complaints + raises + critical + advance : 5302.837 ±0% # [52] privileges + learning + raises + critical : 15.13044 ±0% # [53] privileges + learning + raises + advance : 134.4662 ±0% # [54] privileges + learning + critical + advance : 20.64672 ±0% # [55] privileges + raises + critical + advance : 11.7191 ±0.01% # [56] learning + raises + critical + advance : 106.5402 ±0% # [57] complaints + privileges + learning + raises + critical : 3826.973 ±0% # [58] complaints + privileges + learning + raises + advance : 7144.828 ±0% # [59] complaints + privileges + learning + critical + advance : 6926.973 ±0% # [60] complaints + privileges + raises + critical + advance : 1608.397 ±0% # [61] complaints + learning + raises + critical + advance : 6461.751 ±0% # [62] privileges + learning + raises + critical + advance : 51.02312 ±0% # [63] complaints + privileges + learning + raises + critical + advance : 2211.912 ±0% # # Against denominator: # Intercept only # --- # Bayes factor type: BFlinearModel, JZS Savage-Dickey法 これはMCMCを使った推定手法のひとつです。Savage-Dickey法についてはこちらを参照のこと。ネストされたモデルに対してのみ有効な手法です。 ◆Zellner-Siow\u0026#39;s Priors\r$(1)$、$(2)$式の$\\boldsymbol{\\beta}_\\boldsymbol{{\\gamma}}$、$\\alpha$、$\\sigma^2$に対する事前分布である下記$(8)$～$(10)$式を、Zellner-Siow\u0026rsquo;s Priorsとよぶ。 $$ \\alpha,\\sigma^2 \\propto \\cfrac{1}{\\sigma^2} \\tag{10} $$ $$ \\boldsymbol{\\beta}_ \\boldsymbol{{\\gamma}} | \\sigma^2, g \\sim \\mathrm{Normal}\\left(\\boldsymbol{0}, g\\sigma^2\\left( \\cfrac{\\boldsymbol{X}_ \\boldsymbol{{\\gamma}}^{T} \\boldsymbol{X}_ \\boldsymbol{{\\gamma}}}{N} \\right)^{-1}\\right) \\tag{11} $$ $$ g \\sim \\mathrm{InvGamma}\\left( \\cfrac{1}{2}, \\cfrac{r}{2} \\right) \\tag{12} $$ ここで、$\\bar{\\boldsymbol{X}_ \\boldsymbol{{\\gamma}}}$は$\\gamma_{i}=1$である$\\boldsymbol{X}_i$における平均値で構成された$N$×$\\sum{\\boldsymbol{\\gamma}}$行列である。 stanコードは以下のとおり。 // for Savage-Dickey method with cmdstanr data { int\u0026lt;lower=0\u0026gt; N, p_gamma; // N : sample size p_gamma : number of predictors vector[N] Y; // responce_variable matrix[N, p_gamma] X_gamma; // predictors real Jeffreys_alpha, Jeffreys_beta, r; //r : scale of the Cauchy //Jeffreys_alpha : mean of prior(sigma^2) (sufficiently small values) //Jeffreys_beta : variance of prior(sigma^2) (sufficiently small values) } parameters { vector[p_gamma] beta_gamma; real\u0026lt;lower=0\u0026gt; sigma, g; real alpha; // sigma : standard deviation of Y // g : variance of the standardized slope // alpha : coefficient } transformed parameters{ vector[N] mu; mu = X_gamma * beta_gamma; } model { //model target += normal_lpdf(Y - rep_vector(alpha, N) | mu, sigma); // prior target += multi_normal_lpdf( beta_gamma | rep_vector(0, p_gamma), N * g * sigma^2 * inverse(crossprod(X_gamma))); target += inv_gamma_lpdf(g | 0.5, r*0.5 ); target += gamma_lpdf(sigma^2 | Jeffreys_alpha, Jeffreys_beta); target += normal_lpdf(alpha | 0, 100); } generated quantities{ vector[p_gamma] mean_beta; matrix[p_gamma,p_gamma] covariance_beta; //mean_beta : mean of CMDE(beta_gamma) //covariance_beta : covariance of CMDE(beta_gamma) real logPostDensBeta, logPriorDensBeta; //logPriorDensBeta:p(beta_gamma=0_vector | prior) //logPostDensBeta:p(beta_gamma=0_vector | posterior) real BF_01, BF_10; //BF_01 : BF[M_N:M_gamma], BF_10 : BF[M_gamma:M_N] matrix[p_gamma,p_gamma] ScaleMatrix_PriorDensBeta = N * r * sigma^2 * inverse_spd(crossprod(X_gamma)); //ScaleMatrix_PriorDensBeta:covariance of beta_gamma at prior covariance_beta = (sigma^2 * ((N * g)^(-1) + 1)^(-1) ) * inverse_spd(crossprod(X_gamma)); mean_beta = sigma^(-2) * covariance_beta * X_gamma\u0026#39; * (Y - rep_vector(alpha, N)); logPostDensBeta = - 0.5 * p_gamma * (log(2) + log(pi())) - 0.5 * log_determinant(covariance_beta) - 0.5 * mean_beta\u0026#39; * inverse_spd(covariance_beta) * mean_beta; logPriorDensBeta = lgamma((1+p_gamma)*0.5) - ((p_gamma + 1) * 0.5) * log(pi()) - 0.5 * log_determinant(ScaleMatrix_PriorDensBeta); BF_01 = exp(logPostDensBeta - logPriorDensBeta); BF_10 = exp(logPriorDensBeta - logPostDensBeta); } これを走らせたい場合は単純に以下のようにすれば走ります。 # data preparation --------------------------------------------------------------- response_variable \u0026lt;- d$rating predictors \u0026lt;- d %\u0026gt;% select(-rating) %\u0026gt;% mutate_all(center) %\u0026gt;% as_tibble() # run_model --------------------------------------------------------------- library(cmdstanr) library(rstan) library(tidyverse) data \u0026lt;- list(Y=response_variable, X_gamma=predictors, r=sqrt(2)/4, N=length(attitude$rating), p_gamma=ncol(predictors), Jeffreys_alpha=1e-5, Jeffreys_beta=1e-5) # cmdstan : for savage-dickey method model1 \u0026lt;- cmdstan_model(paste0(getwd(),\u0026#34;/model/model1.stan\u0026#34;)) # 単純にsavage-dickey法でベイズファクターを1回だけ計算したいときは下のようにする fit_c \u0026lt;- model1$sample( data = data, parallel_chains = 4, chains = 4, iter_warmup = 1000, iter_sampling = 4000, refresh = 0, ) ただ、今回の例では試行ごとに得られるベイズファクターがかなりかわってくるので、各モデルに対し100回ずつ総当たり（Bruteforce）でシミュレーションしてみます。 # BruteForce Regression(Savage-Dickey method) --------------------------------------------------- # 準備 subsetfun \u0026lt;- function(kosuu){ XX \u0026lt;- matrix(,2^kosuu,kosuu) for(i in 1:kosuu){ CCC \u0026lt;- t(rbind(rep(F,2^(kosuu-i)),rep(T,2^(kosuu-i)))) XX[,i] \u0026lt;- rep(CCC,2^(i-1)) } return(XX) } # 設定 trials \u0026lt;- 100 subset \u0026lt;- subsetfun(ncol(predictors)) fit_BF \u0026lt;- matrix(nrow=trials, ncol=nrow(subset), data=NA) fit_BF_name \u0026lt;- matrix(nrow=trials, ncol=nrow(subset), data=NA) progress_bar_j \u0026lt;- txtProgressBar(min=1, max=trials, style=3) progress_bar_i \u0026lt;- txtProgressBar(min=2, max=nrow(subset), style=1) # BruteForce for(i in 2:nrow(subset)){ setTxtProgressBar(pb=progress_bar_i, value=i) data \u0026lt;- list(Y=response_variable, X_gamma=predictors[,subset[i,]], r=sqrt(2)/4, N=length(d$rating), p_gamma= ncol(predictors[,subset[i,]]), Jeffreys_alpha=1e-5, Jeffreys_beta=1e-5) for(j in 1:trials){ setTxtProgressBar(pb=progress_bar_j, value=j) fit_c \u0026lt;- model1$sample( data = data, chains = 4, iter_warmup = 1000, iter_sampling = 4000, refresh = 0 ) stanfit1 \u0026lt;- rstan::read_stan_csv(fit_c$output_files()) res1 \u0026lt;- as.matrix(stanfit1) %\u0026gt;% as.data.frame() %\u0026gt;% select(starts_with(\u0026#34;BF\u0026#34;)) %\u0026gt;% summarise_all(list(mean = mean)) %\u0026gt;% summarise_all(list(round),digits=8) %\u0026gt;% pivot_longer(everything()) fit_BF[j,i] \u0026lt;- 1/min(res1$value) fit_BF_name[j,i] \u0026lt;- res1$name[which.max(res1$value)] rm(fit_c) } save(fit_BF, fit_BF_name, file = paste0(getwd(),\u0026#34;/data/Data_model1.RData\u0026#34;)) } # comparing plot(Savage-Dickey method VS Gaussian Quadrature) ---------------------------------------------------------- fit_BF_rate \u0026lt;- matrix(nrow=trials, ncol=nrow(subset), data=NA) for(i in 2:nrow(subset)){ ## MCMCの採用BF(generated quantities)がすべてBF_01(or BF_10)で一意でない場合停止 if(nrow(unique(fit_BF_name)) != 1) stop(\u0026#34;MCMCの採用BF(generated quantities)がすべてBF_01(or BF_10)で一意でない\u0026#34;) ## regressionBF からの結果抽出用ID id \u0026lt;- paste(attributes(predictors)$names[subset[i,]], collapse = \u0026#34; + \u0026#34;) ## MCMCの結果がBF_01のとき、BF_10に修正 if(unique(fit_BF_name[1,i]) == \u0026#34;BF_01_mean\u0026#34;) fit_BF_rate[,i] \u0026lt;- 1 / fit_BF[,i] else fit_BF_rate[,i] \u0026lt;- fit_BF[,i] ## MCMCの採用BF(generated quantities)をregressionBFの結果で評価 fit_BF_rate[,i] \u0026lt;- fit_BF_rate[,i] / exp(attributes(bf[id])$bayesFactor[[\u0026#34;bf\u0026#34;]]) } fit_BF_rate \u0026lt;- fit_BF_rate %\u0026gt;% as_tibble() ID \u0026lt;- c() for(i in 2:nrow(subset)){ id \u0026lt;- paste(attributes(predictors)$names[subset[i,]], collapse = \u0026#34; + \u0026#34;) ID[i-1] \u0026lt;- exp(attributes(bf[id])$bayesFactor[[\u0026#34;bf\u0026#34;]]) names(ID)[i-1] \u0026lt;- id } for(i in 1:nrow(subset)){ colnames(fit_BF_rate)[i] \u0026lt;- paste(attributes(predictors)$names[subset[i,]], collapse = \u0026#34; + \u0026#34;) } fit_BF_rate %\u0026gt;% select(-\u0026#34;\u0026#34;) %\u0026gt;% summarise_all(list(median)) %\u0026gt;% summarise_all(list(round),digits=2) %\u0026gt;% pivot_longer(everything()) %\u0026gt;% mutate(BF = ID[name]) %\u0026gt;% mutate_at(vars(BF), round, digits=3) %\u0026gt;% mutate_at(vars(BF),as.factor) -\u0026gt; fit_BF_median fit_BF_rate %\u0026gt;% select(-\u0026#34;\u0026#34;) %\u0026gt;% pivot_longer(cols = everything(),names_to = \u0026#34;name\u0026#34;, values_to = \u0026#34;fit_BF\u0026#34;) %\u0026gt;% mutate(BF = ID[name]) %\u0026gt;% mutate_at(vars(BF), round, digits=3) %\u0026gt;% mutate_at(vars(BF),as.factor) -\u0026gt; res library(RColorBrewer) mycol \u0026lt;- c(rep(c(brewer.pal(12,\u0026#34;Set3\u0026#34;),brewer.pal(8,\u0026#34;Set2\u0026#34;),brewer.pal(9,\u0026#34;Set1\u0026#34;)),2),brewer.pal(6,\u0026#34;Set3\u0026#34;)) p \u0026lt;- ggplot(data=res, aes(x=BF,y=fit_BF, fill = name)) + theme_light(base_size=11) + geom_boxplot() + geom_text(data=fit_BF_median, aes(x=BF, y=value, label=value), nudge_y = 0.08, color=\u0026#34;grey20\u0026#34;, size=3.4) + theme(legend.position = \u0026#34;\u0026#34;) + scale_y_log10(limits = c(1e-02, 1e+02)) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + scale_fill_manual(values = mycol) + xlab(\u0026#34;BF10 by Gaussian quadrature\u0026#34;) + ylab(\u0026#34;BF10 by Savage-Dickey method\u0026#34;) BayesFactor::regressionBF()との比較結果を示します。 結果、BayesFactor::regressionBF()による結果から大きく逸脱してはいませんが、BFの値が1000を超えたあたりからMCMC毎の結果のばらつきが大きくなっています。また全体的にBFの値が大きくなるにつれてBFがヌルモデルを過小評価する傾向があります。 BridgeSampling法 Bridgesampling法も推定手法のひとつです。モデルの自由エネルギーをMCMC結果から直接推定する手法のようですが、詳細はまだ勉強してません！ 各モデルとヌルモデルの自由エネルギーを推定し、比を取ることでベイズファクターを推定します。 各モデルの自由エネルギーを推定するためのMCMCを得るStanコードは下記の通り。 data { int\u0026lt;lower=0\u0026gt; N; int\u0026lt;lower=0\u0026gt; p_gamma; // N : sample size p_gamma : number of predictors vector[N] Y; // responce_variable matrix[N, p_gamma] X_gamma; // predictors real Jeffreys_alpha; real Jeffreys_beta; real r; //r : scale of the Cauchy //Jeffreys_alpha : mean of prior(sigma^2) (sufficiently small values) //Jeffreys_beta : variance of prior(sigma^2) (sufficiently small values) } parameters { vector[p_gamma] beta_gamma; real\u0026lt;lower=0\u0026gt; sigma; real g; real alpha; // sigma : standard deviation of Y // g : variance of the standardized slope // alpha : coefficient } transformed parameters{ vector[N] mu; mu = X_gamma * beta_gamma; } model { //model target += normal_lpdf(Y - rep_vector(alpha, N) | mu, sigma); // prior target += multi_normal_lpdf( beta_gamma | rep_vector(0, p_gamma), N * g * sigma^2 * inverse(crossprod(X_gamma))); target += inv_gamma_lpdf(g | 0.5, r*0.5 ); target += gamma_lpdf(sigma^2 | Jeffreys_alpha, Jeffreys_beta); target += normal_lpdf(alpha | 0, 100); } ヌルモデルの自由エネルギーを推定するためのMCMCを得るStanコードは下記の通り。 data { int\u0026lt;lower=0\u0026gt; N; vector[N] Y; // responce_variable real Jeffreys_alpha; real Jeffreys_beta; //Jeffreys_alpha : mean of prior(sigma^2) (sufficiently small values) //Jeffreys_beta : variance of prior(sigma^2) (sufficiently small values) } parameters { real\u0026lt;lower=0\u0026gt; sigma; real alpha; // sigma : standard deviation of Y // g : variance of the standardized slope // alpha : coefficient } model { //model target += normal_lpdf(Y - rep_vector(alpha, N) | 0, sigma); // prior target += gamma_lpdf(sigma^2 | Jeffreys_alpha, Jeffreys_beta); target += normal_lpdf(alpha | 0, 100); } こちらも総当たりで各モデルに対し11回ずつでシミュレーションしてみます。 # BruteForce Regression(bridge-sampling) ----------------------------- # rstan : for bridge-sampling model2 \u0026lt;- stan_model(paste0(getwd(),\u0026#34;/model/model2.stan\u0026#34;)) model3 \u0026lt;- stan_model(paste0(getwd(),\u0026#34;/model/model3.stan\u0026#34;)) library(bridgesampling) trials \u0026lt;- 11 subset \u0026lt;- subsetfun(ncol(predictors)) free_energy_null \u0026lt;- rep(NA, n=trials) free_energy_gamma \u0026lt;- matrix(nrow=trials, ncol=nrow(subset), data=NA) BF_bridgesampler \u0026lt;- matrix(nrow=trials, ncol=nrow(subset), data=NA) progress_bar_j \u0026lt;- txtProgressBar(min=1, max=trials, style=3) progress_bar_i \u0026lt;- txtProgressBar(min=2, max=nrow(subset), style=1) for(j in 1:trials){ fit_b \u0026lt;- sampling( model3, data = data, chains = 4, iter = 10000, warmup = 1000, ) free_energy_null[j] \u0026lt;- bridge_sampler(fit_b, method=\u0026#34;warp3\u0026#34;)$logml rm(fit_b) save(free_energy_null, file = paste0(getwd(),\u0026#34;/data/free_energy_null.RData\u0026#34;)) } for(i in 2:nrow(subset)){ setTxtProgressBar(pb=progress_bar_i, value=i) data \u0026lt;- list(Y=response_variable, X_gamma=predictors[,subset[i,]], r=sqrt(2)/4, N=length(d$rating), p_gamma= ncol(predictors[,subset[i,]]), Jeffreys_alpha=1e-5, Jeffreys_beta=1e-5) for(j in 1:trials){ setTxtProgressBar(pb=progress_bar_j, value=j) fit_b \u0026lt;- sampling( model2, data = data, chains = 4, iter = 10000, warmup = 1000, ) free_energy_gamma[j,i] \u0026lt;- bridge_sampler(fit_b, method=\u0026#34;warp3\u0026#34;)$logml BF_bridgesampler[j,i] \u0026lt;- exp(free_energy_gamma[j,i] - free_energy_null[j]) rm(fit_b) save(free_energy_gamma,BF_bridgesampler, file = paste0(getwd(),\u0026#34;/data/BF_bridgesampler.RData\u0026#34;)) } } # comparing plot(Bridge-sampling method VS Gaussian Quadrature) ---------------------------------------------------------- fit_BF_rate \u0026lt;- matrix(nrow=trials, ncol=nrow(subset), data=NA) for(i in 2:nrow(subset)){ ## regressionBF からの結果抽出用ID id \u0026lt;- paste(attributes(predictors)$names[subset[i,]], collapse = \u0026#34; + \u0026#34;) fit_BF_rate[,i] \u0026lt;- BF_bridgesampler[,i] / exp(attributes(bf[id])$bayesFactor[[\u0026#34;bf\u0026#34;]]) } fit_BF_rate \u0026lt;- fit_BF_rate %\u0026gt;% as_tibble() ID \u0026lt;- c() for(i in 2:nrow(subset)){ id \u0026lt;- paste(attributes(predictors)$names[subset[i,]], collapse = \u0026#34; + \u0026#34;) ID[i-1] \u0026lt;- exp(attributes(bf[id])$bayesFactor[[\u0026#34;bf\u0026#34;]]) names(ID)[i-1] \u0026lt;- id } for(i in 1:nrow(subset)){ colnames(fit_BF_rate)[i] \u0026lt;- paste(attributes(predictors)$names[subset[i,]], collapse = \u0026#34; + \u0026#34;) } fit_BF_rate %\u0026gt;% select(-\u0026#34;\u0026#34;) %\u0026gt;% summarise_all(list(median)) %\u0026gt;% summarise_all(list(round),digits=2) %\u0026gt;% pivot_longer(everything()) %\u0026gt;% mutate(BF = ID[name]) %\u0026gt;% mutate_at(vars(BF), round, digits=3) %\u0026gt;% mutate_at(vars(BF),as.factor) -\u0026gt; fit_BF_median fit_BF_rate %\u0026gt;% select(-\u0026#34;\u0026#34;) %\u0026gt;% pivot_longer(cols = everything(),names_to = \u0026#34;name\u0026#34;, values_to = \u0026#34;fit_BF\u0026#34;) %\u0026gt;% mutate(BF = ID[name]) %\u0026gt;% mutate_at(vars(BF), round, digits=3) %\u0026gt;% mutate_at(vars(BF),as.factor) -\u0026gt; res library(RColorBrewer) mycol \u0026lt;- c(rep(c(brewer.pal(12,\u0026#34;Set3\u0026#34;),brewer.pal(8,\u0026#34;Set2\u0026#34;),brewer.pal(9,\u0026#34;Set1\u0026#34;)),2),brewer.pal(6,\u0026#34;Set3\u0026#34;)) p \u0026lt;- ggplot(data=res, aes(x=BF,y=fit_BF, fill = name)) + theme_light(base_size=11) + geom_boxplot() + geom_text(data=fit_BF_median, aes(x=BF, y=value, label=value), nudge_y = 0.08, color=\u0026#34;grey20\u0026#34;, size=3.4) + theme(legend.position = \u0026#34;\u0026#34;) + scale_y_log10(limits = c(1e-02, 1e+02)) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + scale_fill_manual(values = mycol) + xlab(\u0026#34;BF10 by Gaussian quadrature\u0026#34;) + ylab(\u0026#34;BF10 by BridgeSampling\u0026#34;) BayesFactor::regressionBF()との比較結果を示します。 こちらもBayesFactor::regressionBF()による結果から大きく逸脱していません。全体的にBFの値が大きくなるにつれてBFがヌルモデルを過小評価する傾向もSavage-Dickey法と同じです。 おそらくは、$\\alpha$に分散が大きく平均$0$の正規分布を、$\\sigma^2$にガンマ分布を用いて$(2)$式（Jeffrey\u0026rsquo;s prior）を近似的に表現しているので、本来のモデルとの微妙な差異が結果に影響しているものと思われます。 また、Savage-Dickey法ではBFの値が1000を超えたあたりからMCMC毎のばらつきが大きくなっていて、結果の収束度合いがゴミのようだったのに対し、BridgeSampling法ではBFがどんな値をとってもMCMC毎のばらつきがかなり小さくなっています。BridgeSampling法がいかに優れた手法か思い知らされますね…せっかく$\\boldsymbol{\\beta}_\\boldsymbol{\\gamma}$の条件付き事後分布をせっせと導出したのに残念ながら報われませんでした。 まとめ 本記事では線形回帰モデルを例にベイズファクターの計算手法を複数実践し、それぞれの結果を比較してみました。得られた知見は以下の通り。 ・ Jeffrey\u0026rsquo;s priorの近似的表現は、MCMC結果から推定したBFに若干影響する（たぶん） ・ Savage-Dickey法の推定精度はガバガバ ・ BridgeSampling法は優秀 ということで、BridgeSampling法について詳しくなりたいなあと思いました。"
  },
  {
    url: "https://sucre-stat.com/2021/10/bayesian-hypothesis-testing-3practice/",
    title: "ベイズファクターを用いた仮説検定を実践する～線形回帰分析～",
    date: "2021-10-22T00:00:00Z",
    body: "ベイズファクターを用いた仮説検定を実践する～線形回帰分析～ はじめに 本記事ではベイズファクターを使った線形回帰モデルの評価方法を紹介します。 サンプルデータの分析 今回使用するサンプルデータはR標準的サンプルデータ、Attitudeです。 Attitudeは従業員が自信の所属する会社の評価に関する質問結果のデータで、ratingが会社の総合評価となります。以降は、会社の総合評価がどの要素によって説明されるのかをみていくことにします。 head(attitude) # rating complaints privileges learning raises critical advance # 1 43 51 30 39 61 92 45 # 2 63 64 51 54 63 73 47 # 3 71 70 68 69 76 86 48 # 4 61 63 45 47 54 84 35 # 5 81 78 56 66 71 83 47 # 6 43 55 49 44 54 49 34 尤度に基づく線形回帰分析 従来通りの手法としては尤度に基づく線形回帰分析があります。まずは何も考えずに全説明変数を用いて分析にかけてみましょう。 d \u0026lt;- attitude res_full \u0026lt;- lm(rating~. , data=d) summary(res_full) # Call: # lm(formula = rating ~ ., data = d) # # Residuals: # Min 1Q Median 3Q Max # -10.9418 -4.3555 0.3158 5.5425 11.5990 # # Coefficients: # Estimate Std. Error t value Pr(\u0026gt;|t|) # (Intercept) 10.78708 11.58926 0.931 0.361634 # complaints 0.61319 0.16098 3.809 0.000903 *** # privileges -0.07305 0.13572 -0.538 0.595594 # learning 0.32033 0.16852 1.901 0.069925 . # raises 0.08173 0.22148 0.369 0.715480 # critical 0.03838 0.14700 0.261 0.796334 # advance -0.21706 0.17821 -1.218 0.235577 # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 # # Residual standard error: 7.068 on 23 degrees of freedom # Multiple R-squared: 0.7326,\tAdjusted R-squared: 0.6628 # F-statistic: 10.5 on 6 and 23 DF, p-value: 1.24e-05 complaintsの正の傾きのみに対し十分小さいp値が得られ、他の変数のp値は有意でないという結果が得られました。 ここで、p値が示す意味には注意が必要です。回りくどい表現になってしまいますが、p値の意味は「係数が0と仮定したとき、新たにデータを取るとt分布に従う検定統計量がこれより極端な値をとる確率」となります。簡単にいうと各係数を採用する積極的な証拠を与えていないんです。 ともあれ、complaints以外の変数は消去の余地がありそうですが、尤度に基づく方法でのモデル選択にはAIC（赤池情報量基準）がよく使用されます。 $$ \\mathrm{AIC} = -2×最大対数尤度 + 2×自由パラメータ数　\\tag{1} $$ AICを小さくするモデルほど良いモデルとされます。また冗長なモデルには第２項の自由パラメータ数によってペナルティが与えられます。 step(res_full) # Start: AIC=123.36 # rating ~ complaints + privileges + learning + raises + critical + # advance # # Df Sum of Sq RSS AIC # - critical 1 3.41 1152.4 121.45 # - raises 1 6.80 1155.8 121.54 # - privileges 1 14.47 1163.5 121.74 # - advance 1 74.11 1223.1 123.24 # \u0026lt;none\u0026gt; 1149.0 123.36 # - learning 1 180.50 1329.5 125.74 # - complaints 1 724.80 1873.8 136.04 # # Step: AIC=121.45 # rating ~ complaints + privileges + learning + raises + advance # # Df Sum of Sq RSS AIC # - raises 1 10.61 1163.0 119.73 # - privileges 1 14.16 1166.6 119.82 # - advance 1 71.27 1223.7 121.25 # \u0026lt;none\u0026gt; 1152.4 121.45 # - learning 1 177.74 1330.1 123.75 # - complaints 1 724.70 1877.1 134.09 # # Step: AIC=119.73 # rating ~ complaints + privileges + learning + advance # # Df Sum of Sq RSS AIC # - privileges 1 16.10 1179.1 118.14 # - advance 1 61.60 1224.6 119.28 # \u0026lt;none\u0026gt; 1163.0 119.73 # - learning 1 197.03 1360.0 122.42 # - complaints 1 1165.94 2328.9 138.56 # # Step: AIC=118.14 # rating ~ complaints + learning + advance # # Df Sum of Sq RSS AIC # - advance 1 75.54 1254.7 118.00 # \u0026lt;none\u0026gt; 1179.1 118.14 # - learning 1 186.12 1365.2 120.54 # - complaints 1 1259.91 2439.0 137.94 # # Step: AIC=118 # rating ~ complaints + learning # # Df Sum of Sq RSS AIC # \u0026lt;none\u0026gt; 1254.7 118.00 # - learning 1 114.73 1369.4 118.63 # - complaints 1 1370.91 2625.6 138.16 # # Call: # lm(formula = rating ~ complaints + learning, data = d) # # Coefficients: # (Intercept) complaints learning # 9.8709 0.6435 0.2112 AICに基づくステップワイズ法の結果、採用されたモデルは「rating ~ complaints + learning (+ 切片)」となりました。採用モデルのp値を確認してみましょう。 res_best \u0026lt;- lm(rating ~ complaints + learning, data=d) summary(res_best) # Call: # lm(formula = rating ~ complaints + learning, data = d) # # Residuals: # Min 1Q Median 3Q Max # -11.5568 -5.7331 0.6701 6.5341 10.3610 # # Coefficients: # Estimate Std. Error t value Pr(\u0026gt;|t|) # (Intercept) 9.8709 7.0612 1.398 0.174 # complaints 0.6435 0.1185 5.432 9.57e-06 *** # learning 0.2112 0.1344 1.571 0.128 # --- # Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 # # Residual standard error: 6.817 on 27 degrees of freedom # Multiple R-squared: 0.708,\tAdjusted R-squared: 0.6864 # F-statistic: 32.74 on 2 and 27 DF, p-value: 6.058e-08 complaintsは相も変わらず有意なp値が得られていますが、learningはモデルに含まれるもののp値は有意でありません。このデータは小サンプルなので、これだけで判断することは危険ですが、complaintsはratingの決定要因になっていると考えてよさそうです。 ベイズファクターによるモデル評価 一方のベイズファクターではどんな結果が得られるでしょうか。分析により、下記の通りベイズファクターが算出されたとしましょう。 Jeffreys(1961) model $BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack$ privileges 3.177784 learning 103.393 raises 47.00917 critical 0.4493186 advance 0.4472295 complaints + privileges 75015.23 $\\vdots$ $\\vdots$ complaints + privileges + learning + raises + critical 3826.973 complaints + privileges + learning + raises + advance 7144.828 complaints + privileges + learning + critical + advance 6926.973 complaints + privileges + raises + critical + advance 1608.397 complaints + learning + raises + critical + advance 6461.751 privileges + learning + raises + critical + advance 51.02312 complaints + privileges + learning + raises + critical + advance 2211.912 このとき、どのように線形回帰モデルを評価していけるのか見ていきましょう。 モデル間比較 モデル間の比較には下記式を用います。これはEncompassing approachと呼ばれ、ベースとなるモデルの自由エネルギーを介して各モデルの自由エネルギーの大きさを評価するものです。 $$ BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}} : \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} \\rbrack = \\cfrac{BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack}{BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack} \\tag{2} $$ モデルの冗長性は、パラメータの事前分布と真分布との乖離によって評価されます（モデル自体仮定のものだがここでは真の分布があるとする）。事前分布が、真の分布からおよそ離れた広範囲のパラメータ空間を考慮したものの場合、そのモデルの周辺尤度は0に近づくため、比較的説明力の低いモデルと判断されやすくなってしまいます。 ベースとなるモデルをフルモデルとしたときの比較結果は次のようになります。 最も優れたモデルはcomplaintsのみのモデルという結果になりました。complaintsのみのモデルとの比較ではフルモデルを決定的に否定するベイズファクターが得られています（Kass and Rafteryの指標参照）。一方、complaintsのみのモデルと、さらにlearningを加えた二番目に優れたモデルを比較するベイズファクター(「complaints」/「complaints + learning」 )は2.016となり、二番目のモデルを棄却する証拠はあまりあるとは言えない結果になりました。 これらの結果の優れているところは、モデルを積極的に肯定するエビデンス＝周辺尤度を比較することでモデル間の比較をできることにあります。これはp値に基づく枠組みでは不可能でした。これについてはこちらも参照のこと。 説明変数の選択 モデル間比較ではなく、各説明変数が必要かどうかを知りたい、という場合もあると思います。その場合、ベースとなるモデルから確認したい変数1つだけを除いた（または追加した）モデルと、ベースモデルを、ベイズファクターによって比較するという方法が考えられます。 ベースモデルをフルモデルとしたとき、各変数を1個ずつ取り除いたモデルとの比較を行った結果を下に示します。 complaintsの必要性を測るベイズファクター(「フルモデル」/「フルモデル -complaints」 )は43.35と、強くcomplaintsを除いたモデルを棄却する結果となったため、complaintsはratingを説明するのに需要な指標と言えそうです。一方、それ以外の変数についてはあまり根拠があるとは言えない結果ばかりでした。 ベースモデルをヌルモデルとしたときの結果も下に示します。 complaintsについては決定的にヌルモデルを棄却する結果が得られています。またlearning、raises、privilegesについても肯定的な結果が得られています。あれ、じゃあこれら4つの変数を採用したモデルがいいのでは？…そうでもありません。この4変数を採用したモデルとフルモデルを比較したベイズファクターはそれほど大きくありません。ここには落とし穴があります。 下の表は7変数の相関関係を表しています。これを見ると、有力な変数complaintsは、上で挙げたlearning、raises、privilegesの3変数と有意に正の相関関係にあります。つまり、この3変数はcomplaintsのもつ傾向の一部分を表現できるために、ヌルモデルとの比較の際も肯定的な結果が得られていたのです。 あるモデルに相関関係が高い変数の組み合わせがあることを多重共線性と呼びます。多重共線性のあるモデルは係数の値が不安定となり、また冗長であるために望ましくないとされます。 ベイズファクターを用いたモデル間比較の場合、各変数に着目した比較よりも前節の全モデル間比較の手法の方が、より多重共線性に強い検討手法と言えそうです。 事後モデル確率の更新 ベイズファクターは、得られたデータのモデルへの当てはまりの良さを測る相対的な指標ですが、モデル自体を評価するものではありません。モデルを評価するためには、各モデル$\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}$の事前確率$p\\left(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}\\right)$を、新しく得られたデータから算出したベイズファクターに基づき下記式のようにアップデートすることで、事後モデルオッズを導く必要があります。 $$ p(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} | \\boldsymbol{Y}) = \\cfrac{p(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}})BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {b}\\rbrack}{\\sum_ {\\boldsymbol{\\gamma}^{'}} p(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}})BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}} : \\mathcal{\\boldsymbol{M}}_b \\rbrack} \\tag{3} $$ 事前モデルオッズは、データに完全依存して決定されるベイズファクターとは対照的に、データとは無関係に事前に想定するモデル確率の組み合わせで決定されます。もしあるモデルが何らかの確証のもったメカニズムを背景に持つ場合、そのモデル確率を分子とした事前モデルオッズは大きくなるでしょう。逆に、なんのメカニズムも想定されない無関係な変数同士の関係性を表現したモデルなんかの確率を分子とした事前モデルオッズは、相対的に小さくするべきです。 このように、事前モデルオッズは、データを取る前から分かりきっているような情報や意見を事後モデルオッズに与える役目をもちます。 Attitudeに対し、得られたベイズファクターと事前モデルオッズを基に事後モデルオッズを算出した結果（TOP6）を下記に示します。ここで、事前モデルオッズはモデル間で一律としました。 model $p(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} \\mid \\boldsymbol{Y})$ complaints 0.296 complaints + learning 0.147 complaints + learning + advance 0.062 complaints + raises 0.055 complaints + privileges 0.053 complaints + advance 0.052 事前モデルオッズを一定にした場合、事後モデルオッズはあるモデルの周辺尤度と全モデルの周辺尤度和の比となります。 表から読み取れるように、最も大きい周辺尤度を持つComplaintsのみのモデルが最も事後モデル確率が大きく、全体の約3割を占めました。 BayesFactorパッケージを使ったベイズファクターの計算 最後に、R言語で簡単にベイズファクターを求める方法を載せて終わりにします。 ベイズファクターの計算にはMoreyさんの作成したBayesFactorパっケージが直感的に使えて便利です。これまでの節で示したAttitudeデータのベイズファクターも、このパッケージを使って算出したものになります。 下のスクリプトは単純にAttitudeデータでベイズファクターを求めたものです。 library(BayesFactor) bf \u0026lt;- regressionBF(rating ~ ., data=d, rscaleCont = \u0026#34;medium\u0026#34;) bf # Bayes factor analysis # -------------- # [1] complaints : 417938.6 ±0.01% # [2] privileges : 3.177784 ±0% # [3] learning : 103.393 ±0% # [4] raises : 47.00917 ±0.01% # [5] critical : 0.4493186 ±0% # [6] advance : 0.4472295 ±0% # [58] complaints + privileges + learning + raises + advance : 7144.828 ±0% # ～～略～～ # [59] complaints + privileges + learning + critical + advance : 6926.973 ±0% # [60] complaints + privileges + raises + critical + advance : 1608.397 ±0% # [61] complaints + learning + raises + critical + advance : 6461.751 ±0% # [62] privileges + learning + raises + critical + advance : 51.02312 ±0% # [63] complaints + privileges + learning + raises + critical + advance : 2211.912 ±0% # # Against denominator: # Intercept only # --- # Bayes factor type: BFlinearModel, JZS 下のスクリプトは説明変数の選択を目的とした分析をしています。 bf2 = regressionBF(rating ~ ., data = attitude, whichModels = \u0026#34;top\u0026#34;) bf2 # Bayes factor top-down analysis # -------------- # When effect is omitted from complaints + privileges + learning + raises + critical + advance , BF is... # [1] Omit advance : 1.730165 ±0% # [2] Omit critical : 3.230159 ±0% # [3] Omit raises : 3.131667 ±0% # [4] Omit learning : 0.7271523 ±0% # [5] Omit privileges : 2.921341 ±0% # [6] Omit complaints : 0.02306743 ±0% # # Against denominator: # rating ~ complaints + privileges + learning + raises + critical + advance # --- # Bayes factor type: BFlinearModel, JZS bf3 = regressionBF(rating ~ ., data = attitude, whichModels = \u0026#34;bottom\u0026#34;) bf3 # Bayes factor analysis # -------------- # [1] complaints : 417938.6 ±0.01% # [2] privileges : 3.177784 ±0% # [3] learning : 103.393 ±0% # [4] raises : 47.00917 ±0.01% # [5] critical : 0.4493186 ±0% # [6] advance : 0.4472295 ±0% # # Against denominator: # Intercept only # --- # Bayes factor type: BFlinearModel, JZS 下のスクリプトでは事前モデルオッズを一定としたときの事後モデルオッズを算出しています。 prior.odds \u0026lt;- newPriorOdds(bf, type=\u0026#34;equal\u0026#34;) post.odds = prior.odds * bf post.prob = as.BFprobability(post.odds) head(post.prob) # Posterior probabilities # -------------- # [1] complaints : 0.296141 ±NA% # [2] complaints + learning : 0.1468678 ±NA% # [3] complaints + learning + advance : 0.06238406 ±NA% # [4] complaints + raises : 0.05491387 ±NA% # [5] complaints + privileges : 0.05315394 ±NA% # [6] complaints + advance : 0.05155578 ±NA% # # Normalized probability: 0.6650164 # --- # Model type: BFlinearModel, JZS まとめ 本記事ではベイズファクターを使った線形回帰モデルの評価方法を紹介しました。 こちらの記事では線形回帰分析での客観ベイズ的な事前分布の設定方法等、理論を少し詳しく説明しています。 こちらの記事ではベイズファクターを推定するための手法を複数実践しているので、読んでみてください。"
  },
  {
    url: "https://sucre-stat.com/2021/10/bayesian-hypothesis-testing-3theory/",
    title: "ベイズファクターを用いた仮説検定～線形回帰分析～",
    date: "2021-10-08T00:00:00Z",
    body: "ベイズファクターを用いた仮説検定～線形回帰分析～ 今回は、ベイズファクターを使った線形回帰分析におけるモデル選択について理論を整理します。 ベイズファクターとはなんぞや？という方はこちらを、Savage-Dickey法についてはこちらを参照のこと。 主な参考文献はこちらです。 線形回帰モデル まずは線形回帰モデルの導出と、周辺尤度について整理します。 $\\boldsymbol{Y} = \\left( y_1, \\ldots, y_N \\right)^T$を応答変数、$\\boldsymbol{X}_ 1 = \\left( x_ {11} - \\bar{x}_1, \\ldots, x_{1N}- \\bar{x}_1 \\right)^T, \\ldots, \\boldsymbol{X}_ p = \\left( x_ {p1} - \\bar{x}_p, \\ldots, x_{pN} - \\bar{x}_p \\right)^T$を説明変数とします($\\bar{x}_i = \\mathbb{E}[\\boldsymbol{X}_ i], i=1,\\ldots,p$ )。 線形回帰モデルでは、応答変数$\\boldsymbol{Y}$が平均ベクトル$\\boldsymbol{\\mu} = \\left( \\mu_1, \\ldots, \\mu_N \\right)^T$をパラメータにもつ正規分布に従うと仮定します。 $$ p(\\boldsymbol{Y}) = \\mathrm{Normal}\\left(\\boldsymbol{\\mu}, \\sigma^2 \\boldsymbol{I}_N\\right) = \\cfrac{1}{(2\\pi)^{n/2}\\sigma^N}\\exp\\left( -\\cfrac{1}{2\\sigma^{2}}\\left( \\boldsymbol{Y} - \\boldsymbol{\\mu} \\right)^T\\left(\\boldsymbol{Y} - \\boldsymbol{\\mu}\\right) \\right) \\tag{1} $$ ここで、$\\boldsymbol{I}_N$は$N×N$の単位行列です。 平均ベクトル$\\boldsymbol{\\mu}$は、$\\boldsymbol{1}_ N$(1で構成されるN行の列ベクトル)、$\\boldsymbol{X}_ 1,\\ldots,\\boldsymbol{X}_ N$のいずれかもしくはすべての線形結合で説明できるものと仮定します。ここで常に考えなければならない問題は、$\\boldsymbol{\\mu}$の説明に用いる説明変数の組をどうするかです。これが線形回帰分析においての所謂モデル選択の問題と呼ばれます。 本記事では参考文献と同様、説明変数の選び方を一般化して説明するため、$p$次元ベクトル$\\boldsymbol{\\gamma} = \\left( \\gamma_1,\\ldots, \\gamma_p \\right)$をおき、$\\gamma_i = 1$のとき、$\\boldsymbol{X}_ i$を用いる説明変数に含め、$\\gamma_i = 0$のときは逆に含めないこととすることで切片と説明変数によって張られるモデル空間を示すことにし、$\\gamma_i = 1$の$\\boldsymbol{X}_ i$で構成される$N$×$p_{\\boldsymbol{\\gamma}}$行列を$\\boldsymbol{X}_ {\\boldsymbol{\\gamma}}$と示します。さらに$\\boldsymbol{\\gamma}$を用いたモデルを$\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}$とおき、$\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}$での係数パラメータを下付き文字で同様に示します。 $$ \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}　: ~~~ \\boldsymbol{\\mu} = \\boldsymbol{1}_ N \\alpha + \\boldsymbol{X}_ {\\boldsymbol{\\gamma}} \\boldsymbol{\\beta}_{\\boldsymbol{\\gamma}} \\tag{2} $$ ここで、$\\alpha$はスカラー、$\\boldsymbol{\\beta}_　{\\boldsymbol{\\gamma}}$は$p_　{\\boldsymbol{\\gamma}}$次元ベクトルです。$\\boldsymbol{X}_ {\\boldsymbol{\\gamma}}$は各変数で中心化されているので、変数のばらつきのみが係数パラメータ$\\boldsymbol{\\beta}_　{\\boldsymbol{\\gamma}}$に反映され、変数のスケールはすべて$\\alpha$で表現されることになります。 また、どの説明変数も用いないモデルをヌルモデルと呼び、$\\mathcal{\\boldsymbol{M}}_N$と表現します（下付き文字の$N$はサンプル数ではなく、Null-modelの頭文字）。 $$ \\mathcal{\\boldsymbol{M}}_ N　: ~~~ \\boldsymbol{\\mu} = \\boldsymbol{1}_ N \\alpha \\tag{3} $$ 線形回帰モデルの評価 ベイズ統計におけるモデル評価方法を整理します。ここで述べることは線形回帰に限定されないより一般的な議論です。 モデル確率の更新 モデル選択やモデルの不確実性の評価にあたっては、不明なパラメータ$\\boldsymbol{\\theta}_ \\boldsymbol{\\gamma} = \\left( \\alpha, \\boldsymbol{\\beta}_{\\boldsymbol{\\gamma}}, \\sigma^2 \\right) ∈ \\boldsymbol{\\Theta}_\\boldsymbol{\\gamma}$の事前分布を決め、各モデル$\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}$の事前確率$p\\left(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}\\right)$を新しく得られたデータに基づきアップデートすることが一つのアプローチとして考えられます。 $$ p(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} | \\boldsymbol{Y}) = \\cfrac{p(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}})p( \\boldsymbol{Y} | \\mathcal{\\boldsymbol{M}}_\\boldsymbol{\\gamma} )}{\\sum_ {\\boldsymbol{\\gamma}} p(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}})p( \\boldsymbol{Y} | \\mathcal{\\boldsymbol{M}}_ \\boldsymbol{\\gamma} ) } \\tag{4} $$ $(4)$式はモデル確率の更新方法を示したもので、ベイズの定理そのままですが、右辺に現れた$p(\\boldsymbol{Y} | \\mathcal{\\boldsymbol{M}}_\\boldsymbol{\\gamma})$が本記事の鍵となる値、周辺尤度です。$(5)$式に示す通り、周辺尤度は尤度をパラメータの事前分布で重みづけ（積分）したもので、データ$\\boldsymbol{Y}$に対するモデルの平均的な説明力を示します。 $$ p(\\boldsymbol{Y} |\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}) = \\int_{\\boldsymbol{\\Theta}_{\\boldsymbol{\\gamma}}} p(\\boldsymbol{Y}|\\boldsymbol{\\theta}_{{\\boldsymbol{\\gamma}}},\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}})p(\\boldsymbol{\\theta}_{{\\boldsymbol{\\gamma}}} | \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} ) d\\boldsymbol{\\theta} _ {\\boldsymbol{\\gamma}} \\tag{5} $$ ベイズファクター ベイズファクターは$(6)$式に示す通り2つのモデル間の周辺尤度比として定義され、データ$\\boldsymbol{Y}$に対する2つのモデルの説明力の比と捉えることができます。 $$ BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}} : \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} \\rbrack = \\cfrac{p(\\boldsymbol{Y} |\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}})}{p(\\boldsymbol{Y} |\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}})} = \\cfrac{\\int_{\\boldsymbol{\\Theta}_{\\boldsymbol{\\gamma}^{'}}} p(\\boldsymbol{Y}|\\boldsymbol{\\theta}_{{\\boldsymbol{\\gamma}^{'}}},\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}})p(\\boldsymbol{\\theta}_{{\\boldsymbol{\\gamma}^{'}}} | \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}} ) d\\boldsymbol{\\theta} _ {\\boldsymbol{\\gamma}^{'}}}{\\int_{\\boldsymbol{\\Theta}_{\\boldsymbol{\\gamma}}} p(\\boldsymbol{Y}|\\boldsymbol{\\theta}_{{\\boldsymbol{\\gamma}}},\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}})p(\\boldsymbol{\\theta}_{{\\boldsymbol{\\gamma}}} | \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} ) d\\boldsymbol{\\theta} _ {\\boldsymbol{\\gamma}}} \\tag{6} $$ ベイズファクターを使うと、$(4)$式は以下のように変形できます。 $$ p(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} | \\boldsymbol{Y}) = \\cfrac{p(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}})BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {b}\\rbrack}{\\sum_ {\\boldsymbol{\\gamma}^{'}} p(\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}})BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}} : \\mathcal{\\boldsymbol{M}}_b \\rbrack} \\tag{7} $$ $\\mathcal{\\boldsymbol{M}}_b$はベイズファクターを算出する際のベースとなるモデルで任意のモデルを選択できますが、通常はどの選択をとってもモデル同士がネストされた関係となるよう、ヌルモデルもしくはフルモデル（すべての説明変数を用いたモデル）が用いられます。 Null-Based Model $$ BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack = \\cfrac{p(\\boldsymbol{Y} |\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}})}{p(\\boldsymbol{Y} |\\mathcal{\\boldsymbol{M}}_ {N})} \\tag{8} $$ また、任意のモデル間を比較するベイズファクターについても、すべてのモデルに対して包含(Encompassing)関係にあるヌルモデルを基準に計算することができます。 Encompassing approach $$ BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}} : \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} \\rbrack = \\cfrac{BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}^{'}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack}{BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack} \\tag{9} $$ 個人的にはベイズファクターとモデル確率更新によるモデル評価手法はものすごく可能性があると思っています。ベイズファクターは新しく得られたデータに対する各モデルの説明力を評価でき、これまでの情報から既に算出されたモデル確率を、ベイズファクターに基づいて更新する・・・とても近未来的なにおいを感じます。\r 事前分布 これまでの議論から、ベイズファクターは事前分布の影響を強く受けることは明白です。客観ベイズの立場から見れば、客観的で研究者間で合意のとれた事前分布の設定方法を確立することで、ベイズファクターやモデル確率の不確定性を克服することが重要です。以下では、望ましい事前分布の設定について整理します。 事前分布に求められる性質 事前分布に求められる性質を列挙します。 ・ Location and Scale Invariance 気温や距離など、説明変数の単位や値の大きさに影響しないこと。\r・ Consistency サンプル数が極大に近づくと、ベイズファクターが適切な値に収束すること。つまり$\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}$と$\\mathcal{\\boldsymbol{M}}_ N$を比較するとき、「真の」モデルが$\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}$であるならば、$BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack \\rightarrow \\infty$に、「真の」モデルが$\\mathcal{\\boldsymbol{M}}_ N$ならば$BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack \\rightarrow 0$にそれぞれ収束すること。\r・ Consistent in Information データが、モデルの比較に用いられる値（線形回帰分析の場合、決定係数）を介してのみベイズファクターに影響すること。線形回帰分析の場合、$R^2 = 1$のとき$BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack \\rightarrow \\infty$となること。\r・ Computationally Convenience ベイズファクターが解析的に計算可能であること。ただし近年ではMCMC法やブリッジサンプリング等の推定手法が進歩しているので、必ずしもこの条件にとらわれる必要はないかもしれません。\rZellner-Siow\u0026rsquo;s Priors 前節で挙げた事前分布の望ましい性質を満たす線形回帰分析におけるパラメータの事前分布として、Zellner-Siow\u0026rsquo;s Priorsが提案されています。 ◆Zellner-Siow\u0026#39;s Priors\r$(1)$、$(2)$式の$\\boldsymbol{\\beta}_\\boldsymbol{{\\gamma}}$、$\\alpha$、$\\sigma^2$に対する事前分布である下記$(8)$～$(10)$式を、Zellner-Siow\u0026rsquo;s Priorsとよぶ。 $$ \\alpha,\\sigma^2 \\propto \\cfrac{1}{\\sigma^2} \\tag{10} $$ $$ \\boldsymbol{\\beta}_ \\boldsymbol{{\\gamma}} | \\sigma^2, g \\sim \\mathrm{Normal}\\left(\\boldsymbol{0}, g\\sigma^2\\left( \\cfrac{\\boldsymbol{X}_ \\boldsymbol{{\\gamma}}^{T} \\boldsymbol{X}_ \\boldsymbol{{\\gamma}}}{N} \\right)^{-1}\\right) \\tag{11} $$ $$ g \\sim \\mathrm{InvGamma}\\left( \\cfrac{1}{2}, \\cfrac{r}{2} \\right) \\tag{12} $$ $(10)$、$(11)$式はZellner(1986)が提案した事前分布で、Zellner\u0026rsquo;s g-Priorsと呼ばれます。この事前分布は次元のペナルティとしての役割を持つパラメータ$g$について特定の値を与える必要があり、それが前述のConsistencyを満たせない要因となっていました。一方、ZellnerとSiow(1980)が提案したZellner-Siow\u0026rsquo;s Priorsは、パラメータgについて事前分布を与えることで、事前分布の望ましい性質を満たすことに成功しています。 また、下記$(11)$式に示すように、$(10)$、$(11)$式は$\\boldsymbol{\\beta}_\\boldsymbol{{\\gamma}}$の事前分布としてコーシー分布を採用することと等価です。これは$g$について積分することで確認できます（筆者未導出）。 $$ \\begin{split} \\int_{0}^{∞} \\boldsymbol{\\beta}_\\boldsymbol{{\\gamma}} | \\sigma^2,g ~~ dg \u0026amp;=\u0026amp; \\int_{0}^{∞} \\mathrm{Normal}\\left(\\boldsymbol{0}, g\\sigma^2\\left( \\cfrac{\\boldsymbol{X}_ \\boldsymbol{{\\gamma}}^{T} \\boldsymbol{X}_ \\boldsymbol{{\\gamma}}}{N} \\right)^{-1}\\right) dg \\\\ \u0026amp;=\u0026amp; \\mathrm{Multivariate-Cauchy}\\left( \\boldsymbol{\\beta} _\\boldsymbol{\\gamma} | \\boldsymbol{0}, N r \\sigma^2 \\left( \\boldsymbol{X}_ \\boldsymbol{{\\gamma}}^{T} \\boldsymbol{X}_ \\boldsymbol{{\\gamma}} \\right) ^{-1} \\right) \\\\ \u0026amp;=\u0026amp; \\cfrac{\\Gamma\\left( \\cfrac{1 + p _\\boldsymbol{\\gamma}}{2} \\right)}{\\Gamma\\left(\\cfrac{1}{2}\\right) \\pi^{\\cfrac{p _\\boldsymbol{\\gamma}}{2}} \\left| N r \\sigma^2 \\left( \\boldsymbol{X}_ \\boldsymbol{{\\gamma}}^{T} \\boldsymbol{X}_ \\boldsymbol{{\\gamma}} \\right) ^{-1} \\right|^{\\cfrac{1}{2}} \\left( 1 + \\cfrac{1}{N r \\sigma^2} \\boldsymbol{\\beta} _\\boldsymbol{\\gamma}^{T} \\boldsymbol{X}_ \\boldsymbol{{\\gamma}}^{T} \\boldsymbol{X}_ \\boldsymbol{{\\gamma}} \\boldsymbol{\\beta} _\\boldsymbol{\\gamma} \\right)^{\\cfrac{1 + p _\\boldsymbol{\\gamma}}{2}} } \\end{split} \\tag{13} $$ ハイパーパラメータ$r$は、$\\boldsymbol{\\beta} _\\boldsymbol{\\gamma}$の事前分布（$(13)$式の多変量コーシー分布）のscale matrixの大きさを調整する役割を持ちます。Richard D. Morey氏は現在のところ$r = \\cfrac{\\sqrt{2}}{4}$を標準値として推奨しているようです。 $\\boldsymbol{\\beta} _\\boldsymbol{\\gamma}$について説明変数や応答変数のスケール等に配慮した事前分布を与えている$(11)$式の解釈は直感的です。まず$g$は各スケールについて標準化した係数パラメータの分散の意味をもちます。次に$\\sigma^2$はその値を応答変数の単位にスケーリングします。 $\\left( \\cfrac{\\boldsymbol{X}_ \\boldsymbol{{\\gamma}}^{T} \\boldsymbol{X}_ \\boldsymbol{{\\gamma}}}{N} \\right)^{-1}$ですが、これは$\\boldsymbol{X}_ \\boldsymbol{{\\gamma}}$の分散共分散行列になるので、$g$を$\\boldsymbol{X}_ \\boldsymbol{{\\gamma}}$の単位にスケーリングする役割をもちます。 ベイズファクターの計算 以降ではZellner-Siow\u0026rsquo;s Priorsをおいたときのベイズファクターの計算方法を整理します。 1変数積分近似による推定 概要を以下に示します。 ◆1変数積分近似による推定方法\rベイズファクター$BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack$ は下記の通り計算できる。 $$ BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack = \\int _{0} ^{∞}(1 + g)^{(N - 1 - p _\\boldsymbol{\\gamma})/2} \\left( 1 + \\left( 1 - R _\\boldsymbol{\\gamma}^2 \\right) g \\right)^{-(n-1)/2} \\pi(g) dg \\tag{14} $$ ここで、$\\pi(g)$は$g$の事前分布を、$R_ \\boldsymbol{\\gamma}^2$は$\\mathcal{\\boldsymbol{M}}_ \\boldsymbol{\\gamma}$での通常の線形回帰における残差の平方和、決定係数を示す。 $(14)$式の$\\pi(g)$以外の部分は、$(10)$$(11)$式で表現されるZellner\u0026rsquo;s g-Priorsにおける周辺尤度を解析的に求めることで算出されたものです。但し、Zellner\u0026rsquo;s g-Priorsはパラメータ$g$については固定値を想定していたようで、さらに$g$の事前分布$(10)$式が加わったZellner-Siow\u0026rsquo;s Priorsについては、$g$についてのみ解析的な計算が不可能となってしまっています。そのため、$(14)$式は$g$についての一変数積分が残っていますが、これはガウス求積法などの手法を使って高精度に推定することが可能です。 ちなみに、本手法を使ったベイズファクターの計算はRichard D. Morey氏らが開発しているBayesFactorパッケージのregressionBF()関数で可能です。 Savage-Dickey法による推定 Savage-Dickey法の概要を以下に示します。 ◆Savage-Dickey法による推定方法\rモデル$\\mathcal{\\boldsymbol{M}}_ {N}$と$\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}$は $$ p(\\boldsymbol{Y} | \\mathcal{\\boldsymbol{M}}_ {N} ) = p( \\boldsymbol{Y} | \\boldsymbol{\\beta}_{\\boldsymbol{\\gamma}} = \\boldsymbol{0}, \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}) \\tag{15} $$ という関係にあるため、ベイズファクター$BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack$は下記のとおり計算できる。 $$ BF\\lbrack \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}} : \\mathcal{\\boldsymbol{M}}_ {N} \\rbrack = \\cfrac{p(\\boldsymbol{\\beta}_{\\boldsymbol{\\gamma}} = \\boldsymbol{0} |\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}})}{p(\\boldsymbol{\\beta}_{\\boldsymbol{\\gamma}} = \\boldsymbol{0} | \\boldsymbol{Y}, \\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}})} \\tag{16} $$ ここで、$p(\\boldsymbol{\\beta} _{\\boldsymbol{\\gamma}} = \\boldsymbol{0} |\\mathcal{\\boldsymbol{M}} _{\\boldsymbol{\\gamma}})$はモデル$\\mathcal{\\boldsymbol{M}} _{\\boldsymbol{\\gamma}}$における$\\boldsymbol{\\beta} _{\\boldsymbol{\\gamma}}$の事前分布の$\\boldsymbol{\\beta} _{\\boldsymbol{\\gamma}}=\\boldsymbol{0}$での確率密度を示す。 同様に$p(\\boldsymbol{\\beta} _{\\boldsymbol{\\gamma}} = \\boldsymbol{0} | \\boldsymbol{Y}, \\mathcal{\\boldsymbol{M}} _{\\boldsymbol{\\gamma}})$はモデル$\\mathcal{\\boldsymbol{M}} _{\\boldsymbol{\\gamma}}$における$\\boldsymbol{\\beta} _{\\boldsymbol{\\gamma}}$の事後分布の$\\boldsymbol{\\beta} _{\\boldsymbol{\\gamma}}=\\boldsymbol{0}$での確率密度を示す。 $(11)$式より、 $$ p(\\boldsymbol{\\beta}_ {\\boldsymbol{\\gamma}} = \\boldsymbol{0} |\\mathcal{\\boldsymbol{M}}_ {\\boldsymbol{\\gamma}}) = \\cfrac{\\Gamma\\left(\\cfrac{p_\\boldsymbol{\\gamma}+1}{2}\\right)}{ \\pi^{\\cfrac{p_\\boldsymbol{\\gamma}+1}{2}} \\left| N r \\sigma^2 \\left( \\boldsymbol{X}_ \\boldsymbol{\\gamma}^T \\boldsymbol{X}_ \\boldsymbol{\\gamma}\\right) ^{-1} \\right|^{-\\cfrac{1}{2}}} $$ であることは明らかですから、あとは、$p(\\boldsymbol{\\beta} _\\boldsymbol{\\gamma} = \\boldsymbol{0} | \\boldsymbol{Y}, \\mathcal{\\boldsymbol{M}} _\\boldsymbol{\\gamma})$をどうやって求めるかが問題です。 ここでは、以前の記事でも採用したConditional Marginal Density Estimator(CMDE) を使って$p(\\boldsymbol{\\beta} _{\\boldsymbol{\\gamma}} = \\boldsymbol{0} | \\boldsymbol{Y}, \\mathcal{\\boldsymbol{M}} _{\\boldsymbol{\\gamma}})$を推定する方法を提案します。 ◆線形回帰分析のCMDE\r条件付事後分布$p(\\boldsymbol{\\beta} _{\\boldsymbol{\\gamma}} = \\boldsymbol{0} | \\boldsymbol{Y}, \\mathcal{\\boldsymbol{M}} _{\\boldsymbol{\\gamma}})$は以下である。 $$ p(\\boldsymbol{\\beta} _{\\boldsymbol{\\gamma}} = \\boldsymbol{0} | \\boldsymbol{Y}, \\mathcal{\\boldsymbol{M}} _{\\boldsymbol{\\gamma}}) = \\mathrm{Normal}\\left(\\cfrac{1}{\\sigma^2}\\Sigma \\boldsymbol{X} _{\\boldsymbol{\\gamma}}^{T} \\boldsymbol{Y}, \\Sigma \\right) \\tag{17} $$ ここで、 $$ \\Sigma = \\cfrac{\\sigma^2}{1+\\cfrac{1}{g}} \\left(\\boldsymbol{X}_ {\\boldsymbol{\\gamma}}^{T}\\boldsymbol{X}_ {\\boldsymbol{\\gamma}} \\right)^{-1} \\tag{18} $$ ※上記の証明はストレートかつ冗長なので割愛します。自分で導出したい人はこちらが大いに参考になります。 まとめ 本記事では以下の内容について整理しました。 ベイズファクターを使ったモデル確率の更新 ベイズファクターを計算する際に求められる事前分布の性質 線形回帰モデルにおいて提案された適切な事前分布 実践編はこちらです。ベイズファクターを実際に算出し、モデルをどのように評価できるのか見ていきます。 さらにこちらの記事ではベイズファクターを推定するための手法を複数実践しているので、読んでみてください。"
  },
  {
    url: "https://sucre-stat.com/tags/%E5%9B%9E%E5%B8%B0/",
    title: "回帰",
    date: "2021-10-08T00:00:00Z",
    body: "回帰"
  },
  {
    url: "https://sucre-stat.com/2021/06/bayesian-hypothesis-testing-2practice/",
    title: "ベイズファクターを用いた仮説検定を実践する～平均値の差の検定～",
    date: "2021-06-21T00:00:00Z",
    body: "ベイズファクターを用いた仮説検定を実践する～平均値の差の検定～ ◆この記事のテーマ\rベイズファクターを使って平均値の差を検定する方法を実践します。 この手法は、例えば下図のようなシーンに適用できます。下図左側では、交通事故対策Aの実施前と実施後の単位時間あたり事故発生件数のデータを蓄積し、対策前後で事故発生件数の平均値に差があるかを検定しています。また、下図右側では交通事故対策Aが実施された交差点と実施されていない交差点の単位時間あたり事故発生件数の平均値に差があるかを検定しています。 ※上記の事例は整数データであるからポアソン分布や負の二項分布等を使用するのが理想ですが、ここでは事故発生件数の平均値が十分大きく正規近似が可能であると仮定します。 ※左側は対応のある（one-sample）グループ間の検定、右側は対応のない（two-sampe）グループ間の検定です。設定上、後者の設計では対策実施効果以外の要因（異なる交差点を比較に用いることによるランダム効果）が結果に絡む可能性が高くなるので、対策Aの効果を確かめることが分析の目的であれば前者の対応のある検定の設計がより望ましいといえます。 方針 理論編で整理した内容の再現を基本とします。ゆえに断りなく理論編で用いた変数を使用します。 事前分布はJZSの事前分布のみ試します。というものこの理論の先駆者であるRichard D. Moreyさんが開発しているBayesFactorパッケージではJZSの事前分布を用いており、氏もこちらを推しているようなので。 本記事で検証する仮説は以下3組です。$\\delta$はスケーリングされた平均値の差と解釈できる値で、ベイズ版平均値の差の検定で着目する値になります。 両側検定に対応する仮説\r$$\r\\begin{cases}\rH_0:\\delta=0 \\\\\\\\\rH_1:\\delta \\neq 0\r\\end{cases}\r$$\r 片側検定に対応する仮説\r$$\r\\begin{cases}\rH_0:\\delta=0\\\\\\\\\rH_{1PO}:\\delta \\leq 0　\\\\\\\\\rH_{1NO}:\\delta \\geq 0\r\\end{cases}\r$$\r※$PO$はpositive orderedの略、$NO$はnegatie orderedの略\r 2つの範囲仮説を検証する場合\r$A = \\{ \\delta:\\delta_l 対応のある検定を実践 サンプルデータの可視化 データはこちらよりダウンロードできます。d$preは対策A実施前の交差点における事故発生件数、d$proは対策A実施後の交差点における事故発生件数とします。 load(\u0026#34;data.RData\u0026#34;) head(d) ## pre pro ## 1 32 38 ## 2 25 26 ## 3 29 33 ## 4 30 25 ## 5 31 30 ## 6 32 33 これらの差をとり、可視化してみます。 視覚的にはなんと対策前の事故件数の方が多そうです。しかし可視化で分かるのは「多そう」に留まってしまいます。対策前の事故件数の方が本当に多いと言えるのか、さらに深掘ってみましょうか。 可視化コードはこちら。 p \u0026lt;- d %\u0026gt;% as.data.frame() %\u0026gt;% mutate(D = pre - pro ) %\u0026gt;% select(D) %\u0026gt;% ggplot(aes(x=D)) + geom_histogram(breaks=seq(min(d$pre-d$pro)+0.5,max(d$pre-d$pro)+0.5,1), fill=\u0026#34;#4169e1\u0026#34;) + theme_light(base_size=12) + xlab(\u0026#34;pre - pro\u0026#34;) + ylab(NULL) 両側検定 memo\r\r筆者は本分析よりStanの実行環境を「Windows + Rstudio Desktop + rstan」から「Ubuntu(Linux) + Rstudio Server + cmdstanr」に移行しました。\rrコード・Stanコードとも現在のrstanではエラーが起きるので留意を。\r Stanコードを示します。 //model1.stan //One-sample t-test data{ int N; //Common sample size array[2] vector[N] D_raw; //Raw data real\u0026lt;lower=0\u0026gt; r, Jeffreys_alpha, Jeffreys_beta; //r:scale factor //Jeffreys_alpha : mean of prior(sigma^2) (sufficiently small values) //Jeffreys_beta : variance of prior(sigma^2) (sufficiently small values) } transformed data{ vector[N] D; //X - Y D = D_raw[1] - D_raw[2]; } parameters{ real delta; //effect size real\u0026lt;lower=0\u0026gt; sigma, g; } model{ //Likelihood target += normal_lpdf(D | delta * sigma, sigma); //JZS prior target += normal_lpdf(delta | 0, sqrt(g)); target += inv_gamma_lpdf(g | 0.5 , (r^2)*0.5); target += gamma_lpdf(sigma^2 | Jeffreys_alpha, Jeffreys_beta); } generated quantities{ real mean_delta, variance_delta; //mean_delta:mean of CMDE(delta) //variance_delta:variance of CMDE(delta) real BF_01; // real BF_10; real logPostDensDelta, logPriorDensDelta; //logPostDensDelta:p(delta=0 | prior) //logPostDensDelta:p(delta=0 | posterior) mean_delta = sum(D) / (sigma * (N + (1 / g))); variance_delta = 1 / (N + (1 / g)); logPostDensDelta = -0.5 * log(pi() * variance_delta * 2) - 0.5 * mean_delta^2 / variance_delta; logPriorDensDelta = -log(pi() * r); BF_01 = exp(logPostDensDelta - logPriorDensDelta); //BF_10 = exp(logPriorDensDelta - logPostDensDelta); } 筆者の見解では、$BF_{01}$及び$BF_{10}$のうち、1より小さい値をとる方をgenerated quatities{}で推定するのが精度の都合上よさそうです。というのも1より大きい値をとると考えられる$BF$は、正の方向に分布の裾が重くなってしまい、平均値が大きい値に引っ張られてしまうから。また$\\mathbb{E}[BF_{01}] = \\cfrac{1}{\\mathbb{E}[BF_{10}]}$は成り立たないので、$BF_{01}$と$BF_{10}$のMCMCサンプルを同時に得ることもおすすめしません。データに応じてreal BF_01 とreal BF_10を使い分けましょう。 これを走らせるコードが以下です。 library(cmdstanr) library(rstan) library(tidyverse) stan_data \u0026lt;- list(D_raw=t(d), N = nrow(d), r =sqrt(2)/2, Jeffreys_alpha=1e-10, Jeffreys_beta=1e-10) model1_c \u0026lt;- cmdstan_model(\u0026#34;/model/model1.stan\u0026#34;) fit_c1 \u0026lt;- model1_c$sample( data = stan_data, parallel_chains = 4, chains = 4, iter_warmup = 1000, iter_sampling = 20000 ) 収束を確認し、ベイズファクターを計算しましょう。 stanfit1 \u0026lt;- rstan::read_stan_csv(fit_c1$output_files()) print(stanfit1) ## Inference for Stan model: model1-202106190132-1-6686ed. ## 4 chains, each with iter=21000; warmup=1000; thin=1; ## post-warmup draws per chain=20000, total post-warmup draws=80000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## delta 0.27 0.00 0.10 0.07 0.20 0.27 0.34 0.47 62133 1 ## sigma 8.15 0.00 0.58 7.11 7.75 8.12 8.53 9.39 58529 1 ## g 3.49 0.81 217.23 0.08 0.21 0.42 1.00 11.79 71142 1 ## mean_delta 0.27 0.00 0.02 0.23 0.26 0.27 0.29 0.31 62414 1 ## variance_delta 0.01 0.00 0.00 0.01 0.01 0.01 0.01 0.01 75686 1 ## BF_01 0.23 0.00 0.13 0.06 0.13 0.20 0.29 0.54 54358 1 ## logPostDensDelta -2.44 0.00 0.56 -3.62 -2.80 -2.41 -2.05 -1.42 61613 1 ## logPriorDensDelta -0.80 0.00 0.00 -0.80 -0.80 -0.80 -0.80 -0.80 2 1 ## lp__ -379.97 0.01 1.28 -383.31 -380.56 -379.64 -379.03 -378.50 32010 1 ## ## Samples were drawn using NUTS(diag_e) at Sat Jun 19 01:32:05 2021. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). ms1 \u0026lt;- as.matrix(stanfit1) res1 \u0026lt;- ms1 %\u0026gt;% as.data.frame() %\u0026gt;% select(starts_with(\u0026#34;BF\u0026#34;)) %\u0026gt;% summarise_all(list(mean = mean)) %\u0026gt;% summarise_all(list(round),digits=8) %\u0026gt;% pivot_longer(everything()) cat(sprintf(\u0026#34;Bayesfactor is\\n\\tBF_01:%.8f\\tBF_10:%.8f\u0026#34;,res1$value, 1 / res1$value)) ## Bayesfactor is ## BF_01:0.22509123\tBF_10:4.44264310 Rhatで収束を確認。結果は $$ \\begin{cases} BF_{01} \\fallingdotseq 0.225　\\\\ BF_{10} \\fallingdotseq 4.443 \\end{cases} $$ となりました。Kass and Raftery(1995)の評価基準では、$H_0$に対する反証の強さは十分であると判断できます。つまり、$\\delta = 0$を棄却し$\\delta \\neq 0$を採択し、対策後の事故件数は対策前から変化したと判断してよさそうです。 $BF_{01}$の分布も確認しておきましょう。 plot_title \u0026lt;- ggtitle(\u0026#34;Posterior distribution of BF_01\u0026#34;, \u0026#34;with mean and 80% interval\u0026#34;) p \u0026lt;- mcmc_areas(ms1, pars = c(\u0026#34;BF_01\u0026#34;), prob = 0.8, point_est = c(\u0026#34;mean\u0026#34;)) + geom_text(data=res1[2], aes(x=value, y=\u0026#34;BF_01\u0026#34;, label=value), nudge_y =-0.03) + plot_title 一応、以上の結果がまともなのかどうか、BayesFactorパッケージで確認します。 library(BayesFactor) bf \u0026lt;- ttestBF(x=d$pre, y=d$pro, paired=T) bf ## Bayes factor analysis ## -------------- ## [1] Alt., r=0.707 : 4.297253 ±0% ## ## Against denominator: ## Null, mu = 0 ## --- ## Bayes factor type: BFoneSample, JZS 1 / bf ## Bayes factor analysis ## -------------- ## [1] Null, mu=0 : 0.2327068 ±0% ## ## Against denominator: ## Alternative, r = 0.707106781186548, mu =/= 0 ## --- ## Bayes factor type: BFoneSample, JZS BayesFactor::ttestBF()による結果は、 $$ \\begin{cases} BF_{01} \\fallingdotseq 0.233　\\\\ BF_{10} \\fallingdotseq 4.297 \\end{cases} $$ でした。概ね俺の実装による結果と整合してそうです。 片側検定 間髪を入れず片側検定に移ります。モデル構成は両側検定のときから変わらないので、先ほど得たMCMCサンプルをこねくり回します。 $H_{1PO}$、$H_{1NO}$に対応するモデルをそれぞれ$M_{1PO}$、$M_{1NO}$とおくと、 $$ \\begin{cases} p(\\delta = 0 | M_{1NO}) = p(\\delta = 0 | M_{1PO}) = \\cfrac{2}{\\pi r} \\\\ p(\\delta=0 | \\mathcal{D}, M_{1PO}) = \\cfrac{p(\\delta=0 | \\mathcal{D}, M_1)}{\\Phi(0 | \\mu_{\\delta}, \\sigma_{\\delta})} \\eqsim \\cfrac{1}{T} \\sum_{t=1}^{T} \\cfrac{p(\\delta=0 | \\boldsymbol{\\psi}^{(t)},\\mathcal{D},M_1)}{\\Phi(0 | \\mu_{\\delta}^{(t)}, \\sigma_{\\delta}^{(t)})} \\\\ p(\\delta=0 | \\mathcal{D}, M_{1NO}) = \\cfrac{p(\\delta=0 | \\mathcal{D}, M_1)}{1 - \\Phi(0 | \\mu_{\\delta}, \\sigma_{\\delta})} \\eqsim \\cfrac{1}{T} \\sum_{t=1}^{T} \\cfrac{p(\\delta=0 | \\boldsymbol{\\psi}^{(t)},\\mathcal{D},M_1)}{1 - \\Phi(0 | \\mu_{\\delta}^{(t)}, \\sigma_{\\delta}^{(t)})} \\\\ \\end{cases} $$ だから、Savage-Dickey法より $$ BF_{01PO} = \\cfrac{p(\\delta=0 | \\mathcal{D}, M_{1PO})}{p(\\delta=0 | M_{1PO})} \\eqsim \\cfrac{\\pi r}{2} \\cfrac{1}{T} \\sum_{t=1}^{T} \\cfrac{p(\\delta=0 | \\boldsymbol{\\psi}^{(t)},\\mathcal{D},M_1)}{\\Phi(0 | \\mu_{\\delta}^{(t)}, \\sigma_{\\delta}^{(t)})} = \\cfrac{1}{T} \\sum_{t=1}^{T}\\cfrac{BF_{01}^{(t)}}{2\\Phi(0 | \\mu_{\\delta}^{(t)}, \\sigma_{\\delta}^{(t)}) } $$ $$ BF_{01NO} = \\cfrac{p(\\delta=0 | \\mathcal{D}, M_{1NO})}{p(\\delta=0 | M_{1NO})} \\eqsim \\cfrac{\\pi r}{2} \\cfrac{1}{T} \\sum_{t=1}^{T} \\cfrac{p(\\delta=0 | \\boldsymbol{\\psi}^{(t)},\\mathcal{D},M_1)}{1 - \\Phi(0 | \\mu_{\\delta}^{(t)}, \\sigma_{\\delta}^{(t)})} = \\cfrac{1}{T} \\sum_{t=1}^{T}\\cfrac{BF_{01}^{(t)}}{2\\left(1 - \\Phi(0 | \\mu_{\\delta}^{(t)}, \\sigma_{\\delta}^{(t)})\\right) } $$ です(*´Д`)ﾊｧﾊｧ。 res_ordered \u0026lt;- ms1 %\u0026gt;% data.frame() %\u0026gt;% mutate(BF_01_NO = BF_01 / (2 * (1-pnorm(0, mean=mean_delta, sd=sqrt(variance_delta)))), BF_01_PO = BF_01 / (2 * pnorm(0, mean=mean_delta, sd=sqrt(variance_delta))), BF_10_NO = (2 * (1-pnorm(0, mean=mean_delta, sd=sqrt(variance_delta))) / BF_01), BF_10_PO = (2 * pnorm(0, mean=mean_delta, sd=sqrt(variance_delta)))/ BF_01) %\u0026gt;% summarise(BF_01_NO = mean(BF_01_NO), BF_01_PO = mean(BF_01_PO), BF_10_NO = mean(BF_10_NO), BF_10_PO = mean(BF_10_PO)) res_ordered ## BF_01_NO BF_01_PO BF_10_NO BF_10_PO ## 1 0.1130584 34.61659 12.16943 0.02898778 # 推定精度の良い（BF\u0026lt;1となる）方を用いる cat(sprintf(\u0026#34;Bayesfactor is\\n\\tBF_01_NO:%.8f\\tBF_10_NO:%.8f\\n\\tBF_01_PO:%.8f\\tBF_10_PO:%.8f\u0026#34;, res_ordered$BF_01_NO, 1 / res_ordered$BF_01_NO, 1 /res_ordered$BF_10_PO, res_ordered$BF_10_PO)) ## Bayesfactor is ## BF_01_NO:0.11305844\tBF_10_NO:8.84498327 ## BF_01_PO:34.49729577\tBF_10_PO:0.02898778 結果は $$ \\begin{cases} BF_{01PO} \\fallingdotseq 34.497 \\\\ BF_{10PO} \\fallingdotseq 0.029 \\\\ BF_{01NO} \\fallingdotseq 0.113 \\\\ BF_{10NO} \\fallingdotseq 8.845 \\\\ \\end{cases} $$ でした。Kass and Raftery(1995)の評価基準では、$H_{1PO}$に反する証拠は強く、$H_{0NO}$に反する証拠は十分にあると判断できます。つまり、$\\delta \\leq 0$と$\\delta=0$の比較では$\\delta=0$が採択されることから、事故件数平均値は対策後増加していないと判断され、さらに$\\delta \\geq 0$と$\\delta=0$の比較では$\\delta \\geq 0$が採択されることから、やはり対策後の事故件数の平均値は減少したのだと判断されます。 BayesFactorパッケージとの整合を確認します。 # bayesfactorパッケージでordered restrictionのベイズファクターを計算 bf \u0026lt;- ttestBF(x=d$pre, y=d$pro, nullInterval = c(0,Inf) ,paired=T) bf ## Bayes factor analysis ## -------------- ## [1] Alt., r=0.707 0\u0026lt;d\u0026lt;Inf : 8.564529 ±0% ## [2] Alt., r=0.707 !(0\u0026lt;d\u0026lt;Inf) : 0.02997665 ±0.01% ## ## Against denominator: ## Null, mu = 0 ## --- ## Bayes factor type: BFoneSample, JZS 1/bf ## denominator ## numerator Alt., r=0.707 0\u0026lt;d\u0026lt;Inf Alt., r=0.707 !(0\u0026lt;d\u0026lt;Inf) ## Null, mu=0 0.1167606 33.35929 BayesFactor::ttestBF()による結果は、 $$ \\begin{cases} BF_{01PO} \\fallingdotseq 33.359 \\\\ BF_{10PO} \\fallingdotseq 0.030 \\\\ BF_{01NO} \\fallingdotseq 0.117 \\\\ BF_{10NO} \\fallingdotseq 8.565 \\\\ \\end{cases} $$ でした。やはり俺の実装による結果と整合しているな(；´Д｀)ｽｯ､ｽﾊﾞﾗｽｨ \u0026hellip;ﾊｧﾊｧ。 2つの範囲仮説を検証 範囲仮説については理論編でもこれまでも説明していませんでした。Richard D. Morey氏らの論文で説明されているもので、帰無仮説が$\\delta$のパラメータ空間上の1点ではなく、一定の範囲をもつ場合になります。微小な平均値の差は効果が無いに等しいものとして扱いたいときに有効な方法です。 範囲仮説同士のベイズファクターは、両仮説に対応するモデル$M_0$、$M_1$を包含したモデル（encompassing model）$M_E$を設定すれば、 $$ BF_{01} = \\cfrac{p( \\mathcal{D} | \\delta \\in A, M_E )}{p(\\mathcal{D} | \\delta \\notin A, M_E )} = \\left. \\cfrac{p( \\delta \\in A | \\mathcal{D},M_E)}{p(\\delta \\notin A| \\mathcal{D}, M_E)} \\middle/ \\cfrac{p( \\delta \\in A | M_E)}{p(\\delta \\notin A | M_E)} \\right. $$ と計算できます。 このうち、事前分布の範囲確率$p( \\delta \\notin A| \\mathcal{D}, M_E)$、$p(\\delta \\in A| \\mathcal{D}, M_E)$はまがうことなきClosed formで計算できるとして、引っかかるのが尤度$p(\\delta \\in A | \\mathcal{D}, M_E)$、$p(\\delta \\notin A | \\mathcal{D}, M_E)$です。要は$\\delta$の累積分布関数を$\\Phi(\\delta)$とおいて、 $$ \\begin{cases} p(\\delta \\in A | \\mathcal{D}, M_E) \\eqsim \\cfrac{1}{T} \\sum_{t=1}^{T} \\left( \\Phi(\\delta_u | \\mu_{\\delta}^{(t)}, \\sigma_{\\delta}^{(t)}) - \\Phi(\\delta_l | \\mu_{\\delta}^{(t)}, \\sigma_{\\delta}^{(t)}) \\right) \\\\ p(\\delta \\notin A | \\mathcal{D}, M_E) \\eqsim 1 - p(\\delta \\in A | \\mathcal{D}, M_E) \\end{cases} $$ を計算すればいいのですが、$\\delta$の密度関数の平均$\\mu_{\\delta}^{(t)}$、分散$\\sigma_{\\delta}^{(t)}$を精度よく推定してやる工夫が必要と考えられます。 しかしこれも理論編をしっかり抑えていれば、理論編$(18)$式、$(20)$式を用いてやればよいと分かるはずです(*´Д`)ﾊｧﾊｧ。 これもモデル構成は両側検定のときから変わらないので、両側検定のMCMCサンプルをこねくり回します。2つの仮説の境界は$\\delta_l = -2 / \\sigma$、 $\\delta_u \u0026lt; -2 / \\sigma$、つまり事故発生件数$\\pm2$程度の微小な増減は無視したいという志向で仮説を設定します。 # Area null upper_effect \u0026lt;- 2 lower_effect \u0026lt;- -2 r \u0026lt;- stan_data$r res_Area \u0026lt;- ms1 %\u0026gt;% data.frame() %\u0026gt;% mutate(upper_delta = upper_effect / sigma, lower_delta = lower_effect / sigma,postAreadelta = pnorm(upper_delta, mean=mean_delta, sd=sqrt(variance_delta)) -pnorm(lower_delta, mean=mean_delta, sd=sqrt(variance_delta)), priorAreadelta = pcauchy(upper_delta, 0, r) - pcauchy(lower_delta, 0, r)) %\u0026gt;% mutate(BF_10_Area = (1-postAreadelta) / postAreadelta / ((1-priorAreadelta) / priorAreadelta)) %\u0026gt;% summarise(BF_10_Area = mean(BF_10_Area)) %\u0026gt;% mutate(BF_01_Area = 1 / BF_10_Area) ## res_Area \u0026lt;- ms1 %\u0026gt;% data.frame() %\u0026gt;% ## mutate(upper_delta = upper_effect / sigma, lower_delta = lower_effect / sigma,postAreadelta = pnorm(upper_delta, mean=mean_delta, sd=sqrt(variance_delta)) -pnorm(lower_delta, mean=mean_delta, sd=sqrt(variance_delta)), ## priorAreadelta = pcauchy(upper_delta, 0, r) - pcauchy(lower_delta, 0, r)) %\u0026gt;% ## mutate(BF_01_Area = postAreadelta/(1-postAreadelta) / (priorAreadelta/(1-priorAreadelta))) %\u0026gt;% ## summarise(BF_01_Area = mean(BF_01_Area)) %\u0026gt;% mutate(BF_10_Area = 1 / BF_01_Area) res_Area ## BF_10_Area BF_01_Area ## 1 0.4152557 2.408155 結果は、 $$ \\begin{cases} BF_{01Area} \\fallingdotseq 2.408 \\\\ BF_{10Area} \\fallingdotseq 0.415 \\\\ \\end{cases} $$ となりました。$H_{0Area}$の方が支持されるものの、Kass and Raftery(1995)の評価基準では、$H_{1Area}$に反する証拠は十分でないと判断されます。つまり、$\\pm2$以上の事故件数の増減はなかったといえそうだが、その証拠は十分ではない、ということです。 BayesFactorパッケージとの整合を確認します。 X \u0026lt;- scale(d$pre - d$pro) bf \u0026lt;- ttestBF(x=d$pre, y=d$pro, nullInterval = c(-2,2)/attr(X, \u0026#34;scaled:scale\u0026#34;) ,paired=T) bf[1]/bf[2] ## Bayes factor analysis ## -------------- ## [1] Alt., r=0.707 -0.245057417614946\u0026lt;d\u0026lt;0.245057417614946 : 2.472662 ±0% ## ## Against denominator: ## Alternative, r = 0.707106781186548, mu =/= 0 !(-0.245057417614946\u0026lt;d\u0026lt;0.245057417614946) ## --- ## Bayes factor type: BFoneSample, JZS bf[2]/bf[1] ## Bayes factor analysis ## -------------- ## [1] Alt., r=0.707 !(-0.245057417614946\u0026lt;d\u0026lt;0.245057417614946) : 0.4044224 ±0% ## ## Against denominator: ## Alternative, r = 0.707106781186548, mu =/= 0 -0.245057417614946\u0026lt;d\u0026lt;0.245057417614946 ## --- ## Bayes factor type: BFoneSample, JZS BayesFactor::ttestBF()による結果は、 $$ \\begin{cases} BF_{01Area} \\fallingdotseq 2.473 \\\\ BF_{10Area} \\fallingdotseq 0.404 \\\\ \\end{cases} $$ やはり俺の実装はうまくいってそうだ(；´Д｀)ｽｯ､ｽﾊﾞﾗｽｨ \u0026hellip;ﾊｧﾊｧ。 対応のない検定を実践 対応のない検定は、尤度が異なる点を除き対応のある検定と同じです。 サンプルデータの可視化 データは対応のある検定のときと同じものを用います。命名と実際の意味が少し異なっていて分かりづらいですが、d$preは対策A未実施の交差点における事故発生件数、d$proは対策A実施済みの交差点における事故発生件数とします。 視覚化はこんな感じです。 可視化コードはこちら。 p1 \u0026lt;- ggplot(data.frame(X = d$pre), aes(x=X)) + theme_light(base_size=12) + geom_histogram(breaks=seq(min(c(d$pre,d$pro)), max(c(d$pre,d$pro)), 1), fill=\u0026#34;#ffb6c1\u0026#34;) + xlab(\u0026#34;pre\u0026#34;) + ylab(NULL) p2 \u0026lt;- ggplot(data.frame(X = d$pro), aes(x=X)) + theme_light(base_size=12) + geom_histogram(breaks=seq(min(c(d$pre,d$pro)), max(c(d$pre,d$pro)), 1), fill=\u0026#34;#90ee90\u0026#34;) + xlab(\u0026#34;pro\u0026#34;) + ylab(NULL) library(gridExtra) p \u0026lt;- grid.arrange(p1,p2, nrow=2) 両側検定 Stanコードは以下のとおり。 //model2.stan //Two-sample t-test data{ int N; //sample size og group1 int M; //sample size of group2 vector[N] D1; //data of group1 vector[M] D2; //data of group2 real\u0026lt;lower=0\u0026gt; r, Jeffreys_alpha, Jeffreys_beta; //r:scale factor //Jeffreys_alpha:mean of prior(sigma^2) (sufficiently small values) //Jeffreys_beta:variance of prior(sigma^2) (sufficiently small values) } parameters{ real delta, mu; //delta:effect size mu:overall mean real\u0026lt;lower=0\u0026gt; sigma, g; } model{ //Likelihood target += normal_lpdf(D1 | mu - delta * sigma / 2, sigma); target += normal_lpdf(D2 | mu + delta * sigma / 2, sigma); //JZS prior target += normal_lpdf(delta | 0, sqrt(g)); target += inv_gamma_lpdf(g | 0.5 , (r^2)*0.5); target += gamma_lpdf(sigma^2 | Jeffreys_alpha, Jeffreys_beta); } generated quantities{ real mean_delta, variance_delta; //mean_delta:mean of CMDE(delta) //variance_delta:variance of CMDE(delta) real BF_01; // real BF_10; real logPostDensDelta, logPriorDensDelta; //logPostDensDelta:p(delta=0 | prior) //logPostDensDelta:p(delta=0 | posterior) mean_delta = 2 * g * (sum(D2) - sum(D1) + (N - M) * mu ) / ((4 + ( N + M ) * g ) * sigma); variance_delta = 4 * g / (4 + (N + M) * g); logPostDensDelta = -0.5 * log(pi() * variance_delta * 2) - 0.5 * mean_delta^2 / variance_delta; logPriorDensDelta = -log(pi() * r); BF_01 = exp(logPostDensDelta - logPriorDensDelta); //BF_10 = exp(logPriorDensDelta - logPostDensDelta); } これを走らせるRコードはこちら。 stan_data \u0026lt;- list(D1=d$pro, D2=d$pre, N = length(d$pro), M = length(d$pre), r =sqrt(2)/2, Jeffreys_alpha=1e-10, Jeffreys_beta=1e-10) model2_c \u0026lt;- cmdstan_model(\u0026#34;/model/model2.stan\u0026#34;) fit_c_area \u0026lt;- model3_c$sample( data = stan_data, parallel_chains = 4, chains = 4, iter_warmup = 500, iter_sampling = 2000 ) 以降のコードは対応のある場合と基本的に同じなので、結果だけ載せていきますね　|ω·`) ## Inference for Stan model: model3-202106202142-1-61dec5. ## 4 chains, each with iter=2500; warmup=500; thin=1; ## post-warmup draws per chain=2000, total post-warmup draws=8000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## delta 0.39 0.00 0.14 0.12 0.29 0.39 0.48 0.66 8173 1 ## mu 30.28 0.00 0.39 29.53 30.02 30.28 30.55 31.07 7252 1 ## sigma 5.60 0.00 0.28 5.09 5.40 5.58 5.78 6.17 7184 1 ## g 3.59 0.93 67.27 0.09 0.23 0.47 1.13 13.19 5182 1 ## mean_delta 0.39 0.00 0.03 0.32 0.37 0.39 0.41 0.44 7823 1 ## variance_delta 0.02 0.00 0.00 0.02 0.02 0.02 0.02 0.02 8608 1 ## BF_01 0.14 0.00 0.07 0.05 0.09 0.12 0.17 0.31 6952 1 ## logPostDensDelta -2.88 0.01 0.46 -3.79 -3.19 -2.89 -2.58 -1.97 7593 1 ## lp__ -655.90 0.02 1.44 -659.60 -656.61 -655.56 -654.83 -654.11 3423 1 ## logPriorDensDelta -0.80 0.00 0.00 -0.80 -0.80 -0.80 -0.80 -0.80 2 1 ## ## Samples were drawn using NUTS(diag_e) at Sun Jun 20 21:42:05 2021. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). ## Bayesfactor is ## BF_01:0.13800334\tBF_10:7.24620143 結果は $$ \\begin{cases} BF_{01} \\fallingdotseq 0.138 \\\\ BF_{10} \\fallingdotseq 7.246 \\\\ \\end{cases} $$ です。よって$H_1$を採択し、2グループ間の事故件数には差があると判断されます。 BayesFactorパッケージの場合は、 bf \u0026lt;- ttestBF(x=d$pre, y=d$pro, paired=F) bf ## Bayes factor analysis ## -------------- ## [1] Alt., r=0.707 : 7.149843 ±0% ## ## Against denominator: ## Null, mu1-mu2 = 0 ## --- ## Bayes factor type: BFindepSample, JZS 1 / bf ## Bayes factor analysis ## -------------- ## [1] Null, mu1-mu2=0 : 0.1398632 ±0% ## ## Against denominator: ## Alternative, r = 0.707106781186548, mu =/= 0 ## --- ## Bayes factor type: BFindepSample, JZS $$ \\begin{cases} BF_{01} \\fallingdotseq 0.140 \\\\ BF_{10} \\fallingdotseq 7.150 \\\\ \\end{cases} $$ ほぼ一致Σ(ﾟДﾟ)ｽｹﾞｪ! 片側検定 ## Bayesfactor is ## BF_01_NO:0.06924356\tBF_10_NO:14.44177639 ## BF_01_PO:25.05332284\tBF_10_PO:0.03991487 俺の実装による結果は $$ \\begin{cases} BF_{01PO} \\fallingdotseq 25.053 \\\\ BF_{10PO} \\fallingdotseq 0.040 \\\\ BF_{01NO} \\fallingdotseq 0.069 \\\\ BF_{10NO} \\fallingdotseq 14.442 \\\\ \\end{cases} $$ 今回の実装で$\\delta$は「未対策の交差点における事故件数の平均値」-「対策済みの交差点における事故件数の平均値」の値です。まず$H_{0PO}$が強く採択されることから、「対策済み」グループのほうが「未対策」グループよりも事故件数の平均値が多い、ということはないと判断できます。さらに、$H_{1NO}$が採択されることから、「未対策」グループのほうが「対策済み」グループよりも事故件数の平均値が多いと言えると判断できます。 bf \u0026lt;- ttestBF(x=d$pre, y=d$pro, nullInterval = c(0,Inf) ,paired=F) bf ## Bayes factor analysis ## -------------- ## [1] Alt., r=0.707 0\u0026lt;d\u0026lt;Inf : 14.25912 ±0% ## [2] Alt., r=0.707 !(0\u0026lt;d\u0026lt;Inf) : 0.04056425 ±0.17% ## ## Against denominator: ## Null, mu1-mu2 = 0 ## --- ## Bayes factor type: BFindepSample, JZS 1/bf ## denominator ## numerator Alt., r=0.707 0\u0026lt;d\u0026lt;Inf Alt., r=0.707 !(0\u0026lt;d\u0026lt;Inf) ## Null, mu1-mu2=0 0.07013055 24.65225 パッケージによる結果は $$ \\begin{cases} BF_{01PO} \\fallingdotseq 24.652 \\\\ BF_{10PO} \\fallingdotseq 0.041 \\\\ BF_{01NO} \\fallingdotseq 0.070 \\\\ BF_{10NO} \\fallingdotseq 14.259 \\\\ \\end{cases} $$ ほぼ一致…(；´Д｀)ｽｯ､ｽﾊﾞﾗｽｨ \u0026hellip;ﾊｧﾊｧ 2つの範囲仮説を検証 対応のある場合と同様、2つの仮説の境界は$\\delta_l = -2 / \\sigma$、 $\\delta_u \u0026lt; -2 / \\sigma$とします。 BF_10_Area BF_01_Area 1 0.5996078 1.667757 俺の実装による結果は、 $$ \\begin{cases} BF_{01Area} \\fallingdotseq 1.668 \\\\ BF_{10Area} \\fallingdotseq 0.600 \\\\ \\end{cases} $$ よって、$H_{0Area}$の方がデータの説明力は高いものの、決定的でないことが分かります。つまりグループ間に$\\pm2$以上の事故件数の平均値の差はないといえそうだが、その証拠は十分ではない、ということです。 X \u0026lt;- scale(c(d$pre,d$pro)) attr(X, \u0026#34;scaled:scale\u0026#34;) bf \u0026lt;- ttestBF(x=d$pre, y=d$pro, nullInterval = c(-2,2)/attr(X, \u0026#34;scaled:scale\u0026#34;) ,paired=F) bf[1]/bf[2] ## Bayes factor analysis ## -------------- ## [1] Alt., r=0.707 -0.351290094235453\u0026lt;d\u0026lt;0.351290094235453 : 1.638839 ±0% ## ## Against denominator: ## Alternative, r = 0.707106781186548, mu =/= 0 !(-0.351290094235453\u0026lt;d\u0026lt;0.351290094235453) ## --- ## Bayes factor type: BFindepSample, JZS bf[2]/bf[1] ## Bayes factor analysis ## -------------- ## [1] Alt., r=0.707 !(-0.351290094235453\u0026lt;d\u0026lt;0.351290094235453) : 0.6101882 ±0% ## ## Against denominator: ## Alternative, r = 0.707106781186548, mu =/= 0 -0.351290094235453\u0026lt;d\u0026lt;0.351290094235453 ## --- パッケージによる結果は、 $$ \\begin{cases} BF_{01Area} \\fallingdotseq 1.639 \\\\ BF_{10Area} \\fallingdotseq 0.610 \\\\ \\end{cases} $$ 最後の検定結果もほぼ同じ、無事有終の美を飾ることができました。"
  },
  {
    url: "https://sucre-stat.com/2021/06/bayesian-hypothesis-testing-2theory/",
    title: "ベイズファクターを用いた仮説検定～平均値の差の検定～",
    date: "2021-06-21T00:00:00Z",
    body: "ベイズファクターを用いた仮説検定～平均値の差の検定～ ◆この記事のテーマ\rベイズファクターを使って平均値の差を検定する方法を整理します。 この手法は、例えば下図のようなシーンに適用できます。下図左側では、交通事故対策Aの実施前と実施後の単位時間あたり事故発生件数のデータを蓄積し、対策前後で事故発生件数の平均値に差があるかを検定しています。また、下図右側では交通事故対策Aが実施された交差点と実施されていない交差点の単位時間あたり事故発生件数の平均値に差があるかを検定しています。 ※上記の事例は整数データであるからポアソン分布や負の二項分布等を使用するのが理想ですが、ここでは事故発生件数の平均値が十分大きく正規近似が可能であると仮定します。 ※左側は対応のある（one-sample）グループ間の検定、右側は対応のない（two-sampe）グループ間の検定です。設定上、後者の設計では対策実施効果以外の要因（異なる交差点を比較に用いることによるランダム効果）が結果に絡む可能性が高くなるので、対策Aの効果を確かめることが分析の目的であれば前者の対応のある検定の設計がより望ましいといえます。 参考文献は以下の通り。ベイズファクターを使って平均値の差の検定が英語なら文献が多い。 Byesian hypothesis testing for psychologists: A tutorial on the Savage-Dickey method Using MCMC chain outputs to efficiently estimate Bayes factors Bayesian t tests for accepting and rejecting the null hypothesis effect size $\\delta$の導入 ここでは、対応のある場合、対応のない場合に分けて検定の対象となるパラメータ$\\delta$を導入します。 対応のある場合 同じ対象に対し、2つの異なる状態で観測された値をそれぞれ確率変数$X_i$、$Y_i$からの観測値$x_i$、$y_i$とおき、独立同分布の確率変数の組$X^n=(X_1,X_2,\\ldots,X_n)$、$Y^n=(Y_1,Y_2,\\ldots,Y_n)$から観測値$x^n=(x_1,x_2,\\ldots,x_n)$、$y^n=(y_1,y_2,\\ldots,y_n)$を得たとします。 まずは、簡単に確率変数$X_i$、$Y_i$の差が平均$\\mu$の正規分布に従うと記載しちゃいます。 $$\rX_i - Y_i \\sim \\mathrm{Normal}(\\mu, \\sigma^2), ~~~ i=1,\\ldots,n \\tag{1}\r$$\r $(1)$式の唐突に現れた分散$\\sigma^2$は$(X_i - Y_i)$のスケールを表現するパラメータです。これはそのときどきの検定対象によって異なる値をとります。このとき、平均$\\mu$と$\\sigma$の間に何の関係も与えない場合、$\\mu$の値の大小がどれくらいの意味をもつものなのか把握が困難になってしまいます。そこで、平均$\\mu$をeffect sizeと呼ばれる値$\\delta$とスケールを指定する値に分け、スケールを指定する値を$\\sigma$としちゃいます。 $$\r\\mu = \\delta \\sigma \\tag{2}\r$$\r これでようやくスケールが単位あたりに調整されたeffect size$\\delta$に着目すれば良いことになり、以降の議論を一般的な形で記述できるようになりました。 ◆$X_i$及び$Y_i$と$\\delta$の関係のモデル化（対応のある場合）\r$$ X_i - Y_i \\sim \\mathrm{Normal}(\\delta \\sigma, \\sigma^2), ~~~ i=1,\\ldots,n \\tag{3} $$\r 対応のない場合 グループ1、グループ2に所属する対象からの観測値をそれぞれ確率変数$X_i$、$Y_i$からの観測値$x_i$、$y_i$とおき、独立同分布の確率変数の組$X^n=(X_1,X_2,\\ldots,X_n)$、$Y^m=(Y_1,Y_2,\\ldots,Y_m)$から観測値$x^n=(x_1,x_2,\\ldots,x_n)$、$y^m=(y_1,y_2,\\ldots,y_m)$を得たとします。 まずは、$X_i$、$Y_j$がともに分散$\\sigma$の正規分布に従い、また2つの分布の平均が$\\alpha$だけ離れているとおきます。 $$\r\\begin{cases}\rX_i \\sim \\mathrm{Normal}\\left(\\mu - \\cfrac{\\alpha}{2}, \\sigma^2\\right),~~~i=1,\\ldots,n \\\\\\\\\rY_j \\sim \\mathrm{Normal}\\left(\\mu + \\cfrac{\\alpha}{2}, \\sigma^2\\right),~~~j=1,\\ldots,m\r\\end{cases} \\tag{4}\r$$\r この場合もやはり同様に、2つの分布の平均値の差$\\alpha$と分散$\\sigma$の間に何の関係も与えない場合、$\\alpha$の値の大小がどれくらいの意味をもつものなのか把握が困難になってしまいます。そこで、やはり同様に $$\r\\alpha=\\delta \\sigma \\tag{5}\r$$\r とおいてやれば、ようやくスケールが単位あたりに調整されたeffect size$\\delta$に着目すれば検定が可能になり、こちらも以降の議論を一般的な形で記述できるようになります。 ◆$X_i$及び$Y_i$と$\\delta$の関係のモデル化（対応のない場合）\r$$ \\begin{cases} X_i \\sim \\mathrm{Normal}\\left(\\mu - \\cfrac{\\delta \\sigma}{2}, \\sigma^2\\right),~~~i=1,\\ldots,n \\\\ Y_j \\sim \\mathrm{Normal}\\left(\\mu + \\cfrac{\\delta \\sigma}{2}, \\sigma^2\\right),~~~j=1,\\ldots,m \\end{cases} \\tag{6} $$\r 仮説の設定 $(3)$、$(6)$式の$\\delta$に着目し、従来通りに帰無仮説と対立仮説を設定します。 ◆帰無仮説と対立仮説\r従来の統計的仮説検定に対応する仮説は、\r$\\delta$の正負が明らかでない両側検定の場合、\r$$\r\\mathrm{Unrestricted~~Model:} \\begin{cases}\rH_0:\\delta=0 \\\\\\\\\rH_1:\\delta\\neq0\r\\end{cases}\r$$\r$\\delta$が0以上の値をとることが明らかな片側検定の場合、\r$$\r\\mathrm{Order-restricted~~Model:} \\begin{cases}\rH_0:\\delta=0 \\\\\\\\\rH_2:\\delta 0\r\\end{cases}\r$$\r\r 以降では説明の簡略化のため、両側検定の場合の仮説を前提にします。 事前分布の設定 さて、ベイズの枠組みではすべての母数に事前分布を設定してやる必要があります。この事前分布の役割は、分析者が前もって知りうる情報を反映させるものである…と思っていませんか？ この考え方は主観ベイズ（subjective Bayes）と呼ばれており、間違ってはいません。しかし今回の目的は検定です。それもベイズファクターを用いた検定であり、事前分布の設定が検定結果に大きく左右されることからも、なるべく事前分布に主観を与えたくありません。このような態度を、客観ベイズ（objective Bayes）と呼び、ベイズファクターを用いた仮説検定の場合は客観ベイズの立場で事を考えることが重要になってきます（Rouder et al.(2009)）。 古今東西、客観ベイズの分野（それもなぜか心理学研究分野）では、研究者の間で合意のとれた検定のための汎用性のある事前分布の設定方法が盛んに研究されてきました。平均値の差の検定のための汎用的な事前分布もいくつか開発されています。ここでは天下り的に、JZSの事前分布（JZS proir）と単位情報事前分布（unit information proir）について整理します。 ◆JZSの事前分布\rJZSの事前分布は検定対象のパラメータ$\\delta$まわりの事前分布を以下のように設定する。 $$ \\begin{cases} \\delta \\sim \\mathrm{Normal}(0,g) \\\\ g \\sim \\mathrm{Inverse}~\\mathrm{Gamma}\\left(\\cfrac{1}{2}, \\cfrac{r^2}{2}\\right) \\\\ \\pi\\left(\\sigma^2\\right) ∝ \\cfrac{1}{\\sigma^2} \\\\ \\end{cases} \\tag{7} $$ ここで、$r$はscale factorとよばれ、effect sizeのスケールを設定するために分析者が指定するパラメータである。また$\\pi(x)$はパラメータ$x$の事前分布である。 これは、下記設定に等しい。 $$ \\begin{cases} \\delta \\sim \\mathrm{Cauchy}(0,r) \\\\ \\pi\\left(\\sigma^2\\right) ∝ \\cfrac{1}{\\sigma^2} \\\\ \\end{cases} \\tag{8} $$ 以上が対応のある平均値の差の検定における事前分布の設定である。対応のない平均値の差の検定ではさらに$\\mu$に以下のとおり事前分布を設定する。 $$ \\pi(\\mu) ∝ 1 \\tag{9} $$ memo\r\rコーシー分布は下記式で定義される。\r$$\r\\mathrm{Cauthy}(y | \\mu, \\sigma) = \\cfrac{1}{\\pi \\sigma}\\cfrac{1}{1 + ((y - \\mu)/\\sigma)^2}\r$$\r$\\mu=0$、$\\sigma=1$としたコーシー分布を標準コーシー分布と呼び、下記式で定義される。\r$$\r\\mathrm{Cauthy}(y | \\mu=1, \\sigma=1) = \\cfrac{1}{\\pi}\\cfrac{1}{1 + y^2}\r$$\r逆ガンマ分布は下記式で定義される。\r$$\r\\mathrm{Inverse}~\\mathrm{Gamma}\\left( y | \\alpha, \\beta \\right) =\r\\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}y^{-\\alpha-1}\\exp\\left( -\\cfrac{\\beta}{y} \\right) ~~~(y0)\r$$\r\r ◆単位情報事前分布\r単位情報事前分布は検定対象のパラメータ$\\alpha$まわりの事前分布を以下のように設定する。 $$ \\begin{cases} \\delta \\sim \\mathrm{Normal}(0,r^2) \\\\ \\sigma_{\\alpha}^2 ∝ \\cfrac{1}{\\sigma^2} \\\\ \\end{cases} \\tag{10} $$ 以上が対応のある平均値の差の検定における事前分布の設定である。対応のない平均値の差の検定ではさらに$\\mu$に以下のとおり事前分布を設定する。 $$ \\pi(\\mu) ∝ 1 \\tag{11} $$ JZSの事前分布と単位情報事前分布の唯一の違いはeffect size $\\delta$の事前分布（正規分布）の分散の設定です。JZSの事前分布は分散$g$が逆カイ二乗分布に従うとした一方、単位情報事前分布は分散固定です。その意味では、単位情報事前分布の方がモデルに与える事前情報が多いことになります。また$r=1$のとき、2つの設定は$\\delta$の事前分布を標準正規分布にするか、標準コーシー分布にするかの違いに帰着することが分かります。 標準正規分布と標準コーシー分布を比較した図が以下です。 図からも、標準コーシー分布は標準正規分布と比較し裾が重く、0から外れた値もとりやすい分布になっていることから、$r=1$の場合、JZSの事前分布は単位情報事前分布より事前情報が少ないことが確認できます。 また、両設定に共通のパラメータ$\\sigma$及び、対応のある検定の時のみ必要な$\\mu$については、ともにJeffeysの事前分布と呼ばれる事前分布を用いています。Jeffreysの事前分布はフィッシャー情報量から導かれるもので、事前分布と事後分布のカルバック・ライブラー情報量を最大化する効果がある、という点で無情報事前分布として使えるとされているようです。このあたりは詳しくないですが、Appendixに定義から正規分布の平均及び分散に対するJeffreysの事前分布を導出する方法を載せています。 ちなみに、$\\sigma$のように検定の対象となるパラメータとは別に存在し、かつ両モデルに共通の役割をもつパラメータはnuisance parameterと称され、こうしたパラメータはベイズファクターの値の決定にクリティカルでないことが証明されています。これに関しては以前の記事を参照してくだせえ。 ベイズファクターの解法 前節でモデルの設定を整理したので、本節ではベイズファクターの求め方を整理します。 解析的に求める 先に説明したJZSの事前分布と単位情報事前分布は解析的に計算することが可能です。ここでは導出や計算式までは深堀りしません。あまり面白くないので…。式を確認したい場合は参考文献を参照のこと。この文献の著者らはJZSの事前分布や単位情報事前分布の解析解を求めることができるWebページやRパッケージを開発しているので、実践編で解析解を求める際はこのあたりを活用させてもらいます。 MCMC法で近似的に求める 本記事と実践編の本題はこちらです。これにはネストされたモデル同士の比較で有効なSavage-Dickey法を使ってベイズファクターを計算します。Savage-Dickey法の概要を以下に示します。詳細は以前の記事を参照のこと。 ◆Savage-Dickey法\rモデル$M_0$と$M_1$に共通のパラメータ$\\boldsymbol{\\delta}=(\\delta_1, \\ldots, \\delta_m)$があるとき、$M_0$と$M_1$が $$ p(\\mathcal{D} | M_0) = p(\\mathcal{D} | \\boldsymbol{\\delta} = \\boldsymbol{\\delta}_0, M_1) \\tag{12} $$ とネストされた関係にある場合、ベイズファクター$BF_{01}$は下記のとおり計算できる。 $$ BF_{01} = \\cfrac{p(\\boldsymbol{\\delta}=\\boldsymbol{\\delta}_0 | \\mathcal{D}, M_1)}{p(\\boldsymbol{\\delta}=\\boldsymbol{\\delta}_0 |M_1)} \\tag{13} $$ ここで、$\\mathcal{D}$は全データセットである。 $(11)$、$(12)$式において、$H_0$、$H_1$にそれぞれ対応するモデルを$M_0$、$M_1$と読み替えれば、$H_1$に対応するモデル$M_1$における対象パラメータの事前分布と事後分布の一点比較をするだけでベイズファクター$BF_{01}$を求められることが分かります。 事前分布$p(\\boldsymbol{\\delta}=\\boldsymbol{\\delta}_0 |M_1)$の方は、MCMCの結果からではなく、設定したモデルから値を算出します。たとえば、従来通りの仮説検定の枠組みでは、JZSの事前分布、単位情報事前分布の双方ともに$\\delta=0$が帰無仮説に対応するパラメータ空間上の点ですから、 $$\r\\begin{cases}\rJZSの事前分布の場合： p(\\delta=0 |M_1) = \\cfrac{1}{\\pi r}~~ \u0026\\therefore\u0026~~ BF_{01} = \\pi r \\times p(\\delta=0 | \\mathcal{D}, M_1)　\\\\\\\\\r単位情報事前分布の場合： p(\\delta=0 |M_1) = \\cfrac{1}{\\sqrt{2\\pi r^2}}~~ \u0026\\therefore\u0026~~ BF_{01} = \\sqrt{2\\pi r^2} \\times p(\\delta=0 | \\mathcal{D}, M_1)　\\tag{14}\r\\end{cases}\r$$\r これが求めたいベイズファクターになります。 あとは$p(\\delta=0 | \\mathcal{D}, M_1)$が分かればベイズファクターを求められるので、以降はこれを求めることを考えます。 $\\delta$の事後分布の求め方 条件の無い周辺事後分布を使う こちらは全パラメータの同時分布から$\\delta$以外のパラメータ$\\boldsymbol{\\psi}$を周辺化消去することで$\\delta$の事後分布を求めています。JZSの事前分布の場合、$\\boldsymbol{\\psi}=(\\sigma,g,(\\mu))$、単位情報事前分布の場合、$\\boldsymbol{\\psi}=\\sigma$ですね。$r$は分析者が事前に設定するものなのでこれに含まれません。 $$\rp(\\delta=0 | \\mathcal{D}, M_1) = \\int_{\\boldsymbol{\\psi}}p(\\delta=0,\\boldsymbol{\\psi} | \\mathcal{D}, M_1) d\\boldsymbol{\\psi} = \\mathrm{E}_{\\boldsymbol{\\psi}}[p(\\delta=0, \\boldsymbol{\\psi} |\\mathcal{D},M_1)] \\tag{15}\r$$\r $(14)$式はMCMCのサンプルを用いて近似的に求めるなら、$\\boldsymbol{\\psi}$を無視し、$\\delta$のサンプルの分布をカーネル密度推定、もしくは以前の記事のように対数スプライン推定をするだけでイケます。簡単で便利です。 条件付き周辺事後分布を使う こちらは$\\boldsymbol{\\psi}$に関する条件付きの$\\delta$の事後分布を使って$p(\\delta=0 | x^n, M_1)$を求める方法です。参考文献に倣ってConditional MArginal Density Estimator を略し、CMDEと呼びます。 $$\rp(\\delta=0 | \\mathcal{D}, M_1) = \\int_{\\boldsymbol{\\psi}}p(\\delta=0 |\\boldsymbol{\\psi}, \\mathcal{D}, M_1) d\\boldsymbol{\\psi} = \\mathrm{E}_{\\boldsymbol{\\psi}}[p(\\delta=0, |\\boldsymbol{\\psi},\\mathcal{D},M_1)] \\tag{16}\r$$\r $(14)$式の計算では切り捨てていた$\\boldsymbol{\\psi}$について、その事後分布も$x^n$についての情報を含んでいるのだから、$\\boldsymbol{\\psi}$も考慮して$p(\\delta=0 | x^n, M_1)$を求めてやるべきだ、というのがCMDEの発想ですが、実際、$(16)$式による計算は$(15)$式よりもはるかに$p(\\delta=0 | \\mathcal{D}, M_1)$の推定精度が良いことが参考文献による実験で解明されています。その理由はラオ・ブラックウェルの定理により明らかとのこと。勉強できたらAppendixに載せたいと思います。 $(16)$式は、MCMCサンプルを用いて次のように近似的に計算されます。 $$\r\\mathrm{E}_ {\\boldsymbol{\\psi}}[p(\\delta=0, |\\boldsymbol{\\psi}, \\mathcal{D},M_1)] \\eqsim \\cfrac{1}{T} \\sum_{t=1}^{T} p(\\delta=0 | \\boldsymbol{\\psi}^{(t)}, \\mathcal{D},M_1) \\tag{17}\r$$\r $(17)$式は、条件付き事後分布$p(\\delta|\\boldsymbol{\\psi},\\mathcal{D},M_1)$の関数形が明らかであれば解析的に計算可能です。そこで、JZSの事前分布、単位情報事前分布それぞれの場合の条件付き事後分布$p(\\delta|\\boldsymbol{\\psi},\\mathcal{D},M_1)$及びその導出過程を、対応のある場合とない場合に分けて提示します。 ◆対応のある平均値の差の検定におけるCMDE\rJZSの事前分布を設定したときの条件付き事後分布$p(\\delta | \\boldsymbol{\\psi}=(\\sigma,g), \\mathcal{D}=(x^n,y^n), M_1)$は以下のとおりである。 $$ p(\\delta | \\boldsymbol{\\psi},\\mathcal{D}, M_1) = \\mathrm{Normal}\\left(\\cfrac{\\sum_{i=1}^{n}(x_i-y_i)}{\\sigma\\left(n + \\cfrac{1}{g}\\right)}, \\cfrac{1}{n + \\cfrac{1}{g}}\\right) \\tag{18} $$ 単位情報事前分布を設定したときの条件付き事後分布$p(\\delta | \\boldsymbol{\\psi}=\\sigma, \\mathcal{D}=(x^n,y^n), M_1)$は、 $$ p(\\delta | \\boldsymbol{\\psi},\\mathcal{D}, M_1) = \\mathrm{Normal}\\left(\\cfrac{\\sum_{i=1}^{n}(x_i-y_i)}{\\sigma\\left(n + \\cfrac{1}{r^2}\\right)}, \\cfrac{1}{n + \\cfrac{1}{r^2}}\\right) \\tag{19} $$ ◆導出\r(18)式を導出する。\rベイズルールより、\r$$\rp(\\delta | \\mathcal{D},\\boldsymbol{\\psi}, M_1) \\propto p(\\mathcal{D} | \\delta, \\boldsymbol{\\psi}, M_1 )p(\\delta | \\boldsymbol{\\psi})\r$$\r$(3)$式、$(7)$式を用いるため、\r$$\r\\begin{cases}\rp(\\mathcal{D} | \\delta, \\boldsymbol{\\psi}, M_1 ) = ∏_{i=1}^{n} p(x_i-y_i | \\delta, \\sigma) = ∏_{i=1}^{n} \\mathrm{Normal} (x_i-y_i | \\delta\\sigma, \\sigma^2 ) \\\\\\\\\rp(\\delta | \\boldsymbol{\\psi}) = p(\\delta | g) = \\mathrm{Normal}(\\delta |0,g)\r\\end{cases}\r$$\rよって、\r$$\r\\begin{split}\rp(\\delta | \\mathcal{D},\\boldsymbol{\\psi}, M_1) \u0026=\u0026 ∏_{i=1}^{n} \\mathrm{Normal} (x_i-y_i | \\delta\\sigma, \\sigma^2 ) \\times \\mathrm{Normal}(\\delta | 0,g) \\\\\\\\\r\u0026=\u0026 ∏_{i=1}^{n} \\cfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\cfrac{((x_i - y_i) - \\delta\\sigma)^2}{2\\sigma^2}\\right) \\times \\cfrac{1}{\\sqrt{2\\pi g}}\\exp\\left(-\\cfrac{\\delta^2}{2g}\\right) \\\\\\\\\r\u0026\\propto\u0026 \\exp \\left(\r-\\cfrac{n\\sigma^2\\delta^2 - 2\\sum_{i=1}^{n}(x_i - y_i)\\delta\\sigma + \\sum_{i=1}^{n}(x_i - y_i)^2}\r{2\\sigma^2} - \\cfrac{\\delta^2}{2g}\r\\right) \\\\\\\\\r\u0026\\propto\u0026 \\exp\\left(-\\cfrac{1}{2\\sigma^2}n\\sigma^2\\left(\\delta - \\cfrac{1}{n\\sigma}\\sum_{i=1}^{n}(x_i - y_i)\\right)^2 - \\cfrac{\\delta^2}{2g}\\right) \\\\\\\\\r\u0026\\propto\u0026 \\exp\\left( -\\cfrac{1}{2} \\left( \\left(n + \\cfrac{1}{g}\\right)\\delta^2 -2\\cfrac{1}{\\sigma}\\sum_{i=1}^{n}(x_i - y_i)\\delta \\right) \\right) \\\\\\\\\r\u0026\\propto\u0026 \\exp\\left(-\\cfrac{1}{2\\cfrac{1}{n + \\cfrac{1}{g}}}\\left(\\delta - \\cfrac{\\cfrac{1}{\\sigma}\\sum_{i=1}^{n}(x_i - y_i)}{n + \\cfrac{1}{g}}\\right)^2\\right) \\\\\\\\\r\u0026\\propto\u0026 \\mathrm{Normal}\\left(\\cfrac{\\sum_{i=1}^{n}(x_i - y_i)}{\\sigma\\left(n + \\cfrac{1}{g}\\right)}, \\cfrac{1}{n + \\cfrac{1}{g}}\\right)\r\\end{split}\r$$\r$(19)$式は$(3)$、$(10)$式を用いるので、上述の導出で$g$を$r^2$に置き換えることで同様に導出できる。\r\r ◆対応のない平均値の差の検定におけるCMDE\rJZSの事前分布を設定したときの条件付き事後分布$p(\\delta | \\boldsymbol{\\psi}=(\\sigma,g,\\mu), \\mathcal{D}=(x^n,y^m), M_1)$は以下のとおりである。 $$ p(\\delta | \\boldsymbol{\\psi},\\mathcal{D}, M_1) = \\mathrm{Normal}\\left(\\cfrac{2g\\left( \\sum_{j=1}^{m}y_j - \\sum_{i=1}^{n} x_i + (n-m)\\mu \\right)}{\\left(4 + (n+m)g \\right)\\sigma }, \\cfrac{4g}{4+(n+m)g}\\right) \\tag{20} $$ 単位情報事前分布を設定したときの条件付き事後分布$p(\\delta | \\boldsymbol{\\psi}=(\\sigma, \\mu), \\mathcal{D}=(x^n,y^m), M_1)$は、 $$ p(\\delta | \\boldsymbol{\\psi},\\mathcal{D}, M_1) = \\mathrm{Normal}\\left(\\cfrac{2r^2\\left( \\sum_{j=1}^{m}y_j - \\sum_{i=1}^{n} x_i + (n-m)\\mu \\right)}{\\left(4 + (n+m)r^2 \\right)\\sigma }, \\cfrac{4r^2}{4+(n+m)r^2}\\right) \\tag{21} $$ ◆導出\r(20)式を導出する。\rベイズルールより、\r$$\rp(\\delta | \\mathcal{D},\\boldsymbol{\\psi}, M_1) \\propto p(\\mathcal{D} | \\delta, \\boldsymbol{\\psi}, M_1 )p(\\delta | \\boldsymbol{\\psi})\r$$\r$(6)$式、$(7)$式を用いるため、\r$$\r\\begin{cases}\rp(\\mathcal{D} | \\delta, \\boldsymbol{\\psi}, M_1 ) = ∏_{i=1}^{n} \\mathrm{Normal}(x_i | \\mu - \\cfrac{\\delta\\sigma}{2}, \\sigma^2) \\times ∏_{j=1}^{m} \\mathrm{Normal}(y_i | \\mu + \\cfrac{\\delta\\sigma}{2}, \\sigma^2) \\\\\\\\\rp(\\delta | \\boldsymbol{\\psi}) = p(\\delta | g) = \\mathrm{Normal}(\\delta |0,g)\r\\end{cases}\r$$\rよって、\r$$\r\\begin{split}\rp(\\delta | \\mathcal{D},\\boldsymbol{\\psi}, M_1) \u0026=\u0026 ∏_{i=1}^{n} \\mathrm{Normal}(x_i | \\mu - \\cfrac{\\delta\\sigma}{2}, \\sigma^2) \\times ∏_{j=1}^{m} \\mathrm{Normal}(y_i | \\mu + \\cfrac{\\delta\\sigma}{2}, \\sigma^2) \\times \\mathrm{Normal}(\\delta |0,g) \\\\\\\\\r\u0026=\u0026 \\prod_{i=1}^{n}\\cfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left\\{-\\cfrac{\\left( x_i - \\left( \\mu - \\cfrac{\\delta\\sigma}{2} \\right) \\right)^2}{2\\sigma^2}\\right\\} \\times\r\\prod_{j=1}^{m}\\cfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left\\{-\\cfrac{\\left( y_j - \\left( \\mu + \\cfrac{\\delta\\sigma}{2} \\right) \\right)^2}{2\\sigma^2}\\right\\} \\times\r\\cfrac{1}{\\sqrt{2\\pi g}}\\exp\\left({\\cfrac{\\delta^2}{2g}}\\right) \\\\\\\\\r\u0026\\propto\u0026 \\exp\\left\\{ -\\cfrac{1}{2\\sigma^2}\\left( \\delta\\sigma\\left( \\sum_{i=1}^{n} x_i - \\sum_{j=1}^{m} y_j \\right) - (n-m)\\mu\\sigma\\delta + \\cfrac{n+m}{4}\\sigma^2\\delta^2 \\right) - \\cfrac{1}{2g}\\delta^2 \\right\\} \\\\\\\\\r\u0026\\propto\u0026 \\exp\\left\\{ -\\cfrac{1}{2} \\left( \\left( \\cfrac{1}{g} + \\cfrac{n+m}{4} \\right) \\delta^2 + \\cfrac{\\sum_{i=1}^{n}x_i - \\sum_{j=1}^{m}y_j -(n-m)\\mu}{\\sigma}\\delta \\right) \\right\\} \\\\\\\\\r\u0026\\propto\u0026 \\exp \\left\\{ -\\cfrac{1}{2\\cfrac{4g}{4+(n+m)g}} \\left( \\delta - \\cfrac{2g\\left( \\sum_{j=1}^{m}y_j - \\sum_{i=1}^{n} x_i + (n-m)\\mu \\right)}{\\left(4 + (n+m)g \\right)\\sigma } \\right)^2 \\right\\} \\\\\\\\\r\u0026\\propto\u0026 \\mathrm{Normal}\\left(\\cfrac{2g\\left( \\sum_{j=1}^{m}y_j - \\sum_{i=1}^{n} x_i + (n-m)\\mu \\right)}{\\left(4 + (n+m)g \\right)\\sigma }, \\cfrac{4g}{4+(n+m)g}\\right)\r\\end{split}\r$$\r$(21)$式は$(6)$、$(10)$式を用いるので、上述の導出で$g$を$r^2$に置き換えることで同様に導出できる。\r\r これでベイズファクターを使って平均値の差の検定をする準備が整いました。実践編は実践編で！ Appendix Jaffrayの事前分布 ◆Jeffreysの事前分布\rJeffreysの事前分布$p_J(\\theta)$は、下記のとおり定義される。 $$ P_J(\\theta) = \\sqrt{I(\\theta)} \\tag{22} $$ ここで、$I(\\theta)$はフィッシャー情報量とよばれ、$\\theta$は（通常確率変数の）パラメータである。 $$ I(\\theta) = \\mathbb{E}\\left[ \\left. \\left( \\cfrac{\\partial}{\\partial \\theta} \\mathrm{ln} ~ L(\\theta | x) \\right)^2 \\right| \\theta \\right] \\tag{23} $$ この定義に沿って正規分布の平均・分散に対するJeffreysの事前分布を導出する。 正規分布の平均$\\mu$に対するJeffreysの事前分布の導出\r正規分布に従う確率変数$X$について考える。\r$$\rL(\\mu | x) = \\cfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left\\{ - \\cfrac{(x - \\mu)^2}{2\\sigma^2} \\right\\}\r$$\rより、\r$$\r\\mathrm{ln} ~ L(\\mu | x) = - \\log(\\sqrt{2\\pi}\\sigma) - \\cfrac{(x - \\mu)^2}{2\\sigma^2}\r$$\rだから、\r$$\r\\cfrac{\\partial}{\\partial \\mu} \\mathrm{ln} ~ L(\\mu | x) = \\cfrac{(x - \\mu)^2}{\\sigma^2}\r$$\rフィッシャー情報量$I(\\mu)$は、\r$$\rI(\\mu) = \\mathbb{E}\\left[ \\left( \\cfrac{x - \\mu}{\\sigma^2} \\right)^2 \\right] = \\cfrac{1}{\\sigma^2} \\mathbb{E} \\left[ \\left( \\cfrac{x -\\mu}{\\sigma} \\right)^2 \\right] = \\cfrac{\\alpha_{X,2}}{\\sigma^2}\r$$\rここで、$\\alpha_{X,2}$は確率変数$X$の2次の標準化積率である。標準化積率は\r$$\r\\alpha_{X,2} = \\mathbb{E}\\left[ \\cfrac{X - \\mu_{X}}{\\sigma_X}^2 \\right] = \\cfrac{\\mu_{X,2}}{\\sigma_X^2}\r$$\rと表現されること(ここで$\\mu_{X,k}$は$X$の中心積率、$\\sigma_X$は$X$の標準偏差)、$\\mu_{X,2}$は$X$の分散であることから、\r$$\rI(\\mu) = \\cfrac{\\alpha_{X,2}}{\\sigma^2} = \\cfrac{1}{\\sigma^2}\r$$\rよって、\r$$\rP_J(\\mu) = \\sqrt{I(\\mu)} = \\cfrac{1}{\\sigma} \\propto 1\r$$\r\r 正規分布の分散$\\sigma^2$に対するJeffreysの事前分布の導出\r正規分布に従う確率変数$X$について考える。\r$$\rL(\\sigma^2 | x) = \\cfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left\\{ - \\cfrac{(x - \\mu)^2}{2\\sigma^2} \\right\\}\r$$\rここで$\\sigma^2 = g$とおいて、\r$$\rL(g | x) = \\cfrac{1}{\\sqrt{2\\pi g}}\\exp\\left\\{ - \\cfrac{(x - \\mu)^2}{2g} \\right\\}\r$$\rこのとき\r$$\r\\cfrac{\\partial}{\\partial g} \\mathrm{ln} ~ L(g | x) = \\cfrac{(x-\\mu)^2 - g }{2g^2}\r$$\rより、\rフィッシャー情報量$I(\\sigma)$は、\r$$\r\\begin{split}\rI(g) \u0026=\u0026 \\mathbb{E}\\left[ \\left( \\cfrac{(x-\\mu)^2 - g }{2g^2} \\right)^2 \\right] \\\\\\\\\r\u0026=\u0026 \\cfrac{1}{4g^2}\\mathbb{E}\\left[ \\cfrac{(x - \\mu)^4}{g^2} \\right] - 2\\cfrac{1}{g^2}\\mathbb{E} \\left[ \\cfrac{(x-u)^2}{g} \\right] + \\cfrac{1}{4g} \\\\\\\\\r\u0026=\u0026 \\cfrac{1}{4g^2} \\alpha_{X,4} - 2\\cfrac{1}{g^2}\\alpha_{X,2} + \\cfrac{1}{4g} \\\\\\\\\r\u0026=\u0026 \\cfrac{1}{2g^2}\r\\end{split}\r$$\r途中、$\\alpha_{X,4}=3$、$\\alpha_{X,2}=1$を用いた。よって\r$$\rP_J(\\sigma^2) = P_J(g) = \\sqrt{I(g)} = \\cfrac{1}{\\sqrt{2}\\sigma} \\propto \\cfrac{1}{\\sigma}\r$$\r\r"
  },
  {
    url: "https://sucre-stat.com/2021/04/bayesian-hypothesis-testing-1practice/",
    title: "ベイズファクターを用いた仮説検定を実践する～比率の差の検定～",
    date: "2021-04-18T00:00:00Z",
    body: "ベイズファクターを用いた仮説検定を実践する～比率の差の検定～ ◆この記事のテーマ\rベイズファクターを使って比率の差を検定する方法を実践します。 この手法は、例えば下図のようなシーンに適用できます。下図では異なる交差点の危険挙動発生割合を比較しています。 交通安全対策実施前後の危険挙動発生割合の変化を判定したいときにも同じ方法論が活用できます。 ※一つ目の例は対応のない（two-sampe）グループ間の検定、二つ目の例は対応のある（one-sample）グループ間の検定ですが、どちらの検定も一つのモデルで包括して説明されます。 モデルの確認 本検定のためのモデルについてはこちらの姉妹記事で詳細を説明していますので、ここでは要点だけ記載しておくことにします。 $n_1$、$n_2$はそれぞれ交差点1、交差点2における車両毎の危険挙動に関するデータ（0=「危険挙動無し」 OR 1「危険挙動あり」）の標本数、$s_1$、$s_2$はそれぞれ交差点1、交差点2において危険挙動をした車両の台数です。交差点ごとに、独立の二項分布に従い危険挙動をした車両が観測されたと仮定し、発生確率を$\\theta_1$、$\\theta_2$とおきモデル化します。 ◆比率の差の検定モデル\r$$\rs_1 \\sim \\mathrm{Binomial}(\\theta_1,n_1) \\tag{1}\r$$\r$$\r\\theta_1 \\sim \\mathrm{Uniform}(0,1) \\tag{2}\r$$\r$$\rs_2 \\sim \\mathrm{Binomial}(\\theta_2,n_2) \\tag{3}\r$$\r$$\r\\theta_2 \\sim \\mathrm{Uniform}(0,1) \\tag{4}\r$$\r $\\theta_1$、$\\theta_2$には、無情報事前分布$\\mathrm{Uniform}(0,1)$を設定することとします。 このとき、我々の興味の対象となる確率変数は$\\delta=\\theta_1 - \\theta_2$です。$\\theta_1$、$\\theta_2$の大小関係についての事前知識がある場合と無い場合に分け、2つの帰無仮説・対立仮説の組を設定します。交差点の比較の例では、ふたつの交差点の危険挙動発生率について大小関係が不明であると考えることもできますが、交差点2は交差点1と同じ形状であるが信号機が設置されていることから、危険挙動発生率は交差点1より少ない、すなわち$\\theta_1 \u0026gt; \\theta_2$ではないか、と考えることもできます。 これらは、従来の仮説検定における片側検定・両側検定に対応します。 帰無仮説と対立仮説\r$\\theta_1$と$\\theta_2$の大小関係が明らかでないときの仮説は、\r$$\r\\mathrm{Unrestricted~~Model:} \\begin{cases}\rH_0:\\delta=0 \\\\\\\\\rH_1:\\delta\\neq0\r\\end{cases}\r$$\r$\\theta_1 \\geq \\theta_2$が明らかな場合の仮説は、\r$$\r\\mathrm{Order-restricted~~Model:} \\begin{cases}\rH_0:\\delta=0 \\\\\\\\\rH_2:\\delta \\geq 0\r\\end{cases}\r$$\r Unrestricted Model では、$\\theta_1$と$\\theta_2$の大小関係が明らかでないときの仮説から検定してみます。Rstanを用いて$(1)～(4)$式をモデル化し、$\\delta$の周辺事後分布をMCMCによって近似推定し、Savage-Dickeyによる$(5)$式を用いて$BF_{01}$を求める方針です。またこちらの記事で導出した解析的な結果との整合性も確認してみます。 まずはサンプルデータを準備します。 # sample data #x1:Group1 x1 \u0026lt;- c(rbinom(n=40, size=1, prob=0.4),rbinom(n=60, size=1, prob=0.5)) #x2:Group2 x2 \u0026lt;- c(rbinom(n=40, size=1, prob=0.2),rbinom(n=60, size=1, prob=0.5)) library(ggplot2) library(gridExtra) p1 \u0026lt;- ggplot(data=data.frame(X=x1)) + theme_light(base_size=11) + geom_bar(aes(x=X), fill=\u0026#34;#004C98\u0026#34;) + scale_x_continuous(breaks=c(0,1), labels = c(\u0026#34;-\u0026#34;,\u0026#34;危険挙動\u0026#34;)) + xlab(\u0026#34;Group1\u0026#34;) p2 \u0026lt;- ggplot(data=data.frame(X=x2)) + theme_light(base_size=11) + geom_bar(aes(x=X), fill=\u0026#34;#004C98\u0026#34;) + scale_x_continuous(breaks=c(0,1), labels = c(\u0026#34;-\u0026#34;,\u0026#34;危険挙動\u0026#34;)) + xlab(\u0026#34;Group2\u0026#34;) p \u0026lt;- grid.arrange(p1, p2, ncol=2) このデータに対し、通常の比率の差の検定を関数prop.test()で行います。原理は昔紹介した分割表の一様性の検定と同じものです。 prop.test(x=c(sum(x1),sum(x2)), n=c(length(x1),length(x2)), correct=F) ## 2-sample test for equality of proportions without continuity correction ## ## data: c(sum(x1), sum(x2)) out of c(length(x1), length(x2)) ## X-squared = 1.6807, df = 1, p-value = 0.1948 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.04549292 0.22549292 ## sample estimates: ## 0.45 0.36 ## prop 1 prop 2 ２グループの比率が同じであるという帰無仮説を設定した検定に対し、p値$0.1948$となり、比率に差があるとは言えない結果となりました。 次にこちらの記事の$(7)$式に基づいて解析的なベイズファクターの計算による検定を行います。 data \u0026lt;- list(N1=length(x1), N2=length(x2), S1=sum(x1), S2=sum(x2)) # calculate BF_01 by closed form # data[[1]]：n1 # data[[2]]：n2 # data[[3]]：s1 # data[[4]]：s2 cat(choose(data[[1]],data[[3]]) * choose(data[[2]],data[[4]]) / choose(data[[1]]+data[[2]], data[[3]]+data[[4]])*(data[[1]]+1)*(data[[2]]+1)/(data[[1]]+data[[2]]+1)) ## 2.526656 対立仮説$H_1:\\delta\\neq0$よりも帰無仮説$H_0:\\delta=0$の方がデータの説明力（周辺尤度）が約$2.53$倍良く、どちらかというと帰無仮説を支持するようです。しかしKass and Raftery(1995)の基準ではこの差は対立仮説に対する反証があまり強いとは言えない程度であると評価されました。 以上、検定結果をひととおり見た上で、次はMCMCにより$\\delta$の事後分布を近似推定し、ベイズファクターを推定します。Stanによる実装例を以下に示します。 //non-restricted aalysis //model1.stan data { //the number fo sample of Group1 int\u0026lt;lower=1\u0026gt; N1; //the number fo sample of Group2 int\u0026lt;lower=1\u0026gt; N2; //the number fo sample which occurs with a probability of theta1 of Group1 int\u0026lt;lower=0\u0026gt; S1; //the number fo sample which occurs with a probability of theta2 of Group2 int\u0026lt;lower=0\u0026gt; S2; } parameters { //the parameter of Binomial distribution of Group1 real\u0026lt;lower=0, upper =1\u0026gt; theta1; //the parameter of Binomial distribution of Group2 real\u0026lt;lower=0, upper=1\u0026gt; theta2; } model { //S1 ~ binomial(N1, theta1) target += binomial_lpmf(S1 | N1, theta1); //S2 ~ binomial(N2, theta2) target += binomial_lpmf(S2 | N2, theta2); //uninformative prior target += beta_lpdf(theta1 | 1,1); target += beta_lpdf(theta2 | 1,1); } generated quantities{ //the difference parameter between theta1 and theta2 real delta; delta = theta1 - theta2; } iterationを$11000$、warmupを$1000$、chain数を$4$としMCMCを走らせ、結果を確認します。 options(mc.cores = parallel::detectCores()) rstan_options(auto_write = TRUE) fit \u0026lt;- stan(file=\u0026#34;model/model1.stan\u0026#34;, data=data, iter=11000, warmup=1000, chain=4) fit ## Inference for Stan model: model1. ## 4 chains, each with iter=11000; warmup=1000; thin=1; ## post-warmup draws per chain=10000, total post-warmup draws=40000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## theta1 0.45 0.00 0.05 0.36 0.42 0.45 0.48 0.55 36883 1 ## theta2 0.36 0.00 0.05 0.27 0.33 0.36 0.39 0.46 36917 1 ## delta 0.09 0.00 0.07 -0.05 0.04 0.09 0.13 0.22 36034 1 ## lp__ -8.89 0.01 1.02 -11.60 -9.27 -8.58 -8.17 -7.90 17925 1 このシミュレーション結果を使って$\\delta$の事後分布を近似推定します。推定手法は参考文献が推奨する対数スプライン推定を用いました。通常、事後分布の推定にはカーネル密度推定が用いられることが多いと思うのですが、対数スプライン推定はカーネル密度推定と比較し推定値が負の値を取らないという利点があり、この場合推定精度が比較的良いとされているようです。 library(ggplot2) library(ggrepel) library(logspline) library(tidyverse) # non_restricted analysis d \u0026lt;- as.matrix(fit)[,\u0026#34;delta\u0026#34;] fit_logspline \u0026lt;- logspline(d) plot_title = ggtitle(label=\u0026#34;equalty of proportions(unrestricted analysis)\u0026#34;) p \u0026lt;- ggplot() + theme_light(base_size=11) + geom_path(data=data.frame(X=x \u0026lt;- seq(-1,1,0.01), Y=dlogspline(x,fit_logspline)), aes(x=X,y=Y), color=\u0026#34;blue\u0026#34;) + geom_line(data=data.frame(x=c(-1,0,1),y=c(0,1,0)),aes(x=x,y=y)) + geom_point(data=data.frame(x=0,y=dlogspline(0, fit_logspline)),aes(x=x,y=y), color=\u0026#34;blue\u0026#34;) + geom_point(data=data.frame(x=0,y=1), aes(x=x, y=y)) + geom_text_repel(data=data.frame(x=c(0,0),y=c(1,dlogspline(0,fit_logspline)),label=c(1,round(dlogspline(0, fit_logspline),2))), aes(x=x,y=y,label=label)) + annotate(\u0026#34;text\u0026#34;,x=-Inf,y=Inf,label=sprintf(\u0026#34;BF01=%.2f\u0026#34;,dlogspline(0,fit_logspline)),hjust=-.2,vjust=2) + plot_title p 結果は、$BF_{01} \\simeq 2.50$と、解析的な解とそれほど大差無い結果となりました。やはりこのデータは確信をもって比率に差があるとは言えないようですな。 同じ危険挙動発生率でも標本数が倍になると、確信をもって差があると言える程度も変わってくるはずです。ちょっと確認してみましょう。 # data with same probability but twice sample size #new_x1:Group1 new_x1 \u0026lt;- rep(x1,10) #new_x2:Group2 new_x2 \u0026lt;- rep(x2,10) ～（以下略）～ cat(1/dlogspline(0,fit_logspline)) ## 147.1852 $BF_{10} \\eqsim 147.19$と、期待通り対立仮説を強く支持する結果となりました。 Order-restricted Model 次に、$\\theta_1 \\geq \\theta_2$が明らかな場合のOrder-restricted Modelについて考えます。モデル構成はUnrestricted Modelと同じで、あらかじめ分かっている事前情報が違うだけなので、新たに別のモデルでMCMCする必要はありません。方針としては、先ほど得たMCMCサンプルより推定した事後分布のうち、$\\theta_1 \\geq \\theta_2$を満たす範囲のみを抽出し、事後分布とします。 # restricted analysis fit_logspline \u0026lt;- logspline(d) dens \u0026lt;- function(x){ dlogspline(x, fit_logspline)/(1-plogspline(0, fit_logspline))} plot_title = ggtitle(label=\u0026#34;equalty of proportions(order-restricted analysis)\u0026#34;) p \u0026lt;- ggplot() + theme_light(base_size=11) + geom_path(data=data.frame(X=x \u0026lt;- seq(0,1,0.001), Y=dens(x)), aes(x=X,y=Y), color=\u0026#34;blue\u0026#34;) + geom_line(data=data.frame(x=c(0,1),y=c(2,0)),aes(x=x,y=y)) + geom_point(data=data.frame(x=0,y=dens(0)),aes(x=x,y=y), color=\u0026#34;blue\u0026#34;) + geom_point(data=data.frame(x=0,y=2), aes(x=x, y=y)) + geom_text_repel(data=data.frame(x=c(0,0),y=c(2,dens(0)),label=c(2,round(dens(0),2))), aes(x=x,y=y,label=label)) + annotate(\u0026#34;text\u0026#34;,x=Inf,y=Inf,label=sprintf(\u0026#34;BF01=%.2f\u0026#34;,dens(0)/2),hjust=1.2,vjust=2) + xlab(\u0026#34;δ\u0026#34;) + ylab(\u0026#34;density\u0026#34;) + plot_title p cat(dens(0)/2) ## 1.385902 検定の結果は、Unrestricted Modelが$BF_{01} \\eqsim 2.50$に対し、Order-restricred Modelが$BF_{02} \\eqsim 1.39$となり、帰無仮説$H_0$を支持する傾向は同じものの、やや確信度が小さくなる結果となりました。直感的には、グループ2よりグループ1の事故発生率が大きいことから、$\\theta_1 \\geq \\theta_2$としたOrder-Restricted Modelに対するデータの当てはまりが良く、$BF_{01} \\geq BF_{02}$となりそうだと考えられ、実際には事前分布の$\\delta=0$での値が$2$倍になったことにより、直感通りの結果が得られたと言えます。 またベイズファクターは相対比較ですから、$BF_{01}$と$BF_{02}$が求まれば$BF_{12}$も一意に定まります。 $$ BF_{12} =\\cfrac{p(D|H_1)}{p(D|H_2)} = \\cfrac{p(D|H_1)}{p(D|H_0)}\\cfrac{p(D|H_0)}{p(D|H_2)} = BF_{10}BF_{02} \\eqsim 0.554 $$ よって、$H_2$の方が$H_1$よりも$\\cfrac{1}{0.554} \\eqsim 1.80$倍データをうまく説明している、と判断することができます。 ここまで、対応の無い比率のさの検定をベイズファクターを使って実践してみました。従来通りの結果と比べて理論が簡潔で私は好みのベイズファクター、「分かりやすい」統計のために今後重要になってくるのではないでしょうか。 一方、本例のような危険挙動データの例の場合、本来、危険挙動を観測した車両の全体に占める割合は非常に小さく、通常1割にも達しません（私の経験）。 このようなデータに対し、二項分布のパラメータ$\\theta$に無情報事前分布を設定すると、周辺尤度の性質から、$BF_{01}$は必ず帰無仮説$H_0:\\delta=0$を強く支持する値となるでしょう。事前分布をどうするかについては、今後の研究が待たれるところです（？）。 おわりに 今回は、ベイズファクターを使って比率の差を検定する方法を実践しました。解析的に求める方法と、MCMCを使って近似的に求める方法の2通りを実践しましたが、精度の面からいうともちろん解析的に求めるのが妥当です。しかし、後半で実践したような、Order-restricted Modelで検定したいときなどは、解析解をまた別に求めてやらなばなりません。こちらの記事で導出した解析解はあくまで従来通りの検定における帰無仮説と対立仮説の（方向性をもたない）比較をしたいときの解であり、この式だけでは他の仮説の比較に応用できないのです。それならOrder-restricted Modelの解析解を求めてやれば良いのですが、目的に応じてその都度解を求めるのは大変です。MCMC法はそういった面倒な計算をすっ飛ばして近似的にベイズファクターやら事後分布やらを求めることができる、という点が魅力的なんですね（といっても今回は片側検定に対応するモデルしかMCMC法で追加検討していませんが）。"
  },
  {
    url: "https://sucre-stat.com/2021/04/bayesian-hypothesis-testing-1/",
    title: "ベイズファクターを用いた仮説検定～比率の差の検定～",
    date: "2021-04-18T00:00:00Z",
    body: "ベイズファクターを用いた仮説検定～比率の差の検定～ ◆この記事のテーマ\rベイズファクターを使って比率の差を検定する方法を整理します。 この手法は、例えば下図のようなシーンに適用できます。下図では異なる交差点の危険挙動発生割合を比較しています。 交通安全対策実施前後の危険挙動発生割合の変化を判定したいときにも同じ方法論が活用できます。 ※一つ目の例は対応のない（two-sampe）グループ間の検定、二つ目の例は対応のある（one-sample）グループ間の検定ですが、どちらの検定も一つのモデルで包括して説明されます。 モデル 参考文献に掲載されたグラフィカルモデルを拝借して以下に示します。またここでは、一つ目の例の対応の無い交差点間の危険挙動割合の比較に着目して考えます。 ここで、$n_1$、$n_2$はそれぞれ交差点1、交差点2における車両毎の危険挙動に関するデータ（0=「危険挙動無し」 OR 1「危険挙動あり」）の標本数、$s_1$、$s_2$はそれぞれ交差点1、交差点2において危険挙動をした車両の台数です。交差点ごとに、独立の二項分布に従い危険挙動をした車両が観測されたと仮定し、発生確率を$\\theta_1$、$\\theta_2$とおきモデル化します。 比率の差の検定モデル\r$$\rs_1 \\sim \\mathrm{Binomial}(\\theta_1,n_1) \\tag{1}\r$$\r$$\r\\theta_1 \\sim \\mathrm{Uniform}(0,1) \\tag{2}\r$$\r$$\rs_2 \\sim \\mathrm{Binomial}(\\theta_2,n_2) \\tag{3}\r$$\r$$\r\\theta_2 \\sim \\mathrm{Uniform}(0,1) \\tag{4}\r$$\r このとき、我々の興味の対象となる確率変数は$\\delta=\\theta_1 - \\theta_2$です。$\\theta_1$、$\\theta_2$の大小関係についての事前知識がある場合と無い場合に分け、2つの帰無仮説・対立仮説の組を設定します。交差点の比較の例では、交差点2は交差点1と同じ形状であり、信号機が設置されていることから、危険挙動発生率は交差点1より少ない、すなわち$\\theta_1 \u0026gt; \\theta_2$ではないか、と考えることができます。 $\\theta_1$、$\\theta_2$には、無情報事前分布$\\mathrm{Uniform}(0,1)$を設定することとします。 ◆帰無仮説と対立仮説\r$\\theta_1$と$\\theta_2$の大小関係が明らかでないときの仮説は、\r$$\r\\mathrm{Unrestricted~~Model:} \\begin{cases}\rH_0:\\delta=0 \\\\\\\\\rH_1:\\delta\\neq0\r\\end{cases}\r$$\r$\\theta_1 \\geq \\theta_2$が明らかな場合の仮説は、\r$$\r\\mathrm{Order-restricted~~Model:} \\begin{cases}\rH_0:\\delta=0 \\\\\\\\\rH_2:\\delta \\geq 0\r\\end{cases}\r$$\r ところで、ここまでグラフィカルモデルは対応のないグループ間の比率の差の検定を考えていましたが、冒頭で言ったように、対応のあるグループについても同じモデルで包括出来てしまいます。ここではその理由について説明しようと思います。 対応のあるグループ間の比率の差を考えたい場合のグラフィカルモデルは以下のようになります。 $\\theta_1$、$\\theta_2$、$\\delta$の三角関係が変わっていますが、$\\theta_1$と$\\theta_2$まわりの尤度計算は対応の無い場合と同じです。さらに$\\theta_1$、$\\delta$に図示の無情報事前分布を設定してやると、$\\theta_2$の事前分布は$\\mathrm{Uniform}(0,1)$と、対応の無い場合と同じ事前分布になってしまいます。つまり、$\\theta_1$、$\\theta_2$の尤度関数と事前分布が対応の場合と同じになってしまうのです。$\\delta$は$\\theta_2-\\theta_1$と、二つの確率変数の差の分布から求まりますから、$\\delta$の事後分布は対応の無い場合の事後分布の$y$軸反転になります。よって、比率の差の検定においてはモデル上、対応の有無を問わず一つのモデルで説明出来てしまうのです。（以上、色々考えた上での私見なんですが、どうなんでしょう？） ベイズファクターを解析的に求める 設定した仮説から分かる通り、本検定はネストされたモデル間の比較を行うので、以前の記事で紹介したSavage-Dickey法を使えばよいと分かります。Savage-Dickey法は、$H_1$に対応するモデルにおける事前分布と事後分布を一点比較をすればベイズファクターを算出できると主張しています。今回の事例では比較する点は$\\delta=0$です。つまり $$ BF_{01} = \\cfrac{p(\\delta=0 | D, H_1)}{p(\\delta=0 |H_1)} \\tag{5} $$ ということになります。ここで$D$は全データセットを示します。 この節では本モデルにおける$\\delta$の事前分布、事後分布について考え、ベイズファクターを解析的に求めてみます。 まずは$\\delta$の事前分布です。 ◆$\\delta$の事前分布\r$\\delta$の事前分布$p(\\delta | H_1)$は重心0の三角分布となる。 $$ p(\\delta | H_1) = \\begin{cases} 1+\\delta ~~~ \\mathrm{for} ~ \\delta \\le 0 \\\\ 1-\\delta ~~~ \\mathrm{for} ~ \\delta \u0026gt; 0 \\end{cases} \\tag{6} $$\r 証明は以下を参照のこと。証明では確率変数の変換公式を応用して確率変数の和（差）の分布を求めるテクニックを用います。 ◆$\\delta$の事前分布の導出\r確率密度$f_{\\boldsymbol{X}^n}$を持つ$n$次元確率ベクトル$\\boldsymbol{X}^n$に一対一の写像$\\boldsymbol{\\phi}^n$で$\\boldsymbol{X}^n = \\boldsymbol{\\phi}^n(\\boldsymbol{Y}^n)$と対応付けされる$n$次元確率ベクトル$\\boldsymbol{Y}^n$の確率密度$g_{\\boldsymbol{Y}^n}$を求める。\r$$\r\\begin{cases}\rX_1 = \\phi_1(Y_1,Y_2,\\ldots,Y_n) \\\\\\\\\rX_2 = \\phi_2(Y_1,Y_2,\\ldots,Y_n) \\\\\\\\\r\\vdots \\\\\\\\\rX_n = \\phi_n(Y_1,Y_2,\\ldots,Y_n)\r\\end{cases}\r$$\r領域$B = \\prod_{i=1}^{n}(-\\inf,y_i] \\in \\mathbb{R}^n$ での$g_{\\boldsymbol{Y^n}}$の積分値と領域$\\boldsymbol{\\phi}(B)$での$f_{\\boldsymbol{X^n}}$の積分値が一致することから、\r$$\r\\int\\cdots\\int_B g_{\\boldsymbol{Y^n}}(y_1,\\ldots,y_n) dy_1\\ldots dy_n = \\left|\\int\\cdots\\int_{\\boldsymbol{\\phi}(B)} f_{\\boldsymbol{X^n}}(x_1,\\ldots,x_n) dx_1 \\ldots dx_n\\right|\r$$\r右辺の多重積分について、積分変数を$(x_1,\\ldots,x_n)$から$(y_1.\\ldots,y_n)$に変換する。\r$$\r\\left|\\int\\cdots\\int_{\\boldsymbol{\\phi}(B)} f_{\\boldsymbol{X^n}}(x_1,\\ldots,x_n) dx_1\\ldots dx_n\\right| = \\int\\cdots\\int_{B} f_{\\boldsymbol{X^n}}(\\phi_1(y_1,\\ldots,y_n),\\ldots,\\phi_n(y_1,\\ldots,y_n)) || J_{\\boldsymbol{\\phi}^n} || dy_1 \\ldots dy_n\r$$\rここで$\\left|\\left|J_{\\boldsymbol{\\phi}^n}\\right|\\right|$はヤコビアンであり変数変換後の単位面積のスケールを調整する役割をもつ。\r$$\r\\left|\\left|J_{\\boldsymbol{\\phi}^n}\\right|\\right| = \\cfrac{dy_1 dy_2\\ldots dy_n}{dx_1 dx_2\\ldots dx_n}\r$$\r以上より\r$$\r\\int\\cdots\\int_B g_{\\boldsymbol{Y^n}}(y_1,\\ldots,y_n) dy_1\\ldots dy_n = \\int\\cdots\\int_{B} f_{\\boldsymbol{X^n}}(\\phi_1(y_1,\\ldots,y_n),\\ldots,\\phi_n(y_1,\\ldots,y_n)) || J_{\\boldsymbol{\\phi}^n} || dy_1 \\ldots dy_n\r$$\rすなわち\r$$\rg_{\\boldsymbol{Y^n}}(y_1,\\ldots,y_n) = f_{\\boldsymbol{X^n}}(\\phi_1(y_1,\\ldots,y_n),\\ldots,\\phi_n(y_1,\\ldots,y_n)) || J_{\\boldsymbol{\\phi}^n} || \\tag{確率変数の変換公式}\r$$\r次に、確率変数$\\Theta_1$、$\\Theta_2$に対して、$\\Delta = \\Theta_1 - \\Theta_2$の分布を求める。以下の一対一写像\r$$\r{\\boldsymbol{\\phi}^{2}}^{-1} = \\begin{cases}\r\\Delta = \\Theta_1 - \\Theta_2 \\\\\\\\\rΕ = \\Theta_2\r\\end{cases}\r$$\rを考える。このとき、\r$$\r\\boldsymbol{\\phi}^{2} = \\begin{cases}\r\\Theta_1 = \\Delta + Ε \\\\\\\\\r\\Theta_2 = Ε\r\\end{cases}\r$$\rヤコビアン$\\left|J_{\\boldsymbol{\\phi}^n}\\right|$は、\r$$\r\\left|J_{\\boldsymbol{\\phi}^n}\\right| = \\cfrac{d\\delta d\\epsilon}{d\\theta_1 d\\theta_2 } = \\left| \\begin{array}{ccc}\r\\cfrac{\\partial \\theta_1}{\\partial \\epsilon} \u0026 \\cfrac{\\partial \\theta_1}{\\partial \\delta} \\\\\r\\cfrac{\\partial \\theta_2}{\\partial \\epsilon} \u0026 \\cfrac{\\partial \\theta_2}{\\partial \\delta}\r\\end{array} \\right| = \\left|\\begin{array}{ccc}\r1 \u0026 1 \\\\\\\\\r1 \u0026 0\r\\end{array}\\right| = -1\r$$\r$\\Theta_1$、$\\Theta_2$が独立の一様分布に従うと仮定したとき、確率変数の変数変換の公式より、$\\Delta$、$Ε$の結合確率密度は、\r$$\r\\begin{split}\rg_{\\Delta,Ε}(\\delta, ϵ) \u0026=\u0026 f_{\\Theta_1,\\Theta_2}(\\delta+\\epsilon,\\epsilon)\\left|\\left|J_{\\boldsymbol{\\phi}^2}\\right|\\right| = f_{\\Theta_1,\\Theta_2}(\\delta+\\epsilon,\\epsilon)\r= f_{\\Theta_1}(\\delta+\\epsilon)f_{\\Theta_2}\\epsilon\\\\\\\\\r\u0026=\u0026 \\begin{cases}\r1~~~\\mathrm{for}~~~ 0 \\leq \\delta + \\epsilon \\leq 1~~\\cap~~0 \\leq \\epsilon \\leq 1 \\\\\\\\\r0~~~\\mathrm{for~~~otherwise}\r\\end{cases}\r\\end{split}\r$$\rこれを$Ε$について積分し、$\\Delta$の周辺確率密度を求める。\r$-1\\leq \\delta 0\r\\end{cases}\r$$\r\r 事前分布について$p(\\delta=0 |H_1)=1$であることがわかりました。よって、$BF_{01} = p(\\delta=0 | D, H_1)$となります。 これを求めた結果を示します。 ◆比率の差の検定におけるベイズファクター\r比率の差を検定するためのベイズファクター$BF_{01}$は $$ BF_{01} = \\cfrac{{}_{n_{1}} C _ {s_{1}} {}_ {n_{2}} C _ {s_{2}}}{{}_ {n_1+n_2} C _ {s_1+s_2}}\\cfrac{(n_1+1)(n_2+1)}{n_1+n_2+1} \\tag{7} $$\r 証明は以下を参照のこと。周辺尤度を無視した事後分布の計算と、確率変数の変換公式を応用して確率変数の和（差）の分布を求めるテクニックを用います。 ◆$p(\\delta=0 | D, H_1)$の導出\r$\\delta = \\theta_1 - \\theta_2$であるから、$p(\\theta_1 | D^{n_1},H_1)$と$p(\\theta_2 | D^{n_2},H_1)$を求め、これらの差の分布を求めることを考える$(D = D^{n_1}+D^{n_2})$。一様分布$\\mathrm{Uniform}(0,1)$はベータ分布$\\mathrm{Beta}(1,1)$に等しいから、\r$$\r\\begin{cases}\rp(\\theta_1 | D^{n_1}, H_1) ∝ \\mathrm{Binomial}(s_1|\\theta_1, n_1) \\mathrm{Beta}(\\theta_1 | 1,1)　\\\\\\\\\rp(\\theta_2 | D^{n_2}, H_1) ∝ \\mathrm{Binomial}(s_2|\\theta_2, n_2) \\mathrm{Beta}(\\theta_2 | 1,1)\r\\end{cases}\r$$\rここで、\r$$\r\\begin{split}\rp(\\theta_1 | D^{n_1}, H_1) \u0026=\u0026 \\cfrac{{}_{n_{1}} C _ {s_{1}}}{\\mathrm{B}(1,1)}\\theta_1^{s_1}(1-\\theta_1)^{n_1 - s_1} \\\\\\\\\r\u0026∝\u0026 \\mathrm{Beta}(\\theta_1 | s_1+1, n_1-s_1+1)\r\\end{split}\r$$\rよって、\r$$\r\\begin{cases}\rp(\\theta_1 | D^{n_1}, H_1) = \\mathrm{Beta}(\\theta_1 | s_1+1, n_1-s_1+1)　\\\\\\\\\rp(\\theta_2 | D^{n_2}, H_1) = \\mathrm{Beta}(\\theta_2 | s_2+1, n_2-s_2+1)\r\\end{cases}\r$$\rここで、確率変数$\\Theta_1$、$\\Theta_2$に対して、$\\Delta = \\Theta_1 - \\Theta_2$の分布を求めると、\r$$\rg_{\\Delta,Ε}(\\delta, ϵ) = f_{\\Theta_1,\\Theta_2}(\\delta+\\epsilon,\\epsilon)\\left|\\left|J_{\\boldsymbol{\\phi}^2}\\right|\\right| = f_{\\Theta_1,\\Theta_2}(\\delta+\\epsilon,\\epsilon)\r= f_{\\Theta_1}(\\delta+\\epsilon)f_{\\Theta_2}\\epsilon\r$$\rこれを$\\epsilon$について積分して、\r$$\rg_{\\Delta}(\\delta) = \\int_{-1}^{1}f_{\\Theta_1}(\\delta+\\epsilon)f_{\\Theta_2}\\epsilon d\\epsilon\r$$\r$f_{\\Theta_1}(\\theta_1)$、$f_{\\Theta_1}(\\theta_1)$について\r$$\r\\begin{cases}\rf_{\\Theta_1}(\\theta_1) = \\mathrm{Beta}(\\theta_1 | s_1+1, n_1-s_1+1)　\\\\\\\\\rf_{\\Theta_1}(\\theta_2) = \\mathrm{Beta}(\\theta_2 | s_2+1, n_2-s_2+1)\r\\end{cases}\r$$\rを代入すると、\r$$\r\\begin{split}\rg_{\\Delta}(\\delta) \u0026=\u0026 \\int_{-1}^{1}f_{\\Theta_1}(\\delta+\\epsilon)f_{\\Theta_2}\\epsilon d\\epsilon \\\\\\\\\r\u0026=\u0026 \\int_{-1}^{1} \\mathrm{Beta}( \\delta+\\epsilon | s_1+1, n_1-s_1+1)\\mathrm{Beta}(\\delta | s_2+1, n_2-s_2+1) d\\epsilon \\\\\\\\\r\u0026=\u0026 \\int_{-1}^{1}\\cfrac{(\\delta+\\epsilon)^{s_1}(1-\\delta-\\epsilon)^{n_1-s_1}\\epsilon^{s_2}(1-\\epsilon)^{n_2-s_2}}{\\mathrm{B}(s_1+1,n_1-s_1+1)\\mathrm{B}(s_2+1,n_2-s_2+1)}d\\epsilon\r\\end{split}\r$$\r求めたいのは $\\left.g_{\\Delta}(\\delta)\\right|_{\\delta=0}$なので、\r$$\r\\begin{split}\r\\left.g_{\\Delta}(\\delta)\\right|_{\\delta=0} \u0026=\u0026 \\cfrac{1}{\\mathrm{B}(s_1+1,n_1-s_1+1)\\mathrm{B}(s_2+1,n_2-s_2+1)} \\int_{-1}^{1}\\epsilon^{s_1}(1-\\epsilon)^{n_1-s_1}\\epsilon^{s_2}(1-\\epsilon)^{n_2-s_2}d\\epsilon \\\\\\\\\r\u0026=\u0026 \\cfrac{\\mathrm{B}(s_1+s_2+1,n_1+n_2-s_1-s_2+1)}{\\mathrm{B}(s_1+1,n_1-s_1+1)\\mathrm{B}(s_2+1,n_2-s_2+1)} \\int_{-1}^{1} \\mathrm{Beta}(\\epsilon | s_1+s_2+1,n_1+n_2-s_1-s_2+1)d \\epsilon \\\\\\\\\r\u0026=\u0026\\cfrac{\\mathrm{B}(s_1+s_2+1,n_1+n_2-s_1-s_2+1)}{\\mathrm{B}(s_1+1,n_1-s_1+1)\\mathrm{B}(s_2+1,n_2-s_2+1)} \\\\\\\\\r\u0026=\u0026 \\cfrac{{}_{n_{1}} C _ {s_{1}} {}_ {n_{2}} C _ {s_{2}}}{{}_ {n_1+n_2} C _ {s_1+s_2}}\\cfrac{(n_1+1)(n_2+1)}{n_1+n_2+1}~~~(\\mathrm{B}(a,b)=\\cfrac{(a-1)!(b-1)!}{(a+b-1)!}より)\r\\end{split}\r$$\rよって、\r$$\r\\begin{split}\rp(\\delta=0 | D, H_1) \u0026=\u0026 \\left( \\left. \\mathrm{Binomial}(s_1|\\theta_1, n_1) \\mathrm{Beta}(\\theta_1 | 1,1) - \\mathrm{Binomial}(s_2|\\theta_2, n_2) \\mathrm{Beta}(\\theta_2 | 1,1) \\right) \\right | _{\\theta_1 - \\theta_2=0} \\\\\\\\\r\u0026=\u0026 \\cfrac{{}_ {n_{1}} C _ {s_{1}} {}_ {n_{2}} C _ {s_{2}}}{{}_ {n_1+n_2} C _ {s_1+s_2}}\\cfrac{(n_1+1)(n_2+1)}{n_1+n_2+1}\r\\end{split}\r$$\r\r おわりに 今回は、比率の差をベイズファクターを使って検定する手法を整理しました。本内容の実践版はこちらの姉妹記事を参照してください。姉妹記事では解析的にベイズファクターを計算するだけではなく、MCMCを用いた近似手法でも計算しています。なぜ精度の劣る方法で…と思うかもしれませんが、従来通りの検定に対応する帰無仮説・対立仮設の設定に留まらず、片側検定に対応する仮説の比較をすることもできることにそのメリットがあります。詳しくは姉妹記事を参照のこと。"
  },
  {
    url: "https://sucre-stat.com/2021/04/savage-dickey-method/",
    title: "ベイジアン仮説検定とSavage-Dickey法",
    date: "2021-04-03T00:00:00Z",
    body: "ベイジアン仮説検定とSavage-Dickey法 今回はベイジアン仮説検定とSavage-Dickey法について取り上げます。 ベイジアン仮説検定は、従来の頻度論に基づく考え型とは異なるベイズの考え方を用いた仮説検定です。一般的な仮説検定には無いメリットを持っており、近年注目されています。 Savage-Dickey法は、以前の記事で紹介したベイズファクターを簡単に求めるための手法の一つです。この手法が適用できる場面は、比較対象となる2つのモデルがネストされた関係にある場合（後述）に限られるのですが、これは多くの一般的な仮説検定の枠組みへ応用できる条件であることから、ベイジアン仮説検定のための重要な手法とされています。 参考記事を以下に列挙します。 Bayesian hypothesis testing for psychologists: A tutorial on the Savage–Dickey method Using MCMC chain outputs to efficiently estimate Bayes factors ベイズファクターによる心理学的仮説・モデルの評価 ベイジアン仮説検定 ベイジアン仮説検定は、文字通りベイズの考え方を用いた仮説検定です。そしてこれは以前の記事で紹介したベイズファクターを用いた検定になります。 ◆ベイズファクター\r2つの異なるモデル$M_0$、$M_1$を考えたとき、ベイズファクター$BF_{01}$は2つの異なるモデルの周辺尤度の比として定義される。 $$ BF_{10} = \\cfrac{p(x^n | M_0)}{p(x^n |M_1)} \\tag{1} $$ ここで、$p(x^n | M)$はモデル$M$における周辺尤度、$x^n$は$n$組の確率変数$X^n$からの実現値である。\r 周辺分布$p(x^n |M)$は、事前分布と事後分布の積をモデル$M$のパラメータについて周辺化消去した値であり、$x^n$の同時確率密度とみなせることから、モデルの平均的な説明力の高さの指標となるのでした。そしてベイズファクターは2つの比較モデルの周辺尤度の比較をしているのでしたな。 ところで、従来の仮説検定では帰無仮説と対立仮設を設定することから始まりますが、ベイズファクターを用いた仮説検定では帰無仮説と対立仮設の設定はどうすればよいのかナ？ 帰無仮説と対立仮説 ここで仮説検定の手順について整理します。 ◆仮説検定の手順\r 棄却したい仮説として、帰無仮説（$H_0$）を、帰無仮説と対立する仮説として対立仮説（$H_1$）を設定する 検定統計量を計算する $H_0$が正しいと仮定したとき、検定統計量が漸近的に所定の分布に従うことを用いて、観測事象よりも極端な事象が起きる確率（p値）を求める p値を有意水準と比較し、帰無仮説を棄却するかどうかを決定する 帰無仮説には、例えば平均値の差の検定の場合、2組の母集団における量の平均$\\mu_1$、$\\mu_2$が等しい（$\\mu_1 = \\mu_2$）という仮説を設定します。また回帰係数の検定$\\beta$では係数が0である（$\\beta=0$）という仮説を設定します。これらの対立仮説はそれぞれ、$\\mu_1 \\neq \\mu_2$、$\\beta \\neq 0$です。 このように、二つの仮説に共通するパラメータ（平均値の差の検定の例ではパラメータの個数1で$\\mu_1 - \\mu_2$、回帰の例でもパラメータの個数1で$\\beta$）に対し、帰無仮説ではパラメータ空間上の1点を、対立仮説ではそれ以外を仮説と整合的なパラメータ空間として設定することになります。 ベイズファクターを用いてこのような2つの仮説の比較を行う場合を、以下のように整理することができます。 ◆ベイズファクターを用いた仮説検定\r2つの仮説$H_0$、$H_1$の比較を考えたとき、ベイズファクター$BF_{01}$は2つの仮説のもとでの周辺尤度の比として定義される。またこれは対立仮説$H_1$のみを用いても定義できる。 $$ BF_{01} = \\cfrac{p(x^n | H_0)}{p(x^n |H_1)} = \\cfrac{p(x^n | \\boldsymbol{\\theta} = \\boldsymbol{\\theta_0},H_1)}{p(x^n |H_1)} \\tag{2} $$ ここで、$p(x^n | M)$はモデル$M$における周辺尤度、$x^n$は$n$組の確率変数の$X^n$からの実現値である。また$\\boldsymbol{\\theta_0}$は帰無仮説に整合的なパラメータ空間上の1点を示す。\r $(2)$式において気を付けなければならないのは、分母が$p(x^n | \\boldsymbol{\\theta} \\neq \\boldsymbol{\\theta_0},H_1)$ではなく$p(x^n |H_1)$としている点です。このようにしても対立仮説との比較が可能な理由は、定義に基づき$H_1$のときの周辺尤度をパラメータについての周辺化（積分）で計算するときに、パラメータ空間に比して、パラメータ空間上の1点（$\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0$となる点）が無視してよい程小さいからです。 また、このように$H_1$がより一般化したモデル$H_1$の特別な場合に値するような状態を、「$H_0$は$H_1$にネストされている」とか単に「ネストされたモデル」などと呼びます。 以下では帰無仮説と対立仮説の一般的な記法$H_0$、$H_1$を用いずそれぞれ$M_0$、$M_1$と記述しますが、適宜読み替えて下さい。 ベイズファクターの特長 上のようにベイズファクターを用いて帰無仮説と対立仮説の比較をするメリットを列挙していきます。 ・基本的な量である 以前の記事で見たように、ベイズファクターは自由エネルギーや周辺尤度から計算される、モデルの説明力の指標となる基本的な量です。この指標を用いて簡潔に仮説の比較を行うことが可能となります。 またこの特徴から（周辺尤度がcoherenceな量であるため）、以下のように3モデル以上の比較も可能です。 $$ \\cfrac{p(x^n | M_1)}{p(x^n | M_3)} = \\cfrac{p(x^n | M_1)}{p(x^n | M_2)} \\cfrac{p(x^n | M_2)}{p(x^n | M_3)} \\tag{3} $$ ・モデル同士の平等な比較を行う ベイズファクターは2つのモデルの周辺尤度の比であることから、2つの仮説を対等に比較することができます。これはつまり、帰無仮説に対応するモデルを支持する根拠も、それに反する根拠もまったく同じように得られるということであり、帰無仮説を支持するという結論を導くことも可能である、ということです。 これに対し、従来の仮説検定では帰無仮説が正と仮定したうえでの背理法に基づく対立仮説の採択しかできない為、結論は、「帰無仮説を棄却し、対立仮説を採択する」もしくは「帰無仮説を棄却できないが採択もしない」の2択となります。このような仮説の非対称性は、頻度論に基づく仮説検定に対する批判の1つとなっています。 ・結果が解釈しやすい ベイズファクターによる仮説検定で得られる結果は「$H_0$に比して$H_1$が正しい確率は〇〇%」であるといったものになります。これがとても分かりやすい。p値を用いた仮説検定ではそうはいきません。p値は「帰無仮説が正しいと仮定したもとで、観測値よりも極端な値が観測される確率」という、厄介な値を示すものだからです。 ・逐次更新が可能 従来の仮説検定は、事前にサンプリング計画を設定し、予定した数のデータが蓄積して初めて実施する必要があります。検定の結果、仮に有意な結果が得られず、さらにデータを追加して再度検定を実施しようとすると、第1種の過誤を犯す確率が本来の確率よりも大きくなってしまいます。 これに対し、ベイズ統計は事前データから事後データへの更新が理論的に可能ですので、ベイズファクターについて定めた閾値に達するまでデータを逐一追加していき、閾値に達した時点でデータの収集をストップすることが問題なく可能となります。 ・複数のモデルの組み合わせに利用できる ベイズファクターを2つのモデルの重みづけ係数として利用し、回帰係数を算出することも可能です。 ・オッカムの剃刀効果をもつ つまり、同程度の説明力をもつモデルがあるとすれば、ベイズファクターはよりシンプルなモデルを選択する、ということです。この性質は以前の記事での実験で確認したものになります。 この理由は、周辺分布$p(x^n |M)$が、事前分布と事後分布の積をモデル$M$のパラメータについて周辺化消去した値であることからイメージすることが可能です。つまり、モデルを複雑にする（パラメータ空間をむやみに拡張する）と、尤度が0に近くなる空間が大部分を占めることとなり、それが平均的な周辺尤度を小さくする要因となるんです。 ベイズファクターの課題 ベイズファクターを用いたモデル比較には課題もあります。以下、課題を列挙します。 ・着目するパラメータの事前分布の設定の影響を受けやすい これは、周辺分布$p(x^n |M)$が事前分布と事後分布の積をモデル$M$のパラメータについて周辺化消去した値であることからも自明です。 では、無情報事前分布を設定してやればよいかというとそうもいきません。なぜなら、無情報事前分布を設定すると、尤度が0に近くなる部分においてもパラメータについて必要以上の確率密度を設定することになってしまい、観測値がどうであれよりシンプルな帰無仮説に対応するモデルを強制的に採択することになってしまうからです。（オッカムの剃刀効果を持つ理由と同じですな） これに対する解決策として、客観ベイズの研究により導かれた既定事前分布を用いる、というものがあります。既定事前分布は、研究者の間で合意のとれた、典型的な応用場面で汎用的に用いることのできる事前分布です。これについてはまた別の記事取り上げたいです…。 ・計算が困難な場合が多い ベイズファクターは、定義に従うならば以下のように計算しなければなりません。 $$ BF_{01} =\\cfrac{\\int_{S_{\\theta_1}}\\int_{S_{\\theta_2}}\\ldots\\int_{S_{\\theta_n}} p(x^n|\\boldsymbol{\\theta},M_0)\\varphi(\\boldsymbol{\\theta}|M_0) d\\theta_n \\ldots d\\theta_2 d\\theta_1}{\\int_{S_{\\theta_1}}\\int_{S_{\\theta_2}}\\ldots\\int_{S_{\\theta_n}} p(x^n|\\boldsymbol{\\theta},M_1)\\varphi(\\boldsymbol{\\theta}|M_1) d\\theta_n \\ldots d\\theta_2 d\\theta_1} \\tag{4} $$ ここで、$p(x^n | M)$は観測値$x^n$が与えられたときのモデル$M $の尤度関数、$\\varphi(M)$はモデル$M$の事前分布です。$\\boldsymbol{\\theta}$はモデル$M_1$、$M_2$に共通するパラメータであり、$\\boldsymbol{\\theta}=(\\theta_1,\\theta_2,\\ldots,\\theta_n),~~~\\theta_1 \\in S_{\\theta_{1}},\\theta_2 \\in S_{\\theta_{2}},\\ldots,\\theta_n \\in S_{\\theta_{n}},~~~S_{\\theta} ∈ \\mathbb{R}$です。 以前の記事での実験では、事前分布に尤度関数と共役な関係にある共役事前分布を用いたため、上記の計算が可能だったのですが、多くの場面でこの計算は解析的には困難です。 これに対する解決策として、以降ではSavage-Dickey法について説明していきます。 Savage-Dickey法 Savage-Dickey法の概要を以下に示します。 ◆Savage-Dickey法\rモデル$M_0$と$M_1$に共通のパラメータ$\\boldsymbol{\\theta}$があるとき、$M_0$と$M_1$が $$ p(x^n | M_0) = p(x^n | \\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0, M_1) \\tag{5} $$ とネストされた関係にある場合、ベイズファクター$BF_{01}$は下記のとおり計算できる。 $$ BF_{01} = \\cfrac{p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0 | x^n, M_1)}{p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0 |M_1)} \\tag{6} $$ $(6)$式$\\boldsymbol{\\theta}_0$は、前述の帰無仮説に整合なパラメータ空間上の一点を指しますが、ここでは任意の一点であると考えて差支えありません。 分母$p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0 | x^n, M_1)$は、$x^n$、$M_1$が与えられたときの事後分布における、$\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0$上の確率密度、分子$p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0 |M_1)$は、$M_1$の事前分布における$\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0$上の確率密度を意味します。 Savage-Dickey法の利点は、$(4)$式のような周辺尤度を用いたベイズファクターの定義を一旦忘れて、より一般化された方のモデルの事前分布と事後分布の一点比較をするだけでベイズファクターを求められるという簡便さにあります。なぜ簡便かというと、事後分布を求めるだけでよいのならば、これはもうMCMCを用いた推定手法の独擅場だからですネ。 $(2)$式のような仮説検定の枠組み上では、$(6)$式は常に成立します。その証明を以下に示します。 ◆仮説検定の文脈でSavage-Dickey法が成立することの証明\rベイズルールより、\r$$\rp(x^n | \\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0, H_1) = \\cfrac{p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0|x^n,H_1) p(x^n|H_1)}{p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0|H_1)}\r$$\rよって、\r$$\rBF_{01} = \\cfrac{p(x^n | H_0)}{p(x^n |H_1)} = \\cfrac{p(x^n | \\boldsymbol{\\theta} = \\boldsymbol{\\theta_0},H_1)}{p(x^n |H_1)} = \\cfrac{p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0|x^n,H_1)}{p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0|H_1)}\r$$\r\r また、仮説検定の対象となるパラメータ$\\boldsymbol{\\theta}$の他にも別の共通したパラメータが存在した場合、そのパラメーターはベイズファクターの結果に$\\boldsymbol{\\theta}$を介してのみしか影響しないことが知られています。その証明を、Savage-Dickey法の一般的な証明として以降に示します。 ◆Savage-Dickey法の証明\rモデル$M_0$と$M_1$に共通のパラメータ$\\boldsymbol{\\theta},\\boldsymbol{\\psi}$があり、$\\boldsymbol{\\psi}$についての条件付き確率密度が$\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0$付近で連続であると仮定する。\r$$\rp(x^n | \\boldsymbol{\\psi}, M_0) = p(x^n | \\boldsymbol{\\psi}, \\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0, M_1) \\tag{★}\r$$\r及び\r$$\rp(\\boldsymbol{\\psi} | M_0) = p(\\boldsymbol{\\psi} | \\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0, M_1) \\tag{☆}\r$$\rが成立するとき、$M_0$のもとでの周辺尤度$p(x^n|M_0)$は、\r$$\r\\begin{split}\rp(x^n|M_0) \u0026=\u0026 \\int_{S_{\\psi_1}} \\int_{S_{\\psi_2}}\\ldots\\int_{S_{\\psi_m}}\rp(x^n | \\boldsymbol{\\psi},M_0)p(\\boldsymbol{\\psi}|M_0)d\\psi_{m}\\ldots d\\psi_{2}d\\psi_{1} \\\\\\\\\r\u0026=\u0026 \\int_{S_{\\psi_1}} \\int_{S_{\\psi_2}}\\ldots\\int_{S_{\\psi_m}}\rp(x^n | \\boldsymbol{\\psi},\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0, M_1)p(\\boldsymbol{\\psi}|\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0,M_1)d\\psi_{m}\\ldots d\\psi_{2}d\\psi_{1} \\\\\\\\\r\u0026=\u0026 p(x^n | \\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0, M_1)\r\\end{split}\r$$\rここで、$\\boldsymbol{\\psi}=(\\psi_1,\\psi_2,\\ldots,\\psi_m),~~~\\psi_1 \\in S_{\\psi_{1}},\\psi_2 \\in S_{\\psi_{2}},\\ldots,\\psi_m \\in S_{\\psi_{m}},~~~S_{\\psi} ∈ \\mathbb{R}$である。また、ベイズルールより\r$$\rp(x^n | \\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0, M_1) = \\cfrac{p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0|x^n,M_1)p(x^n|M_1)}{p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0|,M_1)}\r$$\rよって、\r$$\rBF_{01} = \\cfrac{p(x^n | M_0)}{p(x^n |M_1)} = \\cfrac{p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0|x^n,M_1)}{p(\\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0|M_1)}\r$$\r\r 上記証明において仮定した$(★)$は、$(5)$式と同様、$M_0$が$M_1$にネストされた関係であることを示します。さらに$(☆)$が新たな仮定として追加されましたが、これはネストされた関係にあるモデルでは常に成り立つと考えて問題無いと思います。ちなみに$\\boldsymbol{\\theta}$と$\\boldsymbol{\\psi}$が独立であれば$(☆)$は常に成立します。 上記証明では両モデルに共通するパラメータを、我々の関心対象である$\\boldsymbol{\\theta}$と、それ以外の関心のない（nuisance、厄介な）$\\boldsymbol{\\psi}$に分けています。$(★)$及び$(☆)$が成立するとき、最終的な$BF_{01}$の導出にパラメータ$\\boldsymbol{\\theta}$は出てきているが$\\boldsymbol{\\psi}$は出てきていないので、上記証明は、$\\boldsymbol{\\psi}$は$\\boldsymbol{\\theta}$を介してのみしか$BF_{01}$に影響しない、ということを示しています。 おわりに 前回に引き続き、今回もベイズファクターにまつわる内容を書きました。 前回の記事では、ベイズファクターについて一からその正体を見ていきました。今回はその続編的な内容で、ベイズファクターが仮説検定に利用可能であること、また仮説検定にベイズファクターを用いることの利点や課題、さらに簡便なベイズファクターの計算手法であるSavage-Dickey法について書きました。 これでベイジアン仮説検定を実践するための準備が整ったので、次回以降では実際にベイジアン仮説検定をやっていきたいと思います。"
  },
  {
    url: "https://sucre-stat.com/2021/02/bayesfactor/",
    title: "ベイズファクター",
    date: "2021-02-14T00:00:00Z",
    body: "ベイズファクター 本記事ではベイジアンモデルに対するモデル評価の指標であるベイズファクターについて理論を整理します。 まず、情報量について、エントロピーを踏まえながら理解します。次に、情報量から自由エネルギーを定義し、これが周辺尤度とも深く関連することを理解します。以上の理論的な準備を踏まえ、ベイズファクターを定義します。 後半では、具体的な確率分布を用いた計算を例に自由エネルギーやベイズファクターを計算し、それらを用いたモデル評価の性質をシミュレーションで確認します。 参考にした本はこちらです。モデル評価の指標について分かりやすい説明が並んでいます。この本によれば、モデル評価の指標は自由エネルギーに着目したもの（BIC、WBIC、ベイズファクター）と、汎化誤差に着目したもの（AIC、WAIC）に二分されるようですが、本記事ではそのうち前者の方の、ベイズファクターのみに着目して考えます。 情報量 確率がからむある試行について考えたとき、その試行の結果得られた事象が持っている情報の多さはどのくらいなのか？ 事象のもつ情報の多さ、すなわち情報量を定量的に表現するための関数$f$の条件について考えます。 連続型の確率変数$X$及びその実現値$x$について、情報量は$P(x)$に依存すると考えられることから、まず関数$f$は$P(x)$を変数にとることとします。 次に、情報量をあらわす$f(P(x))$について望ましい性質として、以下が考えられます。 $$\rP(x_i) \\leq P(x_j) \\Rightarrow f(P(x_i)) \\geq f(P(x_j)) \\tag{1}\r$$\r$$\rf(P(x_i)P(x_j)) = f(P(x_i))f(P(x_j)) \\tag{2}\r$$\r$$\rf(P(x_i)=1) = 0 \\tag{3}\r$$\r $(1)$式は、事象が起きる確率が低い程、その事象が持つ驚きの強さ（情報量）が大きくなるような条件です。 $(2)$式は、2つの事象を1回の試行で同時に得るようなときと、それらの事象を2回の試行で一つひとつ得るようなときの情報量が同じになることを意味する条件です。 $(3)$式は、ある事象が起きる確率が1のとき、情報量が0であることを意味する条件です。 これらの条件を満たす関数として、以下の情報量が導出されます。 ◆情報量\r連続型の確率変数$X$から実現値$x$が得られたときの情報量は、以下で定義される。 $$ I(X = x) = -\\log{P(X = x)}　\\tag{4} $$\r ◆情報量の証明\r$x ∈ \\mathbb{R}$について微分可能な関数$f(x)$について、条件$(2)$より、\r$$\rf(x(1 + \\delta)) = f(x + x\\delta) = f(x) + f(1 + \\delta)\r$$\r二つ目の等号より、\r$$\r\\cfrac{f(x + x\\delta) - f(x)}{x\\delta} = \\cfrac{f(1 + \\delta)}{x\\delta}\r$$\r左辺は導関数の定義であるから、\r$$\rf^{'}(x) = K\\cfrac{1}{x}\r$$\rただし、$K = \\cfrac{f(1 + \\delta)}{\\delta}$。\r上式を積分して、\r$$\rf(x) = K\\log{x} + C\r$$\rここで、条件(1)より、$K$は任意の負の実数である。 また条件$(3)$より、$C=1$。\rよって、$K=-1$とすることにより$(4)$式が導かれる。\r\r エントロピー エントロピーは、前節で定義した情報量の期待値です。そのため平均情報量とも呼ばれます。 ◆エントロピー\r$A ∈ \\mathbb{R}$上で定義された確率密度関数$f(x)$をもつ連続型の確率変数$x$のエントロピー$H(X)$を情報量の期待値として下記のとおり定義する。 $$ H(X) = - \\int_{A} f(x)\\log{f(x)}dx \\tag{5} $$ 同様に、確率質量関数$g(x)$をもつ離散型の確率変数$X$のエントロピー$H(X)$を以下の通り定義する。 $$ H(X) = \\sum_{i=1}^{n}-g(x_i)\\log{g(x_i)} \\tag{6} $$ エントロピーは、情報量の期待値ですから、確率分布の分散が大きいような、不確実性の大きな条件下でより大きな値を取ることが想定されます。これをガンマ分布を例に確認してみましょう。 shapeパラメータ$a$、rateパラメータ$b$をもつガンマ分布 $$\r\\mathrm{Gamma}(\\lambda | \\alpha, \\beta) = \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\lambda^{\\alpha -1} e^{-\\beta x} \\tag{7}\r$$\r の形状は、下図ようになっています。ここで、$\\lambda ∈ \\mathbb{R}^+, \\alpha∈ \\mathbb{R}^+, \\beta ∈ \\mathbb{R}^+$です。 1つ目の図はrateパラメータ固定、shapeパラメータを変化させたときのガンマ分布の形状を示しています。また2つ目の図はshapeパラメータ固定、rateパラメータを変化させたときのガンマ分布の形状を示しています。 これらの図から、shapeパラメータが大きくなるほどまたrateパラメータが小さくなるほど分散は大きくなりそうだと確認できます。実際、以前の記事で確認した通り、ガンマ分布の分散は$\\cfrac{\\alpha}{\\beta^2}$です。 では、同様に片方のパラメータを固定したままもう片方のパラメータを変化させたとき、エントロピーはどのように変化するでしょうか。 それを確認するため、まずガンマ分布のパラメータを変数としてエントロピーを計算します。 ◆ガンマ分布のエントロピー\rshapeパラメータ$\\alpha$、rateパラメータ$\\beta$のガンマ分布に従う確率変数$\\lambda$のエントロピーは、\r$$\r\\begin{split}\rH(\\lambda) \u0026= \\mathbb{E}\\left[-\\log{\\lambda}\\right] \\\\\\\\\r\u0026= - \\mathbb{E}\\left[\\alpha\\log{\\beta} - \\log{\\Gamma(\\alpha)} + (\\alpha - 1) \\log{\\lambda} -\\beta\\lambda\\right] \\\\\\\\\r\u0026= -\\alpha\\log{\\beta} + \\log{\\Gamma(\\alpha)} + (1-\\alpha)\\mathbb{E}\\left[\\log\\lambda\\right] + \\beta\\mathbb{E}\\left[\\lambda\\right]\r\\end{split}\r$$\rここで、$\\mathbb{E}\\left[\\lambda\\right] = \\cfrac{\\alpha}{\\beta}$、$\\mathbb{E}\\left[\\log{\\lambda}\\right] = \\psi(\\alpha) - \\log{\\beta}$を用いて、\r$$\r\\begin{split}\rH(\\lambda) \u0026= -\\alpha\\log{\\beta} + \\log{\\Gamma(\\alpha)} + (1-\\alpha)(\\psi(\\alpha) - \\log{\\beta}) + \\beta\\left(\\cfrac{\\alpha}{\\beta}\\right) \\\\\\\\\r\u0026= \\log{\\Gamma(\\alpha)} + (1 - \\alpha){\\psi(\\alpha)} - \\log{\\beta} + \\alpha\r\\end{split}\r$$\rただし、$\\psi(x)$はディガンマ関数であり、ガンマ関数を対数微分したもの。\r\r これを用いてガンマ分布のエントロピーを図示したものが、以下になります。 一つ目の図から、ガンマ分布のエントロピーは、shapeパラメータが大きく、すなわち、分散が大きくなるにつれてエントロピーが増大していることが確認できます。 一方、二つ目の図からは、rateパラメータが小さく、すなわち分散が大きくなるにつれてエントロピーが増大していることが確認できます。 以上、分布のばらつきが大きくなるほどエントロピーが大きくなる例を確認しました。エントロピーを通して、情報量が何をはかろうとしているのかイメージしてもらえるかなと思います。 ベイズ自由エネルギー (逆温度$\\beta = -1$の)ベイズ自由エネルギーは、はじめに述べた情報量について、複数の確率変数$X^n = (X_1, X_2,\\ldots,X_n)$の同時確率分布の場合の拡張について考え、さらにパラメータの事前分布を想定し、パラメータを周辺化消去したものになります。 ◆ベイズ自由エネルギー\r確率変数$X^n=(X_1, X_2,\\ldots,X_n)$とそれらの同時確率分布$f(x^n)$が与えられたとき、ベイズ自由エネルギー$F_n$は以下のとおり定義される。 $$ F_n = -logf(x^n) = -\\log\\int_S f(x^n | \\theta)\\varphi(\\theta) d\\theta \\tag{8} $$ ここで$\\theta$は$S ∈ \\mathbb{R}$で定義されるパラメータ、$\\varphi(\\theta)$はパラメータの事前分布、$x^n = (x_1, x_2, \\ldots, x_n)$は$X^n$の実現値である。\r 特に、$X^n$が独立同分布($\\mathrm{i.i.d}$)であるとき、その確率関数を$g(x)$とすると、$(8)$式は $$\rF_n = -\\log \\int \\prod_{i=1}^{n}g(x_i | \\theta)\\varphi(\\theta)d\\theta \\tag{9}\r$$\r となります。 これまで見てきた内容を踏まえると、ベイズ自由エネルギーは、確率変数の実現値（複数）がどれくらい驚きが大きい値かを示す指標であることから、その値が小さいほど、想定したモデルがデータをうまく説明できることを意味していると理解できます。 周辺尤度 実は、$(9)$式は、ベイズに触れたことのある人ならばまず一回は触れたことのある関数とも関連しています。その関数とは、ベイズの定理における正規化定数、すなわち周辺尤度です。 ◆事後分布と周辺尤度\r標本空間$A ∈ \\mathbb{R}$で定義される確率変数$X^n$に関する確率モデル$p(x^n|\\theta)$と、$S ∈ \\mathbb{R}$で定義されるパラメータ$\\theta$の事前分布$\\varphi(\\theta)$を考えたとき、パラメータの事後分布$p(\\theta|x^n)$は下記で定義される。 $$ p(\\theta|x^n) = \\cfrac{p(x^n|\\theta)\\varphi(\\theta)}{Z_n} \\tag{10} $$ $Z_n$は正規化（$\\int_S p(\\theta|x^n)d\\theta = 1$を確約すること）の為の定数であり、周辺尤度という。 $$ Z_n = \\int_{S} p(x^n|\\theta)\\varphi(\\theta) d\\theta \\tag{11} $$\r 特に、$x^n = (x_1,\\ldots,x_n)$が独立同分布（$\\mathrm{i.i.d}$）の確率変数からの実現値であるとき、その確率関数を$f(x)$とすると、 $$\rp(\\theta|x^n) =　\\cfrac{\\prod_{i=1}^{n} f(x_i|\\theta)\\varphi(\\theta)}{Z_n} \\tag{12}\r$$\r $(12)$式が成り立つとき、 $$\rZ_n = \\int_{S} \\prod_{i=1}^{n} f(x_i|\\theta)\\varphi(\\theta) d\\theta \\tag{13}\r$$\r $Z_n$はパラメータの事後分布の正規化定数であると同時に、確率変数$X^n$の同時確率密度になっています。 $$\r\\begin{split}\r\\int_A \\ldots \\int_A Z_n dx_1\\ldots dx_n \u0026=\r\\int_A \\ldots \\int_A \\int_S \\prod_{i=1}^{n}f(x_i|\\theta)\\varphi(\\theta)d\\theta dx_1\\ldots dx_n\\\\\\\\\r\u0026= \\int_S \\varphi(\\theta)d\\theta \\prod_{i=1}^{n}\\int_A f(x_i|\\theta)dx_i \\\\\\\\\r\u0026= 1\r\\end{split} \\tag{13}\r$$\r よって、$Z_n$は実現値$x^n$が得られる同時確率の$\\theta$に関する周辺分布($\\theta$について周辺化した後の分布)であり、0から1の値をとります。つまり$Z_n$は確率モデル$p(x^n|\\theta)$と事前分布$\\varphi(\\theta)$でデータをうまく説明できているかの指標になります。 $(9)$式と$(12)$式を比較すると、自由エネルギーと周辺尤度の関係が見えてきます。 ◆自由エネルギーと周辺尤度の関係\r自由エネルギー$F_n$と周辺尤度$Z_n$は以下の関係にある。 $$ F_n = - \\log{Z_n} \\tag{13} $$\r 情報量から導かれた自由エネルギー$F_n$は結局のところ$X^n$の同時確率の対数符号反転になることが分かります。 ベイズファクター ベイズファクターは、2つのモデルを考えたとき、どちらの方が優勢かをはかる指標となります。 ◆ベイズファクター\r2つの異なるモデル$M_0$、$M_1$を考えたとき、ベイズファクター$BF_{10}$は2つの異なるモデルの周辺尤度の比として定義される。 $$ BF_{10} = \\cfrac{p(x^n | M_1)}{p(x^n |M_0)} \\tag{14} $$ ここで、$p(x^n | M)$はモデル$M$における周辺尤度である。また$(14)$式を変形することで、自由エネルギーを用いても定義される。 $$ BF_{10} = \\exp{(F_{M_0} - F_{M_1})} \\tag{15} $$ ここで、$F_M$はモデル$M$における自由エネルギーである。\r 定義より、$BF_{10}$はモデル$M_0$に比べてモデル$M_1$がどの程度うまくデータを説明できているかを表しており、1より大きい値をとるにつれて$M_1$の方が優勢になっていくことが分かります。 ベイズファクターの評価基準には以下のよく知られたものがあります。 Jeffreys(1961) $BF_{ij}$ $M_j$に反する証拠の強さ $1\\sim 3.2$ あまりあるとは言えない(Not worth than a bare mention) $3.2\\sim 10$ 十分ある(Substantial) $10 \\sim 100$ 強くある(Strong) $\u0026gt;100$ 決定的にある(Decisive) Kass and Raftery(1995) $BF_{ij}$ $M_j$に反する証拠の強さ $1\\sim 3$ あまりあるとは言えない(Not worth than a bare mention) $3\\sim 20$ 肯定的である(Positive) $20 \\sim 150$ 強くある(Strong) $\u0026gt;150$ 決定的にある(Very strong) ベイズファクターを計算する ベイズファクターの計算は解析的には困難な場合が多いですが、共役事前分布を用いて解析的に計算できる場合もあります。 memo\r\r共役事前分布とは、事前分布と尤度関数を設定したとき、尤度関数のパラメーターの事後分布が事前分布と同じ関数系になるような事前分布のことである。\r 以下では、$A ∈ \\mathbb{R}^+$で定義される独立同分布の$n$個の連続型確率変数$X^n=(X_1,\\ldots,X_n)$からの実現値$x^n=(x_1,\\ldots,x_n)$をもとに、確率変数$X^n$の分布を推定することを考えます。候補モデルには事後分布を解析的に計算可能なモデルを2つ用意し、どちらのモデルが優勢かをベイズファクターによって判断することを考えます。 モデル1は上述の共役事前分布による事後分布の解析的計算が可能なモデルです。尤度関数には指数分布を設定し、事前分布にはガンマ分布を用いました。 ◆モデル１\r$$\rx_i \\sim \\mathrm{Exponential}(\\gamma) ~~~~ i=1,\\ldots,n \\tag{16}\r$$\r$$\r\\gamma \\sim \\mathrm{Gamma}(\\alpha, \\beta) \\tag{17}\r$$\r\r ◆指数分布の共役事前分布がガンマ分布であることの証明\r尤度関数をパラメータ$\\gamma$の指数分布\r$$\rp(x^n | \\gamma) = \\prod_{i=i}^{n}\\left(\\gamma\\exp(-\\gamma x_i)\\right)\r$$\rパラメータ$\\gamma$の事前分布をshapeパラメータ$\\alpha$、rateパラメータ$\\beta$のガンマ分布\r$$\rp(\\gamma) = \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\gamma^{\\alpha -1} e^{-\\beta \\gamma}\r$$\rとするとき、パラメータ$\\gamma$の事後分布は、以下の通りガンマ分布である。\r$$\r\\begin{split}\rp(\\gamma | x^n) \u0026\\varpropto p(x^n | \\gamma)p(\\gamma) \\\\\\\\\r\u0026= \\prod_{i=i}^{n}\\left(\\gamma\\exp(-\\gamma x_i)\\right) \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\gamma^{\\alpha -1} e^{-\\beta \\gamma} \\\\\\\\\r\u0026= \\gamma ^n \\exp(-\\gamma \\sum_{i=1}^{n}x_i)\\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\gamma^{\\alpha -1} e^{-\\beta \\gamma} \\\\\\\\\r\u0026= \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\gamma^{n+\\alpha-1}\\exp(-(\\beta + \\sum_{i=1}^{n}x_i)\\gamma)\\\\\\\\\r\u0026\\propto \\cfrac{\\beta^{n + \\alpha}}{\\Gamma(n + \\alpha)} \\gamma^{n+\\alpha-1}\\exp(-(\\beta + \\sum_{i=1}^{n}x_i)\\gamma) \\\\\\\\\r\u0026= \\mathrm{Gamma}(n+\\alpha, \\beta + \\sum_{i=1}^{n}x_i )\r\\end{split}\r$$\r\r モデル2は、モデル1と同様、尤度関数に指数分布を設定します。一方、事前分布については設定しないこととします。 ◆モデル２\r$$\rx_i \\sim \\mathrm{Exponemtial}(\\gamma) ~~~~ i=1,\\ldots,n \\tag{18}\r$$\r\r ベイズファクターは周辺尤度または自由エネルギーのモデル間比較を行うので、次に上記２モデルの周辺尤度・自由エネルギーを計算します。 モデル1の周辺尤度$p(x^n|M_1)$は、 $$\r\\begin{split}\rp(x^n|M_1) \u0026= \\int_{0}^{∞}p(x^n | \\gamma) \\varphi(\\gamma) d\\gamma \\\\\\\\\r\u0026= \\int_{0}^{∞} \\mathrm{Exponential}(x^n | \\gamma)\\mathrm{Gamma}(\\gamma | \\alpha, \\beta) d\\gamma \\\\\\\\\r\u0026= \\int_{0}^{∞} \\prod_{i=i}^{n}\\left(\\gamma\\exp(-\\gamma x_i)\\right) \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}\\gamma^{\\alpha -1} e^{-\\beta \\gamma} d\\gamma \\\\\\\\\r\u0026= \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\int_{0}^{∞} \\gamma^{n + \\alpha - 1}\\exp(-\\gamma(\\beta +\\sum_{i=1}^{n}x_i)) d\\gamma \\\\\\\\\r\u0026= \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\int_{0}^{∞} \\left(\\cfrac{\\gamma^{'}}{\\beta + \\sum_{i=1}^{n}x_i }\\right)^{(n+\\alpha-1)} e^{-\\gamma^{'}}\\cfrac{1}{\\beta + \\sum_{i=1}^{n}x_i}d\\gamma^{'} ~~~~~\\left( (\\beta + \\sum_{i=1}^{n}x_i)\\gamma = \\gamma^{'} とした置換積分 \\right) \\\\\\\\\r\u0026= \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)(\\beta + \\sum_{i=1}^{n}x_i)^{n+\\alpha}} \\int_0^{∞} \\gamma^{'(n+\\alpha -1)} e^{-\\gamma^{'}} d\\gamma^{'} \\\\\\\\\r\u0026= \\cfrac{\\beta^{\\alpha}\\Gamma(n+\\alpha)}{\\Gamma(\\alpha)(\\beta + \\sum_{i=1}^{n}x_i)^{n+\\alpha}} ~~~~~(ガンマ関数の定義より) \\\\\\\\\r\u0026= \\cfrac{\\beta^{\\alpha} n!}{(\\beta + \\sum_{i=1}^{n}x_i)^{n+\\alpha}} ~~~~~(\\Gamma(s+1) = s\\Gamma(s)より)\r\\end{split}\r$$\r 自由エネルギー$F_{M_{1}}$は、 $$\rF_{M_{1}} = -log(p(x^n|M_1)) = -\\alpha\\log\\beta - \\sum_{i=1}^{n}i + (n + \\alpha)\\log(\\beta + \\sum_{i=1}^{n}x_i) \\tag{19}\r$$\r 同様に、モデル2の周辺尤度$p(x^n|M_2)$と自由エネルギー$F_{M_{2}}$を求めます。 ここで、モデル2についてはパラメーターに事前分布を設定していないので、周辺尤度の計算の際にパラメータで周辺化する必要がありません。よって、 $$\rp(x^n|M_2) = \\mathrm{Exponential}(x^n | \\gamma) = \\prod_{i=1}^{n} \\gamma \\exp(-x_i\\gamma) = \\gamma^n \\exp(-\\sum_{i=1}^{n}x_i \\gamma)\r$$\r$$\rF_{M_2} = -\\log(p(x^n | M_2)) = -n\\log\\gamma + \\sum_{i=1}^{n}x_i\\gamma \\tag{20}\r$$\r では、上記$(19)$、$(20)$式を用いて一つの観測値を例にベイズファクターを計算しましょう。 いま、独立同分布の確率変数の組$X^5$から実現地$x^n = (0.198,0.561,0.572,0.094,0.213)$が得られたとします。このとき、$\\alpha=3$、$\\beta=1$としたときのモデル1と、$\\gamma=3$としたときのモデル2のどちらがよいモデルであるのかを自由エネルギーを用いて比較します。 このときのモデル1の自由エネルギーは、 $$\rF_{M_{1}} = -3\\log1 - \\sum_{i=1}^{5}i + (5 + 3)\\log(1 + \\sum_{i=1}^{5}x_i) = 2.972677\r$$\r モデル2の自由エネルギーは、 $$\rF_{M_2} = -n\\log\\gamma + \\sum_{i=1}^{n}x_i\\gamma = -5\\log3 + 3\\sum_{i=1}^{5}x_i = 4.914\r$$\r よって、パラメータに事前分布を設定したモデル1の方がデータをよく説明出来ていることが分かります。また、ベイズファクターを求めると $$\rexp(F_{M_2} - F_{M_1}) = 6.967966\r$$\r となることから、モデル1の方がやや優勢であると判断することができます。 ベイズファクターの性質を確認する もうすこし掘り下げて、参考文献を参考に、設定したモデルに対しどのようなデータが得られた時に自由エネルギーの値が大きく（小さく）なるのか見ていきます。ここでは、前節と同じ例を用いて、$X^n$に真の分布を設定し、モデル1($\\alpha=3,\\beta=1$)、モデル2($\\gamma=3$)の比較を行います。 まず、実現値の数を$n=30$とし、真の分布を $$\rX^{30} \\sim \\mathrm{Exponential}(8)\r$$\r としたとき。実現値の組を1000回発生させ、$F_{M_1}$、$F_{M_2}$をそれぞれ1000回計算し、結果を要約したものが以下になります。 モデル1の方が自由エネルギーがが小さい傾向にあります。 解釈としては、事前分布を設定しない単純なモデルであるモデル2は、$\\gamma=3$と真のモデルとパラメータがやや異なっているので、当てはまりが比較的悪いのに対し、事前分布を設定したより複雑なモデルであるモデル1は、モデル2に比較しより広い範囲の実現値をカバーできるため、ということになります。 一方、実現値をモデル2のパラメータ3に合わせた場合、結果は以下のように変わってきます。 $$\rX^{30} \\sim \\mathrm{Exponential}(3)\r$$\r 今度はモデル2方が自由エネルギーが小さくなりました。このことから、自由エネルギーは、モデルを複雑にすれば小さくなりやすいというわけではなく、データの当てはまりが良い場合については、より単純なモデルほど小さくなる傾向にあることがわかります。 この傾向を再確認するため、実現値の数を$n=1$とし、実現値を0.1から3まで与えたときの2つのモデルの自由エネルギーを確認したところ、以下のような結果になりました。 単純なモデルであるモデル2が想定している値である0.1から0.8あたりまでが得られた場合、モデル2の自由エネルギーの方が小さくなり、それ以外の範囲では複雑なモデルであるモデル1の方が自由エネルギーが小さくなることが分かります。このことから、自由エネルギー（ベイズファクター）を用いたモデル評価では過学習（データにフィットするようむやみにモデルを複雑にし過ぎること）を抑えることができると言えます。またこの例からも分かるように、自由エネルギーがパラメーターに対し周辺化した値であることから、自由エネルギー（ベイズファクター）を用いたモデル評価では事前分布が大きく影響する、ということが分かります。 おわりに 以上、ベイズファクターについてみていきました。 ベイズファクターはパラメータに対し周辺化した尤度である周辺尤度に基づいて計算されますが、モデルの設定によってはこの計算が解析的に行えない場合があります。この場合、MCMCの結果からWBICを計算したり、ブリッジ・サンプリングを行うことで近似的に周辺尤度を計算する方法が提案されているようです。今後勉強し、まとめていこうと思っています。 また別の始点（汎化誤差）に着目したモデル評価の指標であるWAIC等についても、もう一度整理し投稿したいと思っています。 最後に、関数形の確認やシミュレーションの為に用いたRコードを載せておきます。 library(tidyverse) library(ggplot2) # ガンマ分布の形状を確認 ------------------------------------------------------------- #形状パラメータaを動かしたときのガンマ分布の確率密度 alpha \u0026lt;- seq(.5, 100, by=5) p \u0026lt;- ggplot(data.frame(X=c(0, 40)), aes(x=X)) + theme_bw(base_size=11)+ mapply( function(alpha,beta,co) geom_line(data=data.frame(X=x \u0026lt;- seq(0.1,40,0.05), Y=dgamma(x,shape=alpha,rate=beta)), aes(x=X,y=Y, color=co)), alpha,4,alpha) + coord_cartesian(ylim=c(0,0.75)) + labs(color=\u0026#34;α\u0026#34;, x=\u0026#34;λ\u0026#34;,y=\u0026#34;Gamma(λ | α,β=4)\u0026#34;) p #rateパラメータbを動かしたときのガンマ分布の確率密度 beta \u0026lt;- seq(.5, 10, by=.5) p \u0026lt;- ggplot(data.frame(X=c(0, 40)), aes(x=X)) + theme_bw(base_size=11)+ mapply( function(alpha,beta,co) geom_line(data=data.frame(X=x \u0026lt;- seq(0.1,6,0.01), Y=dgamma(x,shape=alpha,rate=beta)), aes(x=X,y=Y, color=co)), 4,beta,beta) + labs(color=\u0026#34;β\u0026#34;, x=\u0026#34;λ\u0026#34;,y=\u0026#34;Gamma(λ | α=4,β)\u0026#34;) p # ガンマ分布のエントロピーを確認 ------------------------------------------------------------- H_gamma \u0026lt;- function(a, b){ return(lgamma(a) + (1-a) * digamma(a) - log(b) + a) } # 形状パラメータaを動かしたとき p \u0026lt;- ggplot() + geom_path(data=data.frame(X=x \u0026lt;- seq(0.1,100,0.1), Y=H_gamma(x,1)), aes(x=X,y=Y)) p \u0026lt;- ggplot() + theme_light(base_size=11) + mapply( function(beta,co) geom_path(data=data.frame(X=x \u0026lt;- seq(0.1,50,0.1), Y=H_gamma(x,beta)), aes(x=X,y=Y, color=co)), seq(0.01,10,len=20), seq(0.01,10,len=20) ) + labs(color=\u0026#34;β\u0026#34;, x=\u0026#34;α\u0026#34;,y=\u0026#34;H(Gamma(α,β))\u0026#34;) p #rateパラメータbを動かしたときのガンマ分布のエントロピー p \u0026lt;- ggplot() + theme_light(base_size=11) + mapply( function(alpha,co) geom_path(data=data.frame(X=x \u0026lt;- seq(0.1,50,0.1), Y=H_gamma(alpha,x)), aes(x=X,y=Y, color=co)), seq(0.1,10,len=20), seq(0.1,10,len=20) ) + labs(color=\u0026#34;α\u0026#34;, x=\u0026#34;β\u0026#34;,y=\u0026#34;H(Gamma(α,β))\u0026#34;) p # ベイズファクターの計算 ------------------------------------------------------------- x \u0026lt;- round(rexp(5, 3),3) x \u0026lt;- 0.01 F_model1 \u0026lt;- function(X,alpha,beta){ return(-alpha*log(beta) -sum(log(seq(1, length(X)))) + (length(X) + alpha) * log(beta + sum(X)) ) } F_model2 \u0026lt;- function(X, gamma){ return( -length(X) * log(beta) + sum(X) * gamma ) } gamma \u0026lt;- 3 alpha \u0026lt;- 3 beta \u0026lt;- 1 #計算結果 exp(-F_model1(X=x, alpha=alpha, beta=beta) + F_model2(X=x, gamma=gamma)) # lineplot --------------------------------------------------------------- F_model1_p \u0026lt;- function(X,alpha,beta){ return(-alpha*log(beta) + (1 + alpha) * log(beta + X) ) } F_model2_p \u0026lt;- function(X, gamma){ return( -1 * log(beta) + X * gamma ) } p \u0026lt;- ggplot() + theme_light(base_size=11) + mapply( function(gamma) geom_line(data=data.frame(X=x2 \u0026lt;- seq(0.1,3,0.01), Y=F_model2_p(x2,gamma)), aes(x=X,y=Y,lty=\u0026#34;model2\u0026#34;)), gamma ) + mapply( function(alpha,beta) geom_line(data=data.frame(X=x2 \u0026lt;- seq(0.1,3,0.01), Y=F_model1_p(x2,alpha,beta)), aes(x=X,y=Y,lty=\u0026#34;model1\u0026#34;)), alpha,beta ) + labs(x=\u0026#34;x\u0026#34;,y=\u0026#34;Free Energy\u0026#34;) p # boxplot ----------------------------------------------------------------- n \u0026lt;- 30 #sample size gamma_prime \u0026lt;- 1 set.seed(123) m1 \u0026lt;- c() m2 \u0026lt;- c() for(i in 1:1000){ x \u0026lt;- rexp(n,gamma_prime) m2[i] \u0026lt;- sum(-dexp(x,3,log=T)) m1[i] \u0026lt;- F_model1(x,alpha=alpha,beta=beta) } mean(m1) mean(m2) plot_title \u0026lt;- ggtitle(\u0026#34;Comparison of free energy\u0026#34;, sprintf(\u0026#34;Real param = %.0f\u0026#34;,gamma_prime)) p \u0026lt;- data_frame(M1=m1,M2=m2) %\u0026gt;% gather(key = \u0026#34;x\u0026#34;,value = \u0026#34;y\u0026#34;) %\u0026gt;% ggplot() + geom_boxplot(aes(x,y),lwd=0.5,outlier.shape = 21, outlier.size = 0.5) + theme_light() + xlab(\u0026#34;\u0026#34;) + ylab(\u0026#34;\u0026#34;) + theme(legend.text=element_text(size=4), legend.title=element_text(size=8,face=\u0026#34;bold\u0026#34;), axis.text=element_text(size=6), axis.title=element_text(size=8,face=\u0026#34;bold\u0026#34;), strip.text.x = element_text(size=6,face=\u0026#34;bold\u0026#34;), legend.position = \u0026#34;right\u0026#34;) + plot_title p"
  },
  {
    url: "https://sucre-stat.com/tags/%E7%A2%BA%E7%8E%87%E8%AB%96/",
    title: "確率論",
    date: "2021-02-14T00:00:00Z",
    body: "確率論"
  },
  {
    url: "https://sucre-stat.com/2021/01/moment/",
    title: "積率と母関数",
    date: "2021-01-31T00:00:00Z",
    body: "積率と母関数 本記事では確率論の勉強ということで、期待値など確率変数の特徴を表す量について定義し、それらにまつわる便利なアイテム（関数）群を整理しようと思います。 本記事の内容をマスターすれば、確率分布の各特徴を表す量について明るくなったり、確率分布が関係する計算に少し強くなったりできます。 本記事の構成は以下の通りです。 期待値と積率 期待値 積率 分散と中心積率 分散 中心積率 標準化積率と歪度・尖度 標準化積率 歪度と尖度 積率母関数 キュミュラント母関数 期待値と積率 期待値 まず、確率変数$X$の期待値について定義します。 以下、慣例に従い確率変数は大文字（例：$X$）、確率変数からの実現値は同じアルファベットの小文字（例：$x$）で、$A$という事象が起こる確率を$P(A)$で表します。 ◆確率変数の期待値\r離散型の確率変数$X$が確率質量関数$p_{X}(x_k)$$(k = 1,2,\\ldots)$をもつとき、$X$の期待値は下記で定義される。 $$ \\mathbb{E}[X] = \\sum_{k=1}^{∞}x_kP(X = x_k) = \\sum_{k=1}^{∞}x_k p_{X}(x_k) \\tag{1} $$ 連続型の確率変数$X$が確率密度関数$f_{X}(x)$をもつとき、$X$の期待値は下記で定義される。 $$ \\mathbb{E}[X] = \\int_{-∞}^{∞} xf_{X}(x)dx \\tag{2} $$ 感覚的には$(1)$式$(2)$式ともに$X$がとりうる値についてその値をとる確率で重みづけしたものが期待値になります。通常の平均と同じ考えかたですね。 積率 積率（moment）は、期待値にまつわる重要な概念です。 ◆積率\r確率変数$X$及び自然数$k$について、 $X^k$の期待値 $$ \\mu^{'}_{X,k} = \\mathbb{E}[X^k] \\tag{3} $$ を確率変数$X$の$k$次の積率（moment）という。 特に$X$の1次の積率は平均($\\mathbb{E}[X]$)である。\r 上の定義だけでは積率をわざわざ定義する意味が分からないと思いますが、のちのち紹介するように分散や歪度、尖度の計算に2次、3次、4次の積率が利用されます。 試しにガンマ分布の積率を導出し、ガンマ分布に従う確率変数の期待値を求めてみましょう。 memo\r\rガンマ分布の確率密度は下記式で与えられる。ここで、$x ∈ \\mathbb{R}^+, \\alpha∈ \\mathbb{R}^+, \\beta ∈ \\mathbb{R}^+$である。\r$$\r\\mathrm{Gamma}(x | \\alpha, \\beta) = \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha -1} e^{-\\beta x}\r$$\r$\\Gamma(z)$はガンマ関数といい、下記で定義される。\r$$\r\\Gamma (z)= \\int_0^{\\infty}t^{z-1}e^{-t}dt ~~~ (z 0)\r$$\r\r ◆ガンマ分布の積率・期待値\rガンマ分布を確率密度にもつ確率変数$X$について、\r$$\r\\begin{split}\r\\mu^{'}_{X,k} \u0026= \\mathbb{E}[X^k] \\\\\\\\\r\u0026= \\int _{0}^{∞}\\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\beta x} x^k dx \\\\\\\\\r\u0026= \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\int _{0}^{∞}x^{\\alpha+k-1}e^{-\\beta x} dx \\\\\\\\\r\u0026= \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\int _{0}^{∞}\\left(\\cfrac{y}{\\beta}\\right)^{k + \\alpha-1}e^{-y}\\cfrac{1}{\\beta} dy ~~~(y = \\beta x とおいた置換積分) \\\\\\\\\r\u0026= \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\cfrac{1}{\\beta^{k + \\alpha}} \\int_{0}^{∞} y^{k + \\alpha - 1}e^{-y}dy \\\\\\\\\r\u0026= \\cfrac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} \\cfrac{\\Gamma(k + \\alpha)}{\\beta^{k + \\alpha}} \\\\\\\\\r\u0026= \\beta^{-k} \\prod_{i=1}^{k-1}(\\alpha + i - 1) ~~~ (\\Gamma(s + 1) = s\\Gamma(s)を利用)\r\\end{split}\r$$\rよって、\r$$\r\\mu^{'}_{X,1} = \\mathbb{E}(X) = \\cfrac{\\alpha}{\\beta}\r$$\r\r 分散と中心積率 分散 次に確率変数の分散について定義します。 ◆分散\r確率変数$X$の分散は下記で定義される。ここで$X$の平均を$\\mu_X$とする。 $$ \\mathbb{V}[X] = \\mathbb{E}[(X - \\mu_X)^2] \\tag{4} $$\r 確率変数の平均も分散も、通常のデータに対する平均と分散と同じ考え方で定義されています。 中心積率 積率に関連した概念として、中心積率について定義します。 ◆中心積率\r確率変数$X$とその平均$\\mu_X$及び自然数$k$について、$(X-\\mu_X)^k$の期待値を確率変数$X$の$k$次の中心積率（central moment）といい、$\\mu_{X,k}$であらわす。特に2次の中心積率は分散である。 $$ \\mu_{X,k} = \\mathbb{E}[(X-\\mu_X)^k] \\tag{5} $$ $$ \\mu_{X,2} = \\mathbb{E}[(X-\\mu_X)^2] = \\mathbb{V}[X] \\tag{6} $$\r このように、確率変数の分散は中心積率を用いて計算することができます。 試しに、ガンマ分布の分散を求めてみましょう。 ◆ガンマ分布の分散\r$(5)$式を変形して、\r$$\r\\begin{split}\r\\mathbb{V}[X] \u0026= \\mathbb{E}[(X-\\mu_X)^2]\\\\\\\\\r\u0026= \\mathbb{E}[X^2] -2\\mathbb{E}[X]\\mu_X +\\mu_X^2\\\\\\\\\r\u0026= \\mu^{'} _{X,2} - \\mu^{'2} _{X,1}\r\\end{split}\r$$\rよって、ガンマ分布を確率密度に持つ確率変数$X$の分散は、\r$$\r\\begin{split}\r\\mathbb{V}[X] \u0026= \\mu^{'} _{X,2} - \\mu^{'2} _{X,1}\\\\\\\\\r\u0026= \\beta^{-2}\\alpha(\\alpha+1) - (\\beta^{-1}\\alpha)^2\\\\\\\\\r\u0026= \\cfrac{\\alpha}{\\beta^2}\r\\end{split}\r$$\r\r さらに、分散の非負平方根は標準偏差と呼びます。 ◆標準偏差\r標準偏差$\\sigma_X$は下記式で定義される。 $$ \\sigma_X = \\sqrt{\\mu_{X,2}} \\tag{7} $$\r 標準化積率と歪度・尖度 標準化積率 平均$\\mu_X$、標準偏差$\\sigma_X$である確率変数$X$に対する標準化は $$ Z = \\cfrac{X - \\mu_X}{\\sigma_X} \\tag{8} $$ となりますが、これに関連して標準化積率が定義されます。 ◆標準化積率\r平均$\\mu_X$、標準偏差$\\sigma_X$である確率変数$X$および自然数$k$に対して、$\\left(\\cfrac{X - \\mu_X}{\\sigma_X}\\right)^k$の期待値を標準化積率と呼び、$\\alpha_{X,k}$であらわす。 $$ \\alpha_{X,k} = \\mathbb{E} \\left[ \\left(\\cfrac{X - \\mu_X}{\\sigma_X}\\right)^k \\right] \\tag{9} $$ 歪度と尖度 確率分布の形状を把握するための量に歪度と尖度があり、これらは上記の標準化積率を用いて定義されます。 ◆歪度と尖度\r3次の標準化積率を歪度とよび確率変数$X$の歪度を$\\gamma_{X,1}$とあらわす。 $$ \\gamma_{X,1} = \\alpha_{X,3} = \\mathbb{E} \\left[ \\left(\\cfrac{X - \\mu_X}{\\sigma_X}\\right)^3 \\right] \\tag{10} $$ 4次の標準化積率を歪度とよび確率変数$X$の尖度を$\\gamma_{X,2}$とあらわす。 $$ \\gamma_{X,2} = \\alpha_{X,4} = \\mathbb{E} \\left[ \\left(\\cfrac{X - \\mu_X}{\\sigma_X}\\right)^4 \\right] \\tag{11} $$\r 歪度は確率分布の対称性・非対称性の指標となります。 歪度が$\\gamma_{X,1} = 0$となるとき、その確率変数の確率分布は左右対称であるといえます。 一方、歪度$\\gamma_{X,1}\u0026gt; 0$となるとき、$X$は平均以上の値をとることが多いことから、分布の形状は平均より正の方向に長い右歪分布となります。 逆に歪度$\\gamma_{X,1}\u0026lt; 0$のとき、分布の形状は平均より負の方向に長い左歪分布となります。 尖度は確率分布の密集度を示します。尖度が大きいと、$\\sigma_X$が小さくなるため、分布は中心付近に密集するとともに、$X - \\mu_X$が大きくなるため、分布の裾が重い分布となります。 例として、ガンマ分布の歪度と尖度を求めてみましょう。 ◆ガンマ分布の歪度・尖度\rガンマ分布を確率密度にもつ確率変数$X$について、\r$$\r\\begin{split}\r\\gamma_{X,1} \u0026= \\alpha_{X,4} = \\mathbb{E} \\left[ \\left(\\cfrac{X - \\mu_X}{\\sigma_X}\\right)^4 \\right]\\\\\\\\\r\u0026= \\cfrac{\\mu^{'}_{X,3} - 3\\mu^{'}_{X,2}\\mu^{'}_{X,1} + 2\\mu^{'3}_{X,1}}{\\sigma_X^3}\\\\\\\\\r\u0026= \\left( \\cfrac{\\alpha(\\alpha+1)(\\alpha+2)}{\\beta^3} -3\\cfrac{\\alpha(\\alpha+1)}{\\beta^2}\\cfrac{\\alpha}{\\beta} +2\\cfrac{\\alpha^3}{\\beta^3} \\right)\\cfrac{\\beta^3}{\\alpha\\sqrt{\\alpha}}\\\\\\\\\r\u0026= \\cfrac{2}{\\sqrt{\\alpha}}\r\\end{split}\r$$\r$$\r\\begin{split}\r\\gamma_{X,2} \u0026= \\alpha_{X,4} = \\mathbb{E} \\left[ \\left(\\cfrac{X - \\mu_X}{\\sigma_X}\\right)^4\\right] \\\\\\\\\r\u0026= \\cfrac{\\mu^{'}_{X,4} - 4\\mu^{'}_{X,3}\\mu^{'}_{X,1} + 6\\mu^{'}_{X,2}\\mu^{'2}_{X,1} - 3\\mu^{'4}_{X,1}}{\\sigma_X^4} \\\\\\\\\r\u0026= \\cfrac{3(\\alpha + 2)}{\\alpha}\r\\end{split}\r$$\r\r 積率母関数 次に積率母関数を定義します。積率母関数は、積率を生成する関数であることからこのような名前がついています。 ◆積率母関数\r確率変数$X$及び実数$t$に対して、$e^{tX}$の期待値を積率母関数といい、$\\mathrm{M}_{X}(t)$であらわす。 $$ \\mathrm{M}_{X}(t) = \\mathbb{E}\\left[e^{tX}\\right] \\tag{12} $$ 積率と積率母関数には以下の関係がある。 $$ \\mu^{'}_ {X,k} = \\mathrm{M}_{X}^{(k)}(0) = \\left.\\cfrac{d^k}{dt^k}\\mathrm{M}_X(t)\\right|_{t=0} \\tag{13} $$ ◆証明～積率と積率母関数の関係～\r確率変数$X$についての積率母関数$\\mathrm{M}_{X}(t)$をマクローリン展開すると、\r$$\r\\begin{split}\r\\mathrm{M}_{X}(t) \u0026= \\mathbb{E}\\left[1 + tX + \\cfrac{t^2X^2}{2!} + \\cdots + \\cfrac{t^nX^n}{n!}\\right]\\\\\\\\\r\u0026= 1 + t\\mathbb{E}[X] + \\cfrac{t^2}{2!}\\mathbb{E}[X] + \\cdots + \\cfrac{t^n}{n!}\\mathbb{E}[X^n]\r\\end{split}\r$$\r上記結果から、$\\mathrm{M}_{X}(t)$を$t$で微分し$t=0$とすると、\r$$\r\\mathrm{M}^{'}_{X}(0) = \\mathbb{E}[X] = \\mu^{'}_{X,1}\r$$\r$$\r\\mathrm{M}^{''}_{X}(0) = \\mathbb{E}[X^2] = \\mu^{'}_{X,2}\r$$\r$$\r\\vdots\r$$\r$$\r\\mathrm{M}^{(k)}_{X}(0) = \\mathbb{E}[X^k] = \\mu^{'}_{X,k}\r$$\rよって、$(12)$式が成り立つ。\r\r 例として、積率母関数を使ってガンマ分布の平均と分散を求めてみましょう。 ◆ガンマ分布の積率母関数と平均・分散\rガンマ分布を確率密度にもつ確率変数$X$に対して、積率母関数は、\r$$\r\\begin{split}\r\\mathrm{M}_{X}(t) \u0026= \\mathbb{E}[e^{tX}]\\\\\\\\\r\u0026= \\int_{0}^{∞} e^{tx}\\cfrac{\\beta^{\\alpha}x^{\\alpha -1} e^{-\\beta x}}{\\Gamma(\\alpha)} dx\\\\\\\\\r\u0026= \\beta^{\\alpha}(\\beta - t)^{-\\alpha}\\int_{0}^{∞}\\cfrac{(\\beta - t)^{\\alpha}x^{\\alpha -1} e^{-(\\beta-t) x}}{\\Gamma(\\alpha)} dx\\\\\\\\\r\u0026= \\beta^{\\alpha}(\\beta - t)^{-\\alpha}\\int_{0}^{∞} f_{\\Gamma(\\alpha, \\beta-t)}(x)dx~~(t 積率が簡単に求められない場合でも、積率母関数を使えば比較的簡単に積率を求められることがあります。 キュミュラント母関数 キュミュラント母関数も、積率や平均・分散・歪度・尖度の計算に使える便利な関数なのですが、核となる部分の証明に手も足も出なかったので、ちゃんと理解出来たらupしたいと思います。"
  },
  {
    url: "https://sucre-stat.com/2021/01/regularization2/",
    title: "Bayesian RidgeとBayesian Lasso 通常の正則化回帰との比較",
    date: "2021-01-05T00:00:00Z",
    body: "Bayesian RidgeとBayesian Lasso 通常の正則化回帰との比較 はじめに 今回は、以前の記事で紹介したRidge回帰とLasso回帰をRのパッケージglmnetで試してみます。さらにRstanを用いてBayesian RigdeとBayesian Lasso を実装して、glmnetの結果との比較をしてみたいと思います。 目次は以下のとおりです。 はじめに glmnetを用いた正則化回帰 下準備 Lasso回帰 Ridge回帰 rstanを用いた正則化回帰 Lasso回帰 実装 結果 Ridge回帰 実装 結果 まとめ glmnetを用いた正則化回帰 こちらのサイトを参考にglmnetを用いて正則化回帰をします。 下準備 まずはデータの準備を。BostonHousingにはボストンの住宅506件について、住宅の価格medvおよび13の変数が格納されています。ここでは、medvを13の変数で説明する回帰を考えます。 library(mlbench) library(tidyverse) data(\u0026#34;BostonHousing\u0026#34;) head(BostonHousing) ## crim zn indus chas nox rm age dis rad tax ptratio b lstat medv ## 1 0.00632 18 2.31 0 0.538 6.575 65.2 4.0900 1 296 15.3 396.90 4.98 24.0 ## 2 0.02731 0 7.07 0 0.469 6.421 78.9 4.9671 2 242 17.8 396.90 9.14 21.6 ## 3 0.02729 0 7.07 0 0.469 7.185 61.1 4.9671 2 242 17.8 392.83 4.03 34.7 ## 4 0.03237 0 2.18 0 0.458 6.998 45.8 6.0622 3 222 18.7 394.63 2.94 33.4 ## 5 0.06905 0 2.18 0 0.458 7.147 54.2 6.0622 3 222 18.7 396.90 5.33 36.2 ## 6 0.02985 0 2.18 0 0.458 6.430 58.7 6.0622 3 222 18.7 394.12 5.21 28.7 predictors = BostonHousing %\u0026gt;% select(-medv) %\u0026gt;% data.matrix() predictors_std \u0026lt;- scale(predictors) response_variable \u0026lt;- BostonHousing$medv response_variable_std \u0026lt;- scale(response_variable) Rのパッケージlmを使って通常の線形回帰もしてみます。 res \u0026lt;- lm(response_variable_std ~ predictors_std) summary(res) ## Call: ## lm(formula = response_variable_std ~ predictors_std) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.69559 -0.29680 -0.05633 0.19322 2.84864 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -1.620e-16 2.294e-02 0.000 1.000000 ## predictors_stdcrim -1.010e-01 3.074e-02 -3.287 0.001087 ** ## predictors_stdzn 1.177e-01 3.481e-02 3.382 0.000778 *** ## predictors_stdindus 1.534e-02 4.587e-02 0.334 0.738288 ## predictors_stdchas 7.420e-02 2.379e-02 3.118 0.001925 ** ## predictors_stdnox -2.238e-01 4.813e-02 -4.651 4.25e-06 *** ## predictors_stdrm 2.911e-01 3.193e-02 9.116 \u0026lt; 2e-16 *** ## predictors_stdage 2.119e-03 4.043e-02 0.052 0.958229 ## predictors_stddis -3.378e-01 4.567e-02 -7.398 6.01e-13 *** ## predictors_stdrad 2.897e-01 6.281e-02 4.613 5.07e-06 *** ## predictors_stdtax -2.260e-01 6.891e-02 -3.280 0.001112 ** ## predictors_stdptratio -2.243e-01 3.080e-02 -7.283 1.31e-12 *** ## predictors_stdb 9.243e-02 2.666e-02 3.467 0.000573 *** ## predictors_stdlstat -4.074e-01 3.938e-02 -10.347 \u0026lt; 2e-16 *** ## --- ## Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 ## ## Residual standard error: 0.516 on 492 degrees of freedom ## Multiple R-squared: 0.7406,\tAdjusted R-squared: 0.7338 ## F-statistic: 108.1 on 13 and 492 DF, p-value: \u0026lt; 2.2e-16 Lasso回帰 以前の記事と同様に記号を定義したとき、 glmnet::glmnet(alpha, lambda)は下記式に基づいて係数パラメータ$\\boldsymbol{w}$を最適化するようです1。 ◆glmnetにおけるパラメータの最適化方法\r係数パラメータ$\\boldsymbol{w}$の解は、 $$ \\newcommand{\\argmin}{\\mathop{\\rm arg~min}\\limits} \\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\cfrac{1}{2N} \\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\lambda P_{\\alpha}(\\boldsymbol{w}_{-0})\\right] \\tag{1} $$ ここで、 $$ P_{\\alpha}(\\boldsymbol{w}) = (1-\\alpha)\\cfrac{1}{2}||\\boldsymbol{w}||_2^2 + \\alpha||\\boldsymbol{w}_{-0}||_1^1 \\tag{2} $$ $$ \\boldsymbol{w}_{-0} = (w_1,\\ldots, w_H)^T \\tag{3} $$ である。 glmnet::glmnet(alpha=1)で$(2)$式が$P_{\\alpha}(\\boldsymbol{w}) = ||\\boldsymbol{w}||_1^1$となることにより、Lasso回帰をすることができます。引数のlambdaは$\\boldsymbol{w}$が大きくなることによるペナルティ$P_\\alpha(\\boldsymbol{w})$の重みになり、大きくなるほど係数パラメータは小さくなる傾向にあります。lambdaの値は交差検証法を行うglmet::cv.glmet()でnfolds=nrow(BostonHousing)とすることにより1個抜き交差検証法を行い決定します。 簡単にRスクリプトと結果だけ。 library(glmnet) lambdas \u0026lt;- 10^seq(1, -3, by = -.1) # alpha=1でLasso回帰 fit_std \u0026lt;- glmnet(predictors_std, response_variable_std, alpha = 1, lambda = lambdas) lambda_calc \u0026lt;- cv.glmnet(predictors_std, response_variable_std, alpha = 1, lambda = lambdas, nfolds = nrow(BostonHousing), grouped = FALSE) optlambda \u0026lt;- lambda_calc$lambda.min log(optlambda) ## [1] -6.21698 Lasso回帰の結果 coef(fit_std, s = optlambda) ## Lassoの結果 ## 14 x 1 sparse Matrix of class \u0026#34;dgCMatrix\u0026#34; ## 1 ## (Intercept) -8.076217e-16 ## crim -9.513801e-02 ## zn 1.089273e-01 ## indus . ## chas 7.448868e-02 ## nox -2.100694e-01 ## rm 2.937399e-01 ## age . ## dis -3.272420e-01 ## rad 2.541077e-01 ## tax -1.920829e-01 ## ptratio -2.202126e-01 ## b 9.048729e-02 ## lstat -4.057165e-01 # 結果の描画 ------------------------------------------------------------------- res_lm \u0026lt;- res$coefficients %\u0026gt;% as.data.frame() %\u0026gt;% cbind(variable = rownames(.)) %\u0026gt;% mutate(variable = str_replace(variable, pattern = \u0026#34;predictors_std\u0026#34;, replacement = \u0026#34;\u0026#34;)) %\u0026gt;% rename(\u0026#34;value\u0026#34; = \u0026#34;.\u0026#34;) %\u0026gt;% filter(variable != \u0026#34;(Intercept)\u0026#34;) names(lambdas) \u0026lt;- paste0(\u0026#34;s\u0026#34;,seq(0,40)) res_lasso \u0026lt;- as.matrix(fit_std$beta) %\u0026gt;% as.data.frame()%\u0026gt;% cbind(variable = rownames(.)) %\u0026gt;% pivot_longer(cols=-variable , names_to = \u0026#34;x\u0026#34;, values_to=\u0026#34;value\u0026#34;) %\u0026gt;% mutate(lambda = lambdas[x], x=NULL) p \u0026lt;- ggplot(data = res_lasso, aes(x=log(lambda), y=value, group=variable, color=variable)) + theme_light(base_size=11) + geom_line() + labs(x=\u0026#34;Log Lambda\u0026#34;, y= \u0026#34;Coefficients\u0026#34;, title=\u0026#34;Lasso regression\u0026#34;) + geom_hline(data=res_lm, aes(yintercept=value, col=variable), linetype=\u0026#34;dashed\u0026#34;) + geom_vline(aes(xintercept = log(optlambda)), linetype=\u0026#34;dashed\u0026#34;) + geom_text(aes(x=log(optlambda)+1.2, y=-0.45, label=sprintf(\u0026#34;log(lambda) = %.2f\u0026#34;, log(optlambda))), color=\u0026#34;black\u0026#34;) 結果の図には13の変数に対する標準化偏回帰係数が$(1)$式の$\\lambda$の変化とともにどのような値をとるかを示しています。また点線で通常の回帰分析における標準化偏回帰係数も示しています。 $\\lambda$が大きくなるにつれて各回帰係数の値が小さくなる傾向が分かります。特に変数indusとageの係数パラメータははやいうちから0となっており、変数の選択が行われていることが分かります。 Ridge回帰 Lasso回帰のときとほぼ同様ですが、glmnet::glmnet(alpha=0)で$(2)$式が$P_{\\alpha}(\\boldsymbol{w}) = \\cfrac{1}{2} ||\\boldsymbol{w}||_2^2$となることにより、Ridge回帰をすることができます。 同様にして… # alpha=0でRidge回帰 fit_std \u0026lt;- glmnet(predictors_std, response_variable_std, alpha = 0, lambda = lambdas) # Ridge lambda_calc \u0026lt;- cv.glmnet(predictors_std, response_variable_std, alpha = 0, lambda = lambdas,nfolds = nrow(BostonHousing), grouped = FALSE) ## ～（略）～ log(optlambda) ## [1] -4.60517 Ridge回帰の結果 coef(fit_std, s = optlambda) ## Ridgeの結果 ## 14 x 1 sparse Matrix of class \u0026#34;dgCMatrix\u0026#34; ## 1 ## (Intercept) -8.075655e-16 ## crim -9.662095e-02 ## zn 1.100420e-01 ## indus 3.501806e-03 ## chas 7.587874e-02 ## nox -2.090907e-01 ## rm 2.953197e-01 ## age -1.009341e-03 ## dis -3.236125e-01 ## rad 2.537157e-01 ## tax -1.929854e-01 ## ptratio -2.198235e-01 ## b 9.215636e-02 ## lstat -4.006555e-01 結果の図からはLasso回帰と同様、$\\lambda$が大きくなるほどに各係数の値が小さくなる傾向が見てとれます。また0に近づく推移傾向はLasso回帰より緩やかであることも分かります。 rstanを用いた正則化回帰 以前の記事後半を参考に、rstanを用いて今までの正則化回帰と同様の分析を再現します。 Lasso回帰 lambdaの計算だけ注意が必要です。 $(4)$式左辺は以前の記事の$(12)$式の証明より、右辺は$(2)$式よりきています。 $$\r\\newcommand{\\argmin}{\\mathop{\\rm arg~min}\\limits}\r\\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\cfrac{2\\sigma^2}{b}||\\boldsymbol{w}_{-0}||_1^1\\right] =\r\\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\cfrac{1}{2N} \\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\lambda P_{\\alpha}(\\boldsymbol{w}_{-0})\\right] \\tag{4}\r$$\r $$\r\\newcommand{\\argmin}{\\mathop{\\rm arg~min}\\limits}\r\\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\cfrac{2\\sigma^2}{b}||\\boldsymbol{w}_{-0}||_1^1\\right] =\r\\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\cfrac{1}{2N} \\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\lambda ||\\boldsymbol{w}_{-0}||_1^1\\right] \\tag{5}\r$$\r $$\r2N\\lambda = \\cfrac{2\\sigma^2}{b} \\tag{6}\r$$\r $$\r\\therefore ~ \\lambda = \\cfrac{\\sigma^2}{Nb} \\tag{7}\r$$\r 実装 //model_lasso.stan data{ int N; //標本数 int H; //説明変数の数(切片を除く) vector[N] y; //目的変数 標準化済み matrix[N,H] x; // 説明変数 標準化済み } parameters{ real w_0; vector[H] w; //係数パラメータ real\u0026lt;lower=0\u0026gt; sigma; real\u0026lt;lower=0\u0026gt; b; } transformed parameters{ vector[N] mu; mu = w_0 + x * w; } model{ y ~ normal(mu, sigma); w ~ double_exponential(0, b); } generated quantities{ real log_lambda; log_lambda = log(sigma^2 / (N * b)); //(7)式 } 結果 以下で上記Stanファイルを走らせます。 data \u0026lt;- list(N=nrow(BostonHousing), H=ncol(predictors_std), y=as.vector(response_variable_std), x=predictors_std) stanmodel_lasso \u0026lt;- stan_model(\u0026#34;model_lasso.stan\u0026#34;) rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores()) fit_lasso \u0026lt;- sampling(stanmodel_lasso, data=data, iter=2500, warmup=500, chain=4) print(fit_lasso, pars=c(\u0026#34;w_0\u0026#34;,\u0026#34;w\u0026#34;,\u0026#34;log_lambda\u0026#34;)) ## Inference for Stan model: model_lasso. ## 4 chains, each with iter=2500; warmup=500; thin=1; ## post-warmup draws per chain=2000, total post-warmup draws=8000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## w_0 0.00 0 0.02 -0.05 -0.02 0.00 0.02 0.04 8915 1 ## w[1] -0.09 0 0.03 -0.15 -0.11 -0.09 -0.07 -0.03 9311 1 ## w[2] 0.11 0 0.03 0.04 0.08 0.11 0.13 0.17 7094 1 ## w[3] 0.00 0 0.04 -0.08 -0.03 0.00 0.03 0.08 7595 1 ## w[4] 0.07 0 0.02 0.03 0.06 0.07 0.09 0.12 8469 1 ## w[5] -0.21 0 0.05 -0.30 -0.24 -0.21 -0.17 -0.11 6364 1 ## w[6] 0.30 0 0.03 0.23 0.27 0.30 0.32 0.36 6917 1 ## w[7] 0.00 0 0.04 -0.07 -0.03 0.00 0.02 0.08 8055 1 ## w[8] -0.32 0 0.05 -0.41 -0.35 -0.32 -0.29 -0.23 7513 1 ## w[9] 0.24 0 0.06 0.12 0.20 0.24 0.29 0.37 5429 1 ## w[10] -0.18 0 0.07 -0.32 -0.23 -0.18 -0.14 -0.05 5855 1 ## w[11] -0.22 0 0.03 -0.28 -0.24 -0.22 -0.20 -0.16 7772 1 ## w[12] 0.09 0 0.03 0.04 0.07 0.09 0.11 0.14 8959 1 ## w[13] -0.40 0 0.04 -0.48 -0.43 -0.40 -0.38 -0.33 7017 1 ## log_lambda -5.93 0 0.31 -6.57 -6.14 -5.92 -5.71 -5.36 7056 1 係数パラメータの事後分布はglmnet()による結果と概ね整合しているようです。ただし、glmnet()によるLassoでは一部の係数パラメータが0となり、変数選択が可能であったのに対し、Bayesian Lassoでは中央値0付近の事後分布が得られるので、変数選択は難しくなります。 $\\lambda$を係数パラメータとともに最適化できることがBayesian Lassoの強みかもしれません。glmnet()では$\\lambda$をいくつか指定して交差検証により比較するしか方法が無かったので… 結果の描画のためのRスクリプトは以下になります。 library(bayesplot) # 係数パラメータの事後分布の描画(lasso) --------------------------------------------------------- w_id \u0026lt;- c(colnames(predictors)) names(w_id) \u0026lt;- c(sprintf(\u0026#34;w[%.0f]\u0026#34;, seq(1,13,by=1))) posterior \u0026lt;- as.matrix(fit_lasso) %\u0026gt;% as.data.frame() %\u0026gt;% select(starts_with(\u0026#34;w[\u0026#34;)) colnames(posterior) \u0026lt;- w_id[colnames(posterior)] par_median \u0026lt;- posterior %\u0026gt;% summarise_all(list(median)) %\u0026gt;% summarise_all(list(round),digits=3) %\u0026gt;% pivot_longer(everything()) plot_title \u0026lt;- ggtitle(\u0026#34;Posterior distributions(coefficients of Ridge regression)\u0026#34;, \u0026#34;with medians and 80% intervals\u0026#34;) p \u0026lt;- mcmc_areas(posterior, prob = 0.8) + plot_title + theme_light(base_size=11) + geom_text(data=par_median, aes(x=value, y=name, label=value), nudge_y = -0.25) # lambdaの事後分布の描画(lasso) ---------------------------------------------------------- posterior \u0026lt;- as.matrix(fit_lasso) %\u0026gt;% as.data.frame() %\u0026gt;% select(log_lambda) par_median \u0026lt;- posterior %\u0026gt;% summarise_all(list(median)) %\u0026gt;% summarise_all(list(round),digits=3) %\u0026gt;% pivot_longer(everything()) plot_title \u0026lt;- ggtitle(\u0026#34;Posterior distributions(lambda of lasso regression)\u0026#34;, \u0026#34;with medians and 80% intervals\u0026#34;) p \u0026lt;- mcmc_areas(posterior, prob = 0.8) + plot_title + theme_light(base_size=8) + geom_text(data=par_median, aes(x=value, y=name, label=value), nudge_y = -0.04) Ridge回帰 lambdaの計算方法は下記の通りです。 $(8)$式左辺は以前の記事の$(11)$式の証明より、右辺は$(2)$式よりきています。 $$\r\\newcommand{\\argmin}{\\mathop{\\rm arg~min}\\limits}\r\\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\rho\\sigma^2||\\boldsymbol{w}_{-0}||_1^1\\right] =\r\\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\cfrac{1}{2N} \\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\lambda P_{\\alpha}(\\boldsymbol{w}_{-0})\\right] \\tag{8}\r$$\r $$\r\\newcommand{\\argmin}{\\mathop{\\rm arg~min}\\limits}\r\\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\rho\\sigma^2||\\boldsymbol{w}_{-0}||_1^1\\right] =\r\\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\cfrac{1}{2N} \\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\cfrac{1}{2}\\lambda ||\\boldsymbol{w}_{-0}||_1^1\\right] \\tag{9}\r$$\r $$\rN\\lambda = \\rho\\sigma^2 \\tag{10}\r$$\r $$\r\\therefore ~ \\lambda = \\cfrac{\\rho\\sigma^2}{N} \\tag{11}\r$$\r 実装 //model_ridge.stan data{ int N; //標本数 int H; //説明変数の数(切片を除く) vector[N] y; //目的変数 標準化済み matrix[N,H] x; // 説明変数 標準化済み } parameters{ real w_0; vector[H] w; //係数パラメータ real\u0026lt;lower=0\u0026gt; sigma; real\u0026lt;lower=0\u0026gt; rho; } transformed parameters{ vector[N] mu; mu = w_0 + x * w; } model{ y ~ normal(mu, sigma); w ~ normal(0, (1 / sqrt(rho))); } generated quantities{ real log_lambda; log_lambda = log( rho * sigma^2 / N ); //(11)式 } 結果 以下で上記Stanファイルを走らせます。 stanmodel_ridge \u0026lt;- stan_model(\u0026#34;model_ridge.stan\u0026#34;) rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores()) fit_ridge \u0026lt;- sampling(stanmodel_ridge, data=data, iter=2500, warmup=500, chain=4) print(fit_ridge, pars=c(\u0026#34;w_0\u0026#34;,\u0026#34;w\u0026#34;,\u0026#34;log_lambda\u0026#34;)) ## Inference for Stan model: model_ridge. ## 4 chains, each with iter=2500; warmup=500; thin=1; ## post-warmup draws per chain=2000, total post-warmup draws=8000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## w_0 0.00 0 0.02 -0.04 -0.02 0.00 0.02 0.04 9413 1 ## w[1] -0.10 0 0.03 -0.15 -0.12 -0.10 -0.07 -0.03 9737 1 ## w[2] 0.11 0 0.03 0.04 0.09 0.11 0.13 0.17 6719 1 ## w[3] 0.00 0 0.04 -0.08 -0.03 0.00 0.03 0.09 7186 1 ## w[4] 0.08 0 0.02 0.03 0.06 0.08 0.09 0.12 8970 1 ## w[5] -0.21 0 0.05 -0.30 -0.24 -0.21 -0.17 -0.11 6529 1 ## w[6] 0.30 0 0.03 0.23 0.28 0.30 0.32 0.36 6418 1 ## w[7] 0.00 0 0.04 -0.08 -0.03 0.00 0.02 0.08 7222 1 ## w[8] -0.32 0 0.04 -0.41 -0.35 -0.32 -0.29 -0.23 5893 1 ## w[9] 0.25 0 0.06 0.13 0.21 0.25 0.29 0.36 5012 1 ## w[10] -0.19 0 0.06 -0.31 -0.23 -0.19 -0.14 -0.06 5198 1 ## w[11] -0.22 0 0.03 -0.28 -0.24 -0.22 -0.20 -0.16 7225 1 ## w[12] 0.09 0 0.03 0.04 0.07 0.09 0.11 0.14 7857 1 ## w[13] -0.40 0 0.04 -0.47 -0.43 -0.40 -0.37 -0.32 6705 1 ## log_lambda -4.38 0 0.41 -5.23 -4.64 -4.36 -4.09 -3.65 7454 1 係数パラメータの事後分布はglmnet()による結果と概ね整合しているようです。 $\\lambda$の事後分布は以下のとおりになりました。 まとめ 損失関数に係数パラメータのノルム分ペナルティを加えることによる通常の正則化回帰と、Bayesian正則化回帰の整合性を実験により確認することができました。まあまあ楽しかったです。 実用上の観点から両者を比較すると、通常の正則化回帰は（特にLasso回帰の場合）係数パラメータが0に収束することを用いた変数選択が可能であることが強みです。一方Bayesian正則化回帰では、係数パラメータとともに、係数パラメータのノルム分ペナルティの重み$\\lambda$を事後分布の形で最適化できることが強みになるのかなと思います。あとはrstanを用いるので当然様々なモデルへの応用・拡張がきくことも強みです。 以前の記事$(7)$$(8)$式は切片パラメータ$w_0$のノルム分のペナルティも課していましたが、$w_0$は$(2)$$(3)$式のようにペナルティの項から外すのが普通？切片は大きくなっても過学習とは関係ないし… \u0026#x21a9;\u0026#xfe0e;"
  },
  {
    url: "https://sucre-stat.com/julia/",
    title: "Julia",
    date: "2021-01-05T00:00:00Z",
    body: "Julia"
  },
  {
    url: "https://sucre-stat.com/2021/01/begin-julia/",
    title: "Julia始めました",
    date: "2021-01-05T00:00:00Z",
    body: "Julia始めました ふと、R言語以外も使っていろいろとできるようになりたいと思い立ちました。 特にきっかけがあったわけではないのです。まだR歴も浅く綺麗なコードにもほど遠いですし、Rを使って試したいこともまだまだたくさんあります。shinyを使ったアプリ開発とか・・・ ただ趣味でやっている以上、興味をもった対象には少しでも触れてみたいのです。 JuliaはRはPython等の動的型付け言語と比べて計算速度が速く、C言語にも迫る速度だという。 個人的にも、仕事でビックデータを扱う場面があるし、MCMCの計算時間を短縮したいので、計算速度の速い言語に手をつけるのはメリットが多そうだ。 ということでJuliaを勉強していこうと思います。 using LinearAlgebra dot([1,2,3],[4,5,6]) # 32 cross([0,1,0],[0,0,1]) #= 3-element Array{Int64,1}: 1 0 0 =# using Gadfly, RDatasets iris = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;iris\u0026#34;) p = plot(iris, x=:SepalLength, y=:SepalWidth, Geom.point) \r SepalLength 4 5 6 7 8 2.0 2.5 3.0 3.5 4.0 4.5 SepalWidth …こんな感じで！"
  },
  {
    url: "https://sucre-stat.com/2021/01/begin-julia/",
    title: "Julia始めました",
    date: "2021-01-05T00:00:00Z",
    body: "Julia始めました ふと、R言語以外も使っていろいろとできるようになりたいと思い立ちました。 特にきっかけがあったわけではないのです。まだR歴も浅く綺麗なコードにもほど遠いですし、Rを使って試したいこともまだまだたくさんあります。shinyを使ったアプリ開発とか・・・ ただ趣味でやっている以上、興味をもった対象には少しでも触れてみたいのです。 JuliaはRはPython等の動的型付け言語と比べて計算速度が速く、C言語にも迫る速度だという。 個人的にも、仕事でビックデータを扱う場面があるし、MCMCの計算時間を短縮したいので、計算速度の速い言語に手をつけるのはメリットが多そうだ。 ということでJuliaを勉強していこうと思います。 using LinearAlgebra dot([1,2,3],[4,5,6]) # 32 cross([0,1,0],[0,0,1]) #= 3-element Array{Int64,1}: 1 0 0 =# using Gadfly, RDatasets iris = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;iris\u0026#34;) p = plot(iris, x=:SepalLength, y=:SepalWidth, Geom.point) \r SepalLength 4 5 6 7 8 2.0 2.5 3.0 3.5 4.0 4.5 SepalWidth …こんな感じで！"
  },
  {
    url: "https://sucre-stat.com/tags/rstan/",
    title: "rstan",
    date: "2021-01-05T00:00:00Z",
    body: "rstan"
  },
  {
    url: "https://sucre-stat.com/2020/12/information-criterion/",
    title: "モデル選択基準",
    date: "2020-12-30T00:00:00Z",
    body: "モデル選択基準 この記事について 情報量基準などのモデル選択基準について得た断片的な知識をまとめたい。自分の力では一生断片的な知識としかならないだろうが、ブログに残しておくことで少しでも自分の中で体系化できたらいな。 随時更新予定？ memo\r\r情報量基準は、候補モデルが将来得られるデータをどの程度精度よく予測できるかを評価したもの。\r 1. カルバック・ライブラー情報量基準 1.1. 定義 $y$を目的変数、$x$を説明変数とする。 カルバック・ライブラー情報量基準は、$y$についての2つの生成分布に比の対数について、真のデータ生成分布で期待値をとったものとみなすことができる。 カルバック・ライブラー(KL)情報量基準\r$q(x)$を真のデータ生成分布、$f(x)$をデータ予測モデルとしたとき、カルバック・ライブラー情報量基準は以下で定義される。 $$ \\mathcal{D}(f;q) = E_{q}\\left[\\log\\cfrac{q(x)}{f(x)}\\right] = \\int_{-∞}^{∞}~q(x)\\log\\cfrac{q(x)}{f(x)}~d(x) \\tag{1} $$ 1.2. 性質 KL情報量基準は以下のような性質を持つ。これらの性質は2つのデータ生成分布の差としてイメージしやすいと思う。 非負性 $$ \\mathcal{D}(f;q) \u0026gt; 0 $$ 完備性 $$ \\mathcal{D}(f;q) = 0 のときf=q $$ カルバック・ライブラー情報量基準は予測モデル$f(x)$の平均的な予測の良さを表現する。 ただし通常データ生成分布は未知であるからこれは計算できない。 2. AIC（赤池情報量基準） 2.1. 平均対数尤度 カルバック・ライブラー情報量基準は以下の通り対数尤度の期待値の差としても表現できる。 $$\r\\mathcal{D}(f;q) = E_{q}\\left[\\log~q(x)\\right] - E_{q}\\left[\\log~f(x)\\right] = \\int_{-∞}^{∞}q(x)\\log q(x) dx - \\int_{-∞}^{∞}q(x)\\log f(x) dx \\tag{2}\r$$\r 特に母数が所与のもとでは、 $$ \\mathcal{D}(f;q) = \\int_{-∞}^{∞}q(x)\\log q(x) dx - \\int_{-∞}^{∞}q(x)\\log f(x | \\theta) dx \\tag{3}\r$$\r 第2項は対数尤度$f(x|\\theta)$を真の生成分布について期待値をとったものであり、平均対数尤度と呼ぶ。 情報量の算出理由が候補モデル間の比較である場合、第1項は共通であるから、第2項の平均対数尤度のみで比較すればよいことが分かる。 しかしこれも真のデータ生成分布が未知の場合は評価不能。そこで、将来得られるデータに対する予測の良さの観点から平均対数尤度を比較するため、平均対数尤度について確率変数$X$に関する期待値をとる。 $$\rE_X\\left[E_q\\left[\\right[\\log f(x|\\theta)]\\right] \\tag{4}\r$$\r これを期待平均対数尤度とよぶ。 2.2. AICの定義・導出 AIC(赤池情報量基準)は前節の期待平均対数尤度を近似することから導出されるものである。 以下で定義される最大対数尤度 $$\r\\log L_{max}(\\boldsymbol{x} | \\theta) = \\sum_{n=1}^{N}\\log f(x_{n}| \\hat{\\theta}) \\tag{5}\r$$\r を用いて、期待平均対数尤度を $$\rE_X\\left[E_q\\left[\\right[\\log f(x|\\theta)]\\right] \\approx \\cfrac{\\log L_{max}(\\boldsymbol{x} | \\theta)}{N} \\tag{6}\r$$\r と近似する。さらに母数の数についてバイアス補正し、$-2N$倍することにより、下記AICが導出される。 AIC\rAICは下記式で定義される。 $$ -2\\log L_{max}(\\boldsymbol{x}|\\hat{\\theta}) + 2p \\tag{7} $$ ただし、$p$はモデル中の未制約母数の数。\r AICの値が小さい程よいモデルであるとみなす。$(7)$式は対数尤度が高いモデルをなるべく少ない母数の数で達成しようとするものであるとみなすことが出来る。 2.3. AICの適用制限 AICは、以下の条件が満たされる場合のみに適用可能。らしい。 $q(x) = f(x|\\theta)$となる母数が存在する 尤度関数（事後分布）が正規分布で近似可能 そのため、多くのベイジアンモデルでは、事後分布が正規分布で近似できないため、AICを用いることが出来ない。代わりに交差検証法やWAICを用いる。 3. 交差検証法 3.1. 交差検証法 モデル評価のもう一つの方法に交差検証法がある。交差検証法も将来得られるデータ$x^{*}$に対する平均対数尤度 $$\rE_{q}\\left[\\log~f(x^{*}|\\theta)\\right] = \\int_{-∞}^{∞}q(x^{ *})\\log f(x^{ *} | \\theta) dx \\tag{8}\r$$\r の推定量を検証する。 3.2. LOOCV（1個抜き交差検証法） LOOCV(1個抜き交差検証法)では、テストデータとして$\\boldsymbol{x}$のなかから$x_k$だけを用い、それ以外をトレーニングデータとして利用する、という手続きを$N$個の点に対して繰り返し適用し、モデル性能を評価する。 3.3. MCMC標本を用いたLOOCVの推定 まずは一般の交差検証法について、MCMC標本を用いた推定方法を考える。 $K$個のデータをテスト用のデータとして用いた状態で、それ以外をトレーニングデータとして推定した候補モデルを用いて、テストデータ$\\boldsymbol{x}^{* }$に関する尤度を $$\rf^{(-K)}(\\boldsymbol{x}^{*}|\\theta) \\tag{9}\r$$\r と表す。モデルは母数$\\theta$を持っているので、母数事後分布$f(\\theta)$が得られた状況下では、$(9)$式に関する対数予測密度 $$\rlpd = \\log \\int_{-∞}^{∞} f^{(-K)}(\\boldsymbol{x}^{*}|\\theta) f(\\theta) d\\theta \\tag{10}\r$$\r を評価できる。これは1組のトレーニングデータ・テストデータを用いてテストデータ$\\boldsymbol{x}^{* }$に関する候補モデルの尤度の$f(\\theta)$に対する期待値をとったものである。 これをMCMC標本を用いて近似する場合には、 $$\rlpd \\approx \\log\\left[\\cfrac{1}{T}\\sum_{t=1}^{T}f(\\boldsymbol{x}^{*} | \\theta^{(t)})\\right]^{(-K)} \\tag{11}\r$$\r とすればよい。ここで$T$はMCMC標本の数、$\\theta^{(t)}$は母数の1MCMC標本である。右上の$(-K)$は$K$個のデータをテストデータとして推定から除外した状態であることを意味する。 LOOCVのときも同様にして、 $$\rlpd_{loo} = \\log \\int_{-∞}^{∞} f^{(-k)}(x_{k}|\\theta) f(\\theta) d\\theta \\approx \\log\\left[\\cfrac{1}{T}\\sum_{t=1}^{T}f(x_{k} | \\theta^{(t)})\\right]^{(-k)} \\tag{12}\r$$\r を$(8)$式の推定量として計算できる。ここで右上の$(-k)$は$k$番目の標本をテストデータとして推定から除外した状態を意味する。 あとはすべての$k$について$(12)$式を足し上げればよい。 LOOCVによる平均対数尤度の推定量（対数点別予測密度）\rLOOCVにおける候補モデルのデータに対する予測精度は、 $$ lppd_{loo} \\approx \\sum_{k=1}^{N} \\log\\left[\\cfrac{1}{T}\\sum_{t=1}^{T}f(x_{k} | \\theta^{(t)})\\right]^{(-k)} \\tag{13} $$ で与えられる。これを対数点別予測密度という。 4. WAIC WAIC(Widely Applicable Information Criterion)は、2010年に東京工業大学の渡辺先生が考案した情報量基準。 LOOCVと同様に、将来得られるデータに対する平均対数尤度（$(8)$式）を推定することを目的とする。 $(8)$式はデータ生成分布について期待値を取る必要があるが、今までと同様データ生成分布は未知であるから計算できない。今度はデータ生成分布を事後分布で近似することを考える。 $$\relppd = \\sum_{i=1}^{N} E_{post}\\left[\\log f(x_i^{ *} | \\theta)\\right] \\left( \\approx E_{q}\\left[\\log~f(x^{ *}|\\theta)\\right] \\right) \\tag{14}\r$$\r $(14)$式の$elppd$は期待対数点別予測密度と呼ばれる。これをMCMCサンプルを用いて近似計算することを考える。 まず、将来得られる1つのデータ$x_i$に対する予測精度の評価値$lpd$を以下の通り再定義する。 $$\rlpd_{WAIC} = \\log\\left[\\cfrac{1}{T}\\sum_{t=1}^{T}f(x_{i} | \\theta^{(t)})\\right] \\left(\\approx E_{post}\\left[\\log f(x_i|\\theta)\\right] \\right) \\tag{15}\r$$\r これを$N$個すべてのデータ点で足し上げれば、$(14)$式のMCMCサンプルを用いた近似値$lppd_{WAIC}$（対数点別予測密度）を得ることができる。 $$\rlppd_{WAIC} = \\sum_{i=1}^{N} \\log\\left[\\cfrac{1}{T}\\sum_{t=1}^{T}f(x_{i} | \\theta^{(t)})\\right] \\left( \\approx \\sum_{i=1}^{N} E_{post}\\left[\\log f(x_i | \\theta)\\right] \\right) \\tag{16}\r$$\r ただし、$(16)$式からわかるように、将来得られるデータとして既に得られた標本を用いている為、学習データに箇条適合してしまっている。その修正項として以下の有効パラメータと呼ばれる項をペナルティとして$(16)$式に考慮する。 $$\rp_{WAIC} = \\sum_{i=1}^{N} V_{post}\\left[\\log f(x_{i}|\\theta)\\right] \\tag{17}\r$$\r 以上を踏まえ、また式の形をAICに合わせることで、WAICは下記の通り定義される。 WAIC\rWaicは下記式で定義される。 $$ WAIC = -2\\sum_{i=1}^{N} \\log\\left[\\cfrac{1}{T}\\sum_{t=1}^{T}f(x_{i} | \\theta^{(t)})\\right] + 2\\sum_{i=1}^{N} V_{post}\\left[\\log f(x_{i}|\\theta)\\right] \\tag{18} $$\r WAICは、事後分布が正規分布で近似できないような多くのベイジアンモデルにおいても適用可能な情報量基準量である。"
  },
  {
    url: "https://sucre-stat.com/tags/%E6%83%85%E5%A0%B1%E9%87%8F%E5%9F%BA%E6%BA%96/",
    title: "情報量基準",
    date: "2020-12-30T00:00:00Z",
    body: "情報量基準"
  },
  {
    url: "https://sucre-stat.com/2020/12/regularization/",
    title: "正則化（Ridge回帰とLasso回帰）について",
    date: "2020-12-29T00:00:00Z",
    body: "正則化（Ridge回帰とLasso回帰）について はじめに 今回は、回帰分析において過学習を防いだり、多重共線性に対応したりするために使われるRidge回帰や、変数の数が標本数より多いような時に変数選択の方法として使われるLasso回帰について、理論を整理しようと思います。 これら2つの手法ともには正則化という手法で説明されるものです。まずは正則化の観点からRidge回帰とLasso回帰を理解し、さらにこれらの手法が確率モデルでも説明可能であることを示そうと思います。 確率モデルで説明可能な手法であるということは、データセットとモデルから尤度を計算しベイズ推定可能であるということなので、ゆくゆくはRstanでこれら2つの手法を実装してみたいと思っています。 本記事の構成は以下の通りです。 はじめに 線形回帰の導入 正則化 確率モデルでRidge回帰を捉える 確率モデルでLasso回帰を捉える 蛇足 参考にした本や記事は以下のとおりです。 ガウス過程と機械学習 リッジ回帰（Ridge Regression） Lasso回帰（Lasso Regression） ラッソ回帰(L1正則化)を理解する(理論編) - Qiita 線形回帰の導入 以下の線形回帰を考えます。 $$\r\\hat{y} = w_0 + w_1\\phi_1(\\boldsymbol{x}) + \\ldots, w_H\\phi_H(\\boldsymbol{x}) \\tag{1}\r$$\r ここで$\\phi(\\boldsymbol{x})$は$\\boldsymbol{x}$の関数です。 これを行列で表現すると、 $$\r\\left(\r\\begin{array}{ccc}\r\\hat{y}_1 \\\\\\\\\r\\hat{y}_2 \\\\\\\\\r\\vdots \\\\\\\\\r\\hat{y}_N\r\\end{array}\r\\right) =\r\\left(\r\\begin{array}{ccc}\r\\phi_0(\\boldsymbol{x}_1) \u0026 \\phi_1(\\boldsymbol{x}_1) \u0026 \\cdots \u0026 \\phi_H(\\boldsymbol{x}_1) \\\\\\\\\r\\phi_0(\\boldsymbol{x}_2) \u0026 \\phi_1(\\boldsymbol{x}_2) \u0026 \\cdots \u0026 \\phi_H(\\boldsymbol{x}_2) \\\\\\\\\r\\cdots \u0026 \\cdots \u0026 \\ddots \u0026 \\cdots \\\\\\\\\r\\phi_0(\\boldsymbol{x}_N) \u0026 \\phi_1(\\boldsymbol{x}_N) \u0026 \\cdots \u0026 \\phi_H(\\boldsymbol{x}_N)\r\\end{array}\r\\right)\r\\left(\r\\begin{array}{ccc}\rw_0 \\\\\\\\\rw_1 \\\\\\\\\r\\vdots \\\\\\\\\rw_H\r\\end{array}\r\\right) \\tag{2}\r$$\r ただし、$\\phi_0({\\boldsymbol{x}_n}) = 1$です。 これを行列を使って以下のように表記します。 $$\r\\hat{\\boldsymbol{y}} = \\boldsymbol{\\Phi}\\boldsymbol{w} \\tag{3}\r$$\r 一般に$\\boldsymbol{\\Phi}$を計画行列と呼びます。また$\\phi_0(\\boldsymbol{x}),\\ldots,\\phi_H(\\boldsymbol{x})$を基底関数、$\\boldsymbol{\\phi}(\\boldsymbol{x}) = \\left(\\phi_0(\\boldsymbol{x}),\\phi_1(\\boldsymbol{x}),\\ldots, \\phi_H(\\boldsymbol{x}) \\right)^T$を$\\boldsymbol{x}$の特徴ベクトルと呼びます。 memo\r\r基底関数を、ベクトル$\\boldsymbol{x}$をスカラーに変換する解析的な関数であると想定していますが、\r通常の重回帰モデルも$\\boldsymbol{\\phi}(\\boldsymbol{x}) = \\boldsymbol{x}$とすれば$(3)$式で説明できます！その場合基底関数は各変数それぞれを出力する関数になります。\r\r このとき、以下の公式が得られます。 ◆線形回帰モデルの解\r線形回帰モデル$\\hat{\\boldsymbol{y}} = \\boldsymbol{\\Phi}\\boldsymbol{w}$における$\\boldsymbol{w}$の最小二乗解は $$ \\boldsymbol{w} = \\left(\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}\\right)^{-1}\\boldsymbol{\\Phi}^T\\boldsymbol{y} \\tag{4} $$\r ◆証明\rデータ全体の誤差(損失関数)は、\r$$\rE = \\sum_{n=1}^{N} \\left( y_n - \\boldsymbol{\\phi}(\\boldsymbol{x}_n)\\boldsymbol{w} \\right)^2 = (\\boldsymbol{y}-\\boldsymbol{\\Phi}\\boldsymbol{w})^T(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}) = \\boldsymbol{y}^T\\boldsymbol{y} - 2\\boldsymbol{w}^T(\\boldsymbol{\\Phi}^T\\boldsymbol{y}) + \\boldsymbol{w}^T\\boldsymbol{\\Phi}\\boldsymbol{\\Phi}\\boldsymbol{w} \\tag{5}\r$$\rこれを$\\boldsymbol{w}$で微分すると、\r$$\r\\cfrac{\\partial E}{\\partial\\boldsymbol{w}} = -2\\boldsymbol{\\Phi}^T\\boldsymbol{y} + 2\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}\\boldsymbol{w} \\tag{6}\r$$\rよって、$E$を最小化する$\\boldsymbol{w}$は、$\\cfrac{\\partial E}{\\partial\\boldsymbol{w}}=0$より下記の通り得られる。\r$$\r\\boldsymbol{w} = \\left(\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}\\right)^{-1}\\boldsymbol{\\Phi}^T\\boldsymbol{y}\r$$\r\r 正則化 線形回帰モデルの係数パラメータは$(4)$式で計算できることが分かりましたが、右辺には$\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}$の逆行列が存在するため、$\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}$が正則でない場合、係数パラメータの解を得ることが出来ません。 memo\r\r$n$次正方行列$\\boldsymbol{A}$について、\r$$\r\\boldsymbol{A}\\boldsymbol{B} = \\boldsymbol{B}\\boldsymbol{A} = \\boldsymbol{I}\r$$\rとなる$n$次正方行列$\\boldsymbol{B}$が存在するとき、$\\boldsymbol{A}$は正則であるという。\r\r では、$\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}$が正則でないのは具体的にどんな場合かとうと、$\\boldsymbol{\\phi}_ {i}(\\boldsymbol{x}) = \\boldsymbol{\\phi}_ {j}(\\boldsymbol{x})$、もしくは$\\boldsymbol{\\phi}_ {i}(\\boldsymbol{x}) = \\alpha\\boldsymbol{\\phi}_ {j}(\\boldsymbol{x})~~(\\alpha \\in \\mathbb{R})$となるような$\\boldsymbol{\\phi}(\\boldsymbol{x})$の組が存在する場合が典型的です。このような場合、$\\boldsymbol{\\phi}_ {i}(\\boldsymbol{x})$と$\\boldsymbol{\\phi}_ {j}(\\boldsymbol{x})$の相関は1または-1になっています。また$\\boldsymbol{\\phi}(\\boldsymbol{x}_ {i}) \\simeq \\alpha\\boldsymbol{\\phi}(\\boldsymbol{x}_ {j})$だったりする場合では、$\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}^{-1}$の要素が大きくなり、結果的に$\\boldsymbol{w}$の絶対値が大きくなってしまい、過学習が生じるようです。このような場合では、$\\boldsymbol{\\phi}_ {i}(\\boldsymbol{x})$と$\\boldsymbol{\\phi}_ {j}(\\boldsymbol{x})$はかなり強い相関関係になっています1。 memo\r\r$\\boldsymbol{\\phi}_ {i}(\\boldsymbol{x}) = \\alpha\\boldsymbol{\\phi}_ {j}(\\boldsymbol{x})~~(\\alpha \\in \\mathbb{R})$となるような$\\boldsymbol{\\phi}(\\boldsymbol{x})$の組が存在する場合、\r$$\r\\mathrm{rank}\\left(\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}\\right) 係数パラメータの絶対値が大きくなるのを避けるための工夫が正則化です。正則化では、$(5)$式で得られたデータ全体の誤差に、$\\boldsymbol{w}$の絶対値が大きくなることによるペナルティを課すように設定します。 このペナルティの設定方法が、Ridge回帰とLasso回帰の唯一の違いです。 ◆Ridge回帰とLasso回帰の損失関数\rRidge回帰における損失関数は、 $$ E = (\\boldsymbol{y}-\\boldsymbol{\\Phi}\\boldsymbol{w})^T(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}) + \\alpha||\\boldsymbol{w}||_2^2 \\tag{7} $$ Lasso回帰における損失関数は、 $$ E = (\\boldsymbol{y}-\\boldsymbol{\\Phi}\\boldsymbol{w})^T(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}) + \\alpha||\\boldsymbol{w}||_1^1 \\tag{8} $$ ただし、$\\alpha \\geq 0$\r memo\r\r$||\\boldsymbol{x}||_p$はベクトルの$p$ノルムといい\r$$\r||\\boldsymbol{x}||_p = \\sqrt[p]{|x_1|^p+\\ldots,|x_n|^p}\r$$\rを意味する。定義より$||\\boldsymbol{x}||_1^1$は$\\boldsymbol{x}$のマンハッタン距離を、$||\\boldsymbol{x}||_2^2$は$\\boldsymbol{x}$のユークリッド距離を意味する。\r\r 損失関数を上記のように設定することが$\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}$が正則でない場合に有効である仕組みを把握するために、Ridge回帰の場合についてみていきます。 $(7)$式を$\\boldsymbol{w}$で微分すると、 $$\r\\cfrac{\\partial E}{\\partial\\boldsymbol{w}} = -2\\boldsymbol{\\Phi}^T\\boldsymbol{y} + 2\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}\\boldsymbol{w} + 2\\alpha\\boldsymbol{w} \\tag{9}\r$$\r よって、$E$を最小化する$\\boldsymbol{w}$は、$\\cfrac{\\partial E}{\\partial\\boldsymbol{w}}=0$より下記のとおり得られます。 $$\r\\boldsymbol{w} = \\left(\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi} + \\alpha\\boldsymbol{I}\\right)^{-1}\\boldsymbol{\\Phi}^T\\boldsymbol{y} \\tag{10}\r$$\r リッジ回帰は、もともとは$(7)$式のように損失関数に$\\boldsymbol{w}$の絶対値を小さくする為の項を設定したものでしたが、結果的に$\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}$の対角要素に微小量$\\alpha$を足すことで、逆行列計算の対象が正則行列であることを確実にし、計算を安定化させていることが分かります。 memo\r\r任意の行列$\\boldsymbol{A} ∈ \\mathbb{R}^{m×n}$、ベクトル$\\boldsymbol{x} ∈ \\mathbb{R}^m \\neq \\boldsymbol{0}$について、\r$$\r\\boldsymbol{x}^T\\left(\\boldsymbol{A}\\boldsymbol{A}^T\\right)\\boldsymbol{x} = \\left(\\boldsymbol{A}^T\\boldsymbol{x}\\right)^T\\left(\\boldsymbol{A}^T\\boldsymbol{x}\\right) = ||\\boldsymbol{A}^T\\boldsymbol{x}||_2^2 \\geq 0\r$$\rだから、$\\boldsymbol{A}\\boldsymbol{A}^T$は半正定値行列。\rまた\r$$\r\\boldsymbol{x}^T\\left(\\alpha\\boldsymbol{I}\\right)\\boldsymbol{x} = \\alpha||\\boldsymbol{x}||_2^2 0\r$$\rだから、$\\alpha\\boldsymbol{I}$は正定値行列。このとき\r$$\r\\boldsymbol{x}^T\\left(\\boldsymbol{A}\\boldsymbol{A}^T + \\alpha\\boldsymbol{I}\\right)\\boldsymbol{x} = ||\\boldsymbol{A}^T\\boldsymbol{x}||_2^2 + \\alpha||\\boldsymbol{x}||_2^2 0\r$$\rよって$\\boldsymbol{A}^T\\boldsymbol{A} + \\alpha\\boldsymbol{I}$は正定値行列であり、正則行列。\r\r Lasso回帰については同様の方法では正則化との関係が見えてきませんでした。ただ係数パラメータの多くが0になる仕組みについてはこちらの記事に詳しかったです。 確率モデルでRidge回帰を捉える 前節で説明したRidge回帰は確率分布を用いた以下のモデルでも説明できます。 ◆Ridge回帰の確率モデル\r$(7)$のRidge回帰と等価の確率モデルは、 $$ \\begin{cases} p(y | \\boldsymbol{w}, \\boldsymbol{x}) = \\mathrm{Normal}(y | \\boldsymbol{w}^T\\boldsymbol{\\phi}(\\boldsymbol{x}), \\sigma^2) \\\\ p(\\boldsymbol{w}) = \\mathrm{Normal}(\\boldsymbol{w}|0, \\rho^{-1}\\boldsymbol{I}_H) \\end{cases} \\tag{11} $$ ただし、$\\alpha = \\rho\\sigma^2$\r ◆証明\r$y$と$\\boldsymbol{w}$の同時確率密度について以下の通り仮定する。\r$$\rp(y,\\boldsymbol{w}|\\boldsymbol{x}) = p(y | \\boldsymbol{w},\\boldsymbol{x})p(\\boldsymbol{w})\r$$\rこれを$\\boldsymbol{w}$の関数$F(\\boldsymbol{w})$とみたとき、独立同分布のデータセット$\\boldsymbol{y}$、$\\boldsymbol{X}=(\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_N)^T$がすべて観測された時の$F(\\boldsymbol{w})$を最大化する$\\boldsymbol{w}$が最尤推定解である。\r$$\r\\newcommand{\\argmax}{\\mathop{\\rm arg~max}\\limits}\r\\newcommand{\\argmin}{\\mathop{\\rm arg~min}\\limits}\r\\begin{split}\r\\argmax_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}} \\log F(\\boldsymbol{w}) \u0026= \\argmax_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}} \\log \\prod_{n=1}^{N}p(y_n|\\boldsymbol{w}, \\boldsymbol{x}_ n)p(\\boldsymbol{w})\\\\\\\\\r\u0026= \\argmax_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[ \\sum_{n=1}^{N}\\log\\mathrm{Normal}(y_n| \\boldsymbol{w}^T\\boldsymbol{\\phi}(\\boldsymbol{x}),\\sigma^2) + \\log\\mathrm{Normal}(\\boldsymbol{w}|\\boldsymbol{0}, \\rho^{-1}\\boldsymbol{I}_H)\\right] \\\\\\\\\r\u0026= \\argmax_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\log\\mathrm{MultiNormal}(\\boldsymbol{y}| \\boldsymbol{\\Phi}\\boldsymbol{w},\\sigma^2\\boldsymbol{I}_N) + \\log\\mathrm{Normal}(\\boldsymbol{w}|\\boldsymbol{0}, \\rho^{-1}\\boldsymbol{I}_H)\\right] \\\\\\\\\r\u0026= \\argmax_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[ -\\cfrac{1}{2\\sigma^2}\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) -\\cfrac{\\rho}{2}\\boldsymbol{w}^T\\boldsymbol{w} + C \\right] \\\\\\\\\r\u0026=\\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\rho\\sigma^2||\\boldsymbol{w}||_2^2\\right] \\\\\\\\\r\u0026= \\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\alpha||\\boldsymbol{w}||_2^2\\right]\r\\end{split}\r$$\rこれは$(7)$式のRidge回帰における損失関数$E$の$\\boldsymbol{w}$についての最小化である。\r\r 確率モデルでLasso回帰を捉える Lasso回帰は確率分布を用いた以下のモデルでも説明できます。 ◆Lasso回帰の確率モデル\r$(8)$のLasso回帰と等価の確率モデルは、 $$ \\begin{cases} p(y | \\boldsymbol{w}, \\boldsymbol{x}) = \\mathrm{Normal}(y | \\boldsymbol{w}^T\\boldsymbol{\\phi}(\\boldsymbol{x}), \\sigma^2) \\\\ p(\\boldsymbol{w}) = \\prod_{h=1}^{H}\\mathrm{Laplace}(w_h | 0, b) \\end{cases} \\tag{12} $$ ただし、$\\alpha = \\cfrac{2\\sigma^2}{b}$\r ◆証明\r$y$と$\\boldsymbol{w}$の同時確率密度について以下の通り仮定する。\r$$\rp(y,\\boldsymbol{w}|\\boldsymbol{x}) = p(y | \\boldsymbol{w},\\boldsymbol{x})p(\\boldsymbol{w})\r$$\rこれを$\\boldsymbol{w}$の関数$F(\\boldsymbol{w})$とみたとき、独立同分布のデータセット$\\boldsymbol{y}$、$\\boldsymbol{X}=(\\boldsymbol{x}_1,\\ldots,\\boldsymbol{x}_N)^T$がすべて観測された時の$F(\\boldsymbol{w})$を最大化する$\\boldsymbol{w}$が最尤推定解である。\r$$\r\\newcommand{\\argmax}{\\mathop{\\rm arg~max}\\limits}\r\\newcommand{\\argmin}{\\mathop{\\rm arg~min}\\limits}\r\\begin{split}\r\\argmax_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}} \\log F(\\boldsymbol{w}) \u0026= \\argmax_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}} \\log \\prod_{n=1}^{N}p(y_n|\\boldsymbol{w}, \\boldsymbol{x}_ n)p(\\boldsymbol{w})\\\\\\\\\r\u0026= \\argmax_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[ \\sum_{n=1}^{N}\\log\\mathrm{Normal}(y_n| \\boldsymbol{w}^T\\boldsymbol{\\phi}(\\boldsymbol{x}),\\sigma^2) + \\sum_{h=1}^{H}\\log\\mathrm{Laplace}(w_h|0, b)\\right] \\\\\\\\\r\u0026= \\argmax_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\log\\mathrm{MultiNormal}(\\boldsymbol{y}| \\boldsymbol{\\Phi}\\boldsymbol{w},\\sigma^2\\boldsymbol{I}_ N) + \\sum_{h=1}^{H}\\log\\mathrm{Laplace}(w_h|0, b)\\right] \\\\\\\\\r\u0026= \\argmax_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[ -\\cfrac{1}{2\\sigma^2}\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) - \\cfrac{1}{b}\\sum_{h=1}^{H}|w_h| + C \\right] \\\\\\\\\r\u0026=\\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\cfrac{2\\sigma^2}{b}||\\boldsymbol{w}||_1^1\\right] \\\\\\\\\r\u0026= \\argmin_{\\boldsymbol{w}∈\\mathbb{R}^{H+1}}\\left[\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right)^T\\left(\\boldsymbol{y} - \\boldsymbol{\\Phi}\\boldsymbol{w}\\right) + \\alpha||\\boldsymbol{w}||_1^1\\right]\r\\end{split}\r$$\rこれは$(8)$式のLasso回帰における損失関数$E$の$\\boldsymbol{w}$についての最小化である。\r\r memo\r\r確率密度$p(x)$が\r$$\rp(x) = \\cfrac{1}{2b}\\exp\\left[-\\cfrac{|x - \\mu|}{b}\\right]\r$$\rである確率分布をラプラス分布といい、確率変数$X$がラプラス分布に従うことを\r$$\rX \\sim \\mathrm{Laplace}(\\mu, b)\r$$\rと表す。\r\r 蛇足 今回の記事はHugoのshortcode機能を駆使して文章に枠をもたせてみました。今までの記事よりかなり見やすくなっていませんか？？しばらくはこのスタイルで行こうと思います。 最後に今回の記事のイメージソングをあげておきます。ブログ名の由来になった曲です。 回帰分析で生じるこのような問題は多重共線性と呼ばれています。 \u0026#x21a9;\u0026#xfe0e;"
  },
  {
    url: "https://sucre-stat.com/2020/12/tokyo-meshdata/",
    title: "Soft K-means法とガウス過程",
    date: "2020-12-24T00:00:00Z",
    body: "Soft K-means法とガウス過程 はじめに 今回は分類についての記事です。 正規分布の混合モデルをによるsoft K-Means法を扱います。 タイトルにガウス過程とありますが、今回使用するデータが空間データなので、ガウス過程を用いて空間の近接性を考慮したクラスタリングにも挑戦しました、結果、うまくいかなかったのですが… 本記事の構成は以下の通りです。 はじめに 理論 Hard K-means法 Soft K-means法 実践 サンプルデータの準備 実装 結果 ガウス過程をあてはめてみる 理論 Hard K-means法 K-means法はデータをK個のクラスに分類する手法で、典型的には幾何学的・解析的に解が求まるHard K-means法が扱われます。 標本$\\boldsymbol{y}_ 1,\\ldots,\\boldsymbol{y}_ N$を$K$個のクラスターに分類したいとします。ここで$\\boldsymbol{y}_n = (y_{1n},\\ldots, y_{Dn})$、変数の数は$D$です。 Hard K-means法では$\\boldsymbol{y}_ n $を任意のクラスター$\\boldsymbol{Z} = (Z_1,\\ldots,Z_N )$, $Z_n ∈ \\left(1,\\ldots,K\\right)$に割り当て、各クラスター平均$\\boldsymbol{\\mu}_{1},\\ldots,\\boldsymbol{\\mu} _K$、$\\boldsymbol{\\mu} _k = ( \\mu_{1k}, \\ldots, \\mu_{Dk})$を計算し、各標本との距離の合計$\\sum_{n=1}^{N}\\sum_{d=1}^{D}\\left(y_{dn} - \\mu_{dZ_{[n]}}\\right)^2$が最小になるような割り当て方法を模索します。結果は一意に定まります。 Soft K-means法 一方、Soft K-means法は$\\boldsymbol{y}_n$が各クラスターに含まれる確率が結果として得られます。またユークリッド距離と多変量正規分布の関係から、モデルは多変量正規分布で表現されます。 各標本の割り当て先$Z_n$が以下のカテゴリカル分布に従うとします。 $$\rZ_n \\sim \\mathrm{Categorical}\\left(\\boldsymbol{\\theta}\\right) \\tag{1}\r$$\r$$\r\\boldsymbol{\\theta} = \\left(\\theta_1, \\ldots, \\theta_K\\right), ~~ \\sum_{k=1}^{K}\\theta_k = 1 \\tag{2}\r$$\r $\\boldsymbol{\\theta}$は各クラスターに含まれる標本の全体に占める割合とみなせます。 次に、1標本$\\boldsymbol{y}_n$は、$Z_n$に割り当てられる場合、次の多変量正規分布に従うものとします。 $$\r\\boldsymbol{y}_n \\sim \\mathrm{MultiNormal}\\left(\\boldsymbol{\\mu}_{Z_n}, \\Sigma\\right) \\tag{3}\r$$\r ここで各変数は互いに独立に生成されるものとすると、 $$ \\Sigma = \\mathrm{diag[\\sigma_1, \\ldots, \\sigma_D]} \\tag{4} $$ となり、このとき$y_{1n},\\ldots,y_{Dn}$がそれぞれ独立に平均$\\mu_{Z_n}$、標準偏差$\\sigma_d$の正規分布に従うことになります。 $\\boldsymbol{y}_n$がクラスター$k$に分類されるとき$(Z_n = k)$の対数尤度は、 $$\rp_{(Z_n = k)} = \\theta_k\\mathrm{MultiNormal}(\\boldsymbol{y}_n | \\boldsymbol{\\mu}_{k}, \\Sigma) \\propto \\theta_k \\cfrac{1}{\\sqrt{\\det{\\Sigma}}}\\exp\\left(-\\cfrac{1}{2}(\\boldsymbol{y}_n - \\boldsymbol{\\mu}_k)^T\\Sigma^{-1}(\\boldsymbol{y}_n - \\boldsymbol{\\mu}_k)\\right) = \\theta_k\\cfrac{1}{\\prod_{d=1}^{D}\\sigma_d}\\exp\\left(\\sum_{d=1}^{D}\\cfrac{1}{2\\sigma_d^2}(y_{dn} - \\mu_{dk})^2\\right) \\tag{5}\r$$\r となります。 $(5)$式にはクラスター平均と標本のユークリッド距離が含まれています。結局Soft K-means法も標本とクラスター中心の距離で結果が決まってくるのですね…$\\sigma_d$もおそらく変数間の重みづけ程度の役割なんでしょう。 理論は簡潔にこのくらいで… 実践 サンプルデータの準備 今日は経済産業省から平成26年商業統計500mメッシュデータをダウンロードして利用します。データを集計し、事業所数あたり小売業の総売上と従業員あたり小売業の総売上についての東京都内20km四方1km単位メッシュデータを作成します。中で適宜てきとうに欠損値の置き換えや外れ値の置き換えをしています。 # 読み込みと集計 ----------------------------------------------------------------- library(tidyverse) d \u0026lt;- read.csv(\u0026#34;data(big)/H26_03_500m都道府県.csv\u0026#34;, header=F) # 東京都内の20km×20kmをfilter d %\u0026gt;% as.data.frame() %\u0026gt;% mutate(mesh2 = paste(!!!rlang::syms(c(\u0026#34;V5\u0026#34;, \u0026#34;V6\u0026#34;)), sep=\u0026#34;\u0026#34;)) %\u0026gt;% # 2次メッシュコードを作成 filter(mesh2 == 533955 | mesh2 == 533956 | mesh2 == 533945 | mesh2 == 533946 ) %\u0026gt;% # 2次メッシュコードでフィルター select(mesh2, loc = V7, Office = V22, Employees = V23, Sales = V24) %\u0026gt;% # 必要な列のみ抽出 mutate(rowID = as.numeric(case_when(str_sub(loc,end=-2) == \u0026#34;\u0026#34; ~ \u0026#34;0\u0026#34;,TRUE ~ str_sub(loc,end=-2)))) %\u0026gt;% # 2次メッシュ内でのの行番号を作成 mutate(colID = as.numeric(str_sub(loc,start=-1))) %\u0026gt;% # 2次メッシュ内での列番号を作成 mutate(rowID = if_else(mesh2 == 533955 | mesh2 == 533956, rowID + 10, rowID)) %\u0026gt;% # 全体における行番号を作成 mutate(colID = if_else(mesh2 ==533956 | mesh2 == 533946, colID + 10, colID)) %\u0026gt;% # 全体における列番号を作成 na_if(\u0026#34;X\u0026#34;) %\u0026gt;% mutate_if(is.character, as.numeric) %\u0026gt;% # 欠損値XをNAに置き換える+全部double型に変換 group_by(mesh2, loc) %\u0026gt;% mutate_at(vars(Office, Employees, Sales), list( ~replace_na(.,mean(.,na.rm=TRUE)))) %\u0026gt;% # 3次メッシュでグループ化・NAをグループごとの平均値で置換 ungroup() %\u0026gt;% select(rowID, colID, Sales, Employees, Office ) %\u0026gt;% # 必要な列だけ取り出す group_by(rowID, colID,) %\u0026gt;% summarise_all(funs(sum(.))) %\u0026gt;% # 3次メッシュで和をとる ungroup() %\u0026gt;% mutate(SE = Sales / Employees, SO = Sales / Office) %\u0026gt;% # Sales/EmployeesとSales/Officeを計算 mutate_at(vars(SE, SO), ~replace_na(.,mean(.,na.rm=TRUE))) %\u0026gt;% arrange(desc(SE)) -\u0026gt; d d[1,6] \u0026lt;- d[2,6] # 外れ値を置き換え ridyverseでのうまいやり方がわからぬ d %\u0026gt;% arrange(desc(SO)) -\u0026gt; d d[1:3,7] \u0026lt;- d[4,7] # さらに外れ値を置き換え d %\u0026gt;% select(rowID, colID, SE, SO) -\u0026gt; d # 描画 ---------------------------------------------------------------------- p \u0026lt;- ggplot(data=d, aes(x=colID, y=rowID, z=SO, fill=SO)) p \u0026lt;- p + theme_bw(base_size=9) + theme(legend.position = \u0026#34;none\u0026#34;) p \u0026lt;- p + theme(panel.background = element_blank()) + theme(legend.title = element_blank()) + theme(panel.grid = element_blank()) p \u0026lt;- p + geom_tile() p \u0026lt;- p + scale_fill_gradient2(low=\u0026#34;white\u0026#34;,mid=\u0026#34;#A6CEE3\u0026#34;, high=\u0026#34;#1F78B4\u0026#34;) p \u0026lt;- p + labs(title=\u0026#34;Sales/Office\u0026#34;) p \u0026lt;- p + scale_x_continuous(breaks=seq(0,19)) p \u0026lt;- p + scale_y_continuous(breaks=seq(0,19)) p \u0026lt;- p + xlab(\u0026#34;\u0026#34;) + ylab(\u0026#34;\u0026#34;) p \u0026lt;- p + geom_text(aes(label=round(SO,2)), col=\u0026#34;grey8\u0026#34;,size=2.3) p2 \u0026lt;- ggplot(data=d, aes(x=colID, y=rowID, z=SE, fill=SE)) p2 \u0026lt;- p2 + theme_bw(base_size=9) + theme(legend.position = \u0026#34;none\u0026#34;) p2 \u0026lt;- p2 + theme(panel.background = element_blank()) + theme(legend.title = element_blank()) + theme(panel.grid = element_blank()) p2 \u0026lt;- p2 + geom_tile() p2 \u0026lt;- p2 + scale_fill_gradient2(low=\u0026#34;white\u0026#34;,mid=\u0026#34;#A6CEE3\u0026#34;, high=\u0026#34;#1F78B4\u0026#34;) p2 \u0026lt;- p2 + labs(title=\u0026#34;Sales/Office\u0026#34;) p2 \u0026lt;- p2 + scale_x_continuous(breaks=seq(0,19)) p2 \u0026lt;- p2 + scale_y_continuous(breaks=seq(0,19)) p2 \u0026lt;- p2 + xlab(\u0026#34;\u0026#34;) + ylab(\u0026#34;\u0026#34;) p2 \u0026lt;- p2 + geom_text(aes(label=round(SE,2)), col=\u0026#34;grey8\u0026#34;,size=2.3) library(gridExtra) p_extra \u0026lt;- gridExtra::grid.arrange(p,p2, ncol=2) このデータに対してソフトクラスタリングを実行し、事業所ごと・従業員毎の生産性が高い（High Efficiency）地域と低い（Low Efficiency）にメッシュを二分することを目的にします。 実装 実装は基本的に理論編での数式に倣いますが、標準偏差$\\sigma_1,\\ldots,\\sigma_D$はすべて1とします（個人的に$\\sigma_k$を軽視しているのと、$\\sigma_k$をパラメータにすると収束しなかったため）。 Stanコードは以下です。 //model.stan data{ int D; //入力数 int N; //サンプル数 int K; //クラス数 vector[D] Z[N]; //外で標準化済み } parameters{ simplex[K] theta; //各クラスターへ割り振られる確率 ordered[K] Z_mu[D]; //クラスター平均 } transformed parameters{ vector\u0026lt;upper=0\u0026gt;[K] soft_z[N]; //クラスター毎の対数尤度 matrix[K,N] dotself = rep_matrix(0,K,N); for(k in 1:K){ for(n in 1:N){ for(d in 1:D){ dotself[k,n] += (Z_mu[d,k] - Z[n,d])^2; } } } //クラスター毎の対数尤度の計算 for(n in 1:N){ for(k in 1:K){ soft_z[n,k] = log(theta[k]) - 0.5 * dotself[k,n]; } } } model{ //likelihood for(n in 1:N){ target += log_sum_exp(soft_z[n]); } } generated quantities{ vector[K] p[N]; for(n in 1:N){ p[n] = softmax(soft_z[n]); } } 一つ目のポイントはordered Z_mu[D]でしょうか。ラベルスイッチングと呼ばれる、クラスターを識別できない問題を解消しています。これがないと全く収束しません。 二つ目のポイントはvector\u0026lt;upper=0\u0026gt;[K] soft_z[N]とtarget += log_sum_exp(soft_z[n])ですね。$N$個の$K$ベクトルsoft_zの要素には$(5)$式の対数尤度が格納されています。それを関数log_sum_exp()を使って混合モデルとして認識させtargetに足していきます。詳しくはアヒル本203ページを参照のこと。 三つ目のポイントはp[n] = softmax(soft_z[n])です。ソフトマックス関数について思い出して下さい。 $$\r\\mathrm{softmax}(\\boldsymbol{x}_ n) = \\left(\\cfrac{\\exp(x_{1n})}{\\sum_{k=1}^K \\exp(x_{kn})}\\cdots\\cfrac{\\exp(x_{Kn})}{\\sum_{k=1}^K \\exp(x_{kn})} \\right) \\tag{6}\r$$\r 対数尤度が格納されたsoft_zを$\\exp()$で再び尤度に戻しています。尤度比がそのまま各クラスターに分類される確率と解釈できる訳です。 結果 以下でMCMCを走らせ、$\\hat{R}$で収束を確認します。 library(rstan) D \u0026lt;- 2 N \u0026lt;- nrow(d) loc \u0026lt;- d[,c(1,2)] Z \u0026lt;- scale(d[,c(3,4)]) K \u0026lt;- 2 rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores()) data \u0026lt;- list(D=D,N=N,Z=Z, K=K) stanmodel \u0026lt;- stan_model(\u0026#34;model.stan\u0026#34;) fit \u0026lt;- sampling(stanmodel, pars = c(\u0026#34;Z_mu\u0026#34;,\u0026#34;theta\u0026#34;,\u0026#34;p\u0026#34;), data=data, iter=1300, warmup=300, seed=123, chain=4) fit ## Inference for Stan model: model. ## 4 chains, each with iter=1300; warmup=300; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## Z_mu[1,1] -0.18 0.00 0.05 -0.28 -0.22 -0.18 -0.15 -0.08 4664 1 ## Z_mu[1,2] 2.98 0.00 0.27 2.47 2.79 2.98 3.16 3.54 3989 1 ## Z_mu[2,1] -0.19 0.00 0.06 -0.30 -0.23 -0.19 -0.15 -0.09 4715 1 ## Z_mu[2,2] 3.19 0.00 0.27 2.68 3.01 3.18 3.36 3.73 4215 1 ## theta[1] 0.94 0.00 0.01 0.91 0.93 0.94 0.95 0.97 3832 1 ## theta[2] 0.06 0.00 0.01 0.03 0.05 0.06 0.07 0.09 3832 1 ## p[1,1] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 3445 1 ## p[1,2] 1.00 0.00 0.00 1.00 1.00 1.00 1.00 1.00 3445 1 ## p[2,2] 1.00 0.00 0.00 1.00 1.00 1.00 1.00 1.00 3633 1 ## p[2,1] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 3633 1 ～以下省略～ 結果はざっとこんな感じです。 # 分類結果を描画するRスクリプト --------------------------------------------------------- fit %\u0026gt;% rstan::extract() %\u0026gt;% as.data.frame() %\u0026gt;% select(starts_with(\u0026#34;p\u0026#34;)) %\u0026gt;% select(ends_with(\u0026#34;2\u0026#34;)) %\u0026gt;% # 2で終わるpがhighである確率に対応。MCMCサンプルから抽出 pivot_longer(everything(), names_to = \u0026#34;key\u0026#34;, values_to = \u0026#34;val\u0026#34;) %\u0026gt;% # 縦持ち型に変換 mutate(loc=str_sub(str_sub(key, start=3),end=-3), key=NULL) %\u0026gt;% # keyから位置のID(loc)を抽出 group_by(loc) %\u0026gt;% summarise(median=median(val), lower=quantile(val, 0.25), upper=quantile(val,0.75)) %\u0026gt;% mutate(Class = as.factor(round(median))) %\u0026gt;% merge(cbind(loc=seq(1,nrow(d)),d), by=\u0026#34;loc\u0026#34;) %\u0026gt;% select(-loc) -\u0026gt; res_data library(ggplot2) color1 \u0026lt;- colorRampPalette(c(\u0026#34;#A6CEE3\u0026#34;,\u0026#34;#1F78B4\u0026#34;)) p \u0026lt;- ggplot() p \u0026lt;- p + theme_bw(base_size=11) p \u0026lt;- p + theme(panel.background = element_blank()) + theme(legend.title = element_blank()) + theme(panel.grid = element_blank())+ theme(legend.position = \u0026#34;bottom\u0026#34;) p \u0026lt;- p + scale_y_continuous(breaks=seq(0,19)) p \u0026lt;- p + geom_tile(data=data.frame(res_data), aes(x=colID, y=rowID, fill=Class))+ scale_fill_hue(palette=color1, breaks=c(\u0026#34;0\u0026#34;, \u0026#34;1\u0026#34;),labels=c(\u0026#34;Low Efficiency\u0026#34;, \u0026#34;High Efficiency\u0026#34;)) p \u0026lt;- p + geom_text(data=data.frame(res_data), aes(x=colID, y=rowID, label=sprintf(\u0026#34;%0.2f\u0026#34;, median)), colour = \u0026#34;grey8\u0026#34;) p \u0026lt;- p + xlab(\u0026#34;\u0026#34;) + ylab(\u0026#34;\u0026#34;) p \u0026lt;- p + scale_x_continuous(breaks=seq(0,19)) p \u0026lt;- p + labs(title=\u0026#34;Estimated Status\u0026#34;) # パラメータや生成量の事後分布を描画 ------------------------------------------------------- library(bayesplot) plot_title \u0026lt;- ggtitle(\u0026#34;Posterior distributions\u0026#34;, \u0026#34;with medians and 80% intervals\u0026#34;) posterior \u0026lt;- as.matrix(fit) colnames(posterior)[which(colnames(posterior)==\u0026#34;Z_mu[1,1]\u0026#34;)] \u0026lt;- \u0026#34;SO_Class1_normalize\u0026#34; # Sales/Office colnames(posterior)[which(colnames(posterior)==\u0026#34;Z_mu[1,2]\u0026#34;)] \u0026lt;- \u0026#34;SO_Class2_normalize\u0026#34; colnames(posterior)[which(colnames(posterior)==\u0026#34;Z_mu[2,1]\u0026#34;)] \u0026lt;- \u0026#34;SE_Class1_normalize\u0026#34; # Sales/Employees colnames(posterior)[which(colnames(posterior)==\u0026#34;Z_mu[2,2]\u0026#34;)] \u0026lt;- \u0026#34;SE_Class2_normalize\u0026#34; # 標準化したSales/OfficeとSales/Employeesをもとに戻す posterior %\u0026gt;% as.data.frame() %\u0026gt;% mutate(SO_Class1 = SO_Class1_normalize * attr(Z,\u0026#39;scaled:scale\u0026#39;)[1] + attr(Z, \u0026#39;scaled:center\u0026#39;)[1], SO_Class2 = SO_Class2_normalize * attr(Z, \u0026#39;scaled:center\u0026#39;)[1] + attr(Z, \u0026#39;scaled:center\u0026#39;)[1], SE_Class1 = SE_Class1_normalize * attr(Z, \u0026#39;scaled:center\u0026#39;)[2] + attr(Z, \u0026#39;scaled:center\u0026#39;)[2], SE_Class2 = SE_Class2_normalize * attr(Z, \u0026#39;scaled:center\u0026#39;)[2] + attr(Z, \u0026#39;scaled:center\u0026#39;)[2], SO_Class1_normalize = NULL, SO_Class2_normalize = NULL, SE_Class1_normalize = NULL, SE_Class2_normalize = NULL, sigma=NULL) -\u0026gt; posterior plot1 \u0026lt;- mcmc_areas(posterior, regex_pars = c(\u0026#34;sigma\u0026#34;, \u0026#34;theta\u0026#34;), prob = 0.8) + plot_title plot2 \u0026lt;- mcmc_areas(posterior, pars = c(\u0026#34;SO_Class1\u0026#34;,\u0026#34;SO_Class2\u0026#34;), prob=0.8) + ggtitle(\u0026#34;Posterior distributions(Sales/Office)\u0026#34;, \u0026#34;with medians and 80% intervals\u0026#34;) plot3 \u0026lt;- mcmc_areas(posterior, pars = c(\u0026#34;SE_Class1\u0026#34;,\u0026#34;SE_Class2\u0026#34;), prob=0.8) + ggtitle(\u0026#34;Posterior distributions(Sales/Employees)\u0026#34;, \u0026#34;with medians and 80% intervals\u0026#34;) p_extra \u0026lt;- gridExtra::grid.arrange(plot1,plot2,plot3, ncol=1) # 推定した混合正規分布の確率密度を描画 ------------------------------------------------------ posterior \u0026lt;- as.data.frame(fit) colnames(posterior)[which(colnames(posterior)==\u0026#34;Z_mu[1,1]\u0026#34;)] \u0026lt;- \u0026#34;SO_Class1_normalize\u0026#34; # Sales/Office colnames(posterior)[which(colnames(posterior)==\u0026#34;Z_mu[1,2]\u0026#34;)] \u0026lt;- \u0026#34;SO_Class2_normalize\u0026#34; colnames(posterior)[which(colnames(posterior)==\u0026#34;Z_mu[2,1]\u0026#34;)] \u0026lt;- \u0026#34;SE_Class1_normalize\u0026#34; # Sales/Employees colnames(posterior)[which(colnames(posterior)==\u0026#34;Z_mu[2,2]\u0026#34;)] \u0026lt;- \u0026#34;SE_Class2_normalize\u0026#34; posterior %\u0026gt;% select(-starts_with(c(\u0026#34;p\u0026#34;,\u0026#34;lp__\u0026#34;))) %\u0026gt;% mutate(SO_Class1 = SO_Class1_normalize * attr(Z,\u0026#39;scaled:scale\u0026#39;)[1] + attr(Z, \u0026#39;scaled:center\u0026#39;)[1], SO_Class2 = SO_Class2_normalize * attr(Z, \u0026#39;scaled:center\u0026#39;)[1] + attr(Z, \u0026#39;scaled:center\u0026#39;)[1], SE_Class1 = SE_Class1_normalize * attr(Z, \u0026#39;scaled:center\u0026#39;)[2] + attr(Z, \u0026#39;scaled:center\u0026#39;)[2], SE_Class2 = SE_Class2_normalize * attr(Z, \u0026#39;scaled:center\u0026#39;)[2] + attr(Z, \u0026#39;scaled:center\u0026#39;)[2], sigma_SO = 1 * attr(Z,\u0026#39;scaled:scale\u0026#39;)[1], sigma_SE = 1 * attr(Z,\u0026#39;scaled:scale\u0026#39;)[2]) %\u0026gt;% select(SO_Class1, SO_Class2, SE_Class1, SE_Class2, sigma_SO, sigma_SE, starts_with(\u0026#34;theta\u0026#34;) )-\u0026gt; res_data # 混合正規分布の確率密度関数を作成。中央値を用いる bw1 \u0026lt;- diff(range(d[,3]))/30 bw2 \u0026lt;- diff(range(d[,4]))/30 dmixnorm1 \u0026lt;- function(x) bw1 * nrow(d) *median(res_data$\u0026#39;theta[1]\u0026#39;) * dnorm(x,mean=median(res_data$SO_Class1), sd=median(res_data$sigma_SO)) + bw1 * nrow(d) * median(res_data$\u0026#39;theta[2]\u0026#39;) * dnorm(x,mean=median(res_data$SO_Class2), sd=median(res_data$sigma_SO)) dmixnorm2 \u0026lt;- function(x) bw2 * nrow(d) * median(res_data$\u0026#39;theta[1]\u0026#39;) * dnorm(x,mean=median(res_data$SE_Class1), sd=median(res_data$sigma_SE)) + bw2 * nrow(d) * median(res_data$\u0026#39;theta[2]\u0026#39;) * dnorm(x,mean=median(res_data$SE_Class2), sd=median(res_data$sigma_SE)) dmixnorm1_samples \u0026lt;- function(x, sample) bw1 * nrow(d) *res_data$\u0026#39;theta[1]\u0026#39;[sample] * dnorm(x,mean=res_data$SO_Class1[sample], sd=res_data$sigma_SO[sample]) + bw1 * nrow(d) * res_data$\u0026#39;theta[2]\u0026#39;[sample] * dnorm(x,mean=res_data$SO_Class2[sample], sd=res_data$sigma_SO[sample]) dmixnorm2_samples \u0026lt;- function(x, sample) bw2 * nrow(d) * res_data$\u0026#39;theta[1]\u0026#39;[sample] * dnorm(x,mean=res_data$SE_Class1[sample], sd=res_data$sigma_SE[sample]) + bw2 * nrow(d) * res_data$\u0026#39;theta[2]\u0026#39;[sample] * dnorm(x,mean=res_data$SE_Class2[sample], sd=res_data$sigma_SE[sample]) # 雲を纏わせる samples \u0026lt;- sample(seq(1,4000), size=80, replace=FALSE) q1 \u0026lt;- ggplot(data=d[,3],aes(x=SE)) q1 \u0026lt;- q1 + theme_bw(base_size=11) q1 \u0026lt;- q1 + geom_histogram(binwidth = bw1, fill=\u0026#34;#A6CEE3\u0026#34;, color = \u0026#34;grey20\u0026#34;) for(n in 1:length(samples)){ q1 \u0026lt;- q1 + stat_function(fun=dmixnorm1_samples, args=list(sample=samples[n]), color = \u0026#34;#D53E4F\u0026#34;, alpha=0.2, size = 0.5, xlim=c(0, max(d[,3]))) } q1 \u0026lt;- q1 + stat_function(fun=dmixnorm1, color = \u0026#34;#9E0142\u0026#34;, size = 1, xlim=c(0, max(d[,3]))) q1 \u0026lt;- q1 + xlab(\u0026#34;Sales/Employees\u0026#34;) + ylab(\u0026#34;\u0026#34;) q1 \u0026lt;- q1 + coord_cartesian(ylim=c(0,150)) q2 \u0026lt;- ggplot(data=data.frame(x=d[,4]),aes(x=SO)) q2 \u0026lt;- q2 + theme_bw(base_size=11) q2 \u0026lt;- q2 + geom_histogram(binwidth = bw2, fill=\u0026#34;#A6CEE3\u0026#34;, color = \u0026#34;grey20\u0026#34;) +labs(\u0026#34;aa\u0026#34;) for(n in 1:length(samples)){ q2 \u0026lt;- q2 + stat_function(fun=dmixnorm2_samples, args=list(sample=samples[n]), color = \u0026#34;#D53E4F\u0026#34;, alpha=0.2, size = 0.5, xlim = c(0,max(d[,4]))) } q2 \u0026lt;- q2 + stat_function(fun=dmixnorm2, color = \u0026#34;#9E0142\u0026#34;, size = 1, xlim = c(0,max(d[,4]))) q2 \u0026lt;- q2 + xlab(\u0026#34;Sales/Office\u0026#34;) + ylab(\u0026#34;\u0026#34;) q2 \u0026lt;- q2 + coord_cartesian(ylim=c(0,150)) q \u0026lt;- gridExtra::grid.arrange(q2,q1,ncol = 1) 無難な結果が得られているのではないかなあ、という感じです。はじめのタイル図がクラスタリングの推定結果ですが、タイルごとに「High Efficiency」である確率の事後分布の中央値を示しています。このように各クラスターへ分類される確率で結果が得られるのがSoft K-means法の特徴です。 ガウス過程をあてはめてみる 問題はここからです。ただクラスタリングを試すだけなら空間データを扱う必要はありません。なぜ今回空間データを扱ったかというと、普遍的なモデルにガウス過程を組み込む練習がしたかったからです。 ガウス過程は「近い距離関係にある変数同士ほど近い値をとる」というような性質を変数間に与えることが可能です。今回は文字通り地理的に近い距離関係にある地域ほど小売業の「Efficiency」は近い値をとるだろう、という関係をガウス過程を使って上記モデルに組み込んでみたいと思います1。 追加する計算は以下のとおりです。 $$\r\\mathrm{logit}(\\boldsymbol{p}_{(Z_n = k)}) \\sim \\mathrm{MultiNormal}(\\boldsymbol{0}_n, K) \\tag{7}\r$$\r$$\r\\boldsymbol{p}_{(Z_n = k)} = (p_{Z_1=k},\\ldots,p_{Z_n=k})^T, ~~~ \\boldsymbol{0}_n = (0,\\ldots,0)^T∈\\mathbb{R}^n \\tag{8}\r$$\r$$\rk_{nn'} = \\phi_{\\boldsymbol{loc}_n}^T\\phi_{\\boldsymbol{loc}_{n'}} \\tag{9}\r$$\r $\\mathrm{logit}(\\boldsymbol{p}_ {(Z_ n = k)})$の各要素の平均値を0としているので、各クラスが「High Efficiency」である確率は情報に乏しい付近では0.5に収束するようなガウス過程です。 ここで$k_{nn\u0026rsquo;}$はグラム行列$K$の$(n,n\u0026rsquo;)$成分です。$\\boldsymbol{loc}_n$には$n$番目の変数の座標$(x,y)$が格納されています。$\\phi$はカーネル関数です。今回はガウスカーネルを使ってみます。 上記モデルの実装は以下です。以前の記事でガウス過程のいパーパラメータ推定は懲りたので、今回はこちらからハイパーパラメータを指定していきます。 //model2.stan data{ int D; //入力数 int N; //サンプル数 int K; //クラス数 vector[2] loc[N]; //入力位置 vector[D] Z[N]; real alpha; real rho; real delta_sq; } transformed data{ vector[N] Mu; for(i in 1:N) Mu[i] = 0; } parameters{ simplex[K] theta; //各クラスターへ割り振られる確率 ordered[K] Z_mu[D]; //クラスター平均 } transformed parameters{ vector\u0026lt;upper=0\u0026gt;[K] soft_z[N]; //クラスター毎の対数尤度 vector[K] p[N]; matrix[N,K] p_logit; //matrix型なら列・行どちらの取り出しでもベクトル型になる matrix[K,N] dotself = rep_matrix(0,K,N); matrix[N,N] cov; for(k in 1:K){ for(n in 1:N){ for(d in 1:D){ dotself[k,n] += (Z_mu[d,k] - Z[n,d])^2; } } } //クラスター毎の対数尤度の計算 for(n in 1:N){ for(k in 1:K){ soft_z[n,k] = log(theta[k]) - 0.5 * dotself[k,n]; } } for(n in 1:N){ p[n] = softmax(soft_z[n]); p_logit[n,] = logit(p[n])\u0026#39;; } // カーネル行列の作成 cov = cov_exp_quad(loc, alpha, rho); for(n in 1:N){ cov[n,n] = cov[n,n] + delta_sq; } } model{ //likelihood for(n in 1:N){ target += log_sum_exp(soft_z[n]); } //GP for(k in 1:(K-1)){ p_logit[,k] ~ multi_normal(Mu, cov); } } 以下で上記モデルを走らせ、結果を確認します。ハイパーパラメータは$\\alpha=30$、$\\rho=1.15$で。 data \u0026lt;- list(D=D,N=N,Z=Z,loc=loc,alpha=30, rho=1.15, delta_sq=0.01, K=K) stanmodel2 \u0026lt;- stan_model(\u0026#34;model2.stan\u0026#34;) fit2 \u0026lt;-sampling(stanmodel2, pars = c(\u0026#34;Z_mu\u0026#34;,\u0026#34;theta\u0026#34;,\u0026#34;p\u0026#34;), data=data, iter=1300, warmup=300, seed=123) fit2 ## Inference for Stan model: model2. ## 4 chains, each with iter=1300; warmup=300; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## Z_mu[1,1] -0.11 0.00 0.06 -0.24 -0.15 -0.11 -0.07 0.01 1781 1.00 ## Z_mu[1,2] 0.48 0.01 0.17 0.10 0.38 0.49 0.60 0.80 978 1.00 ## Z_mu[2,2] 0.46 0.01 0.17 0.09 0.36 0.47 0.58 0.77 783 1.00 ## Z_mu[2,1] -0.11 0.00 0.06 -0.23 -0.15 -0.11 -0.07 0.01 2398 1.00 ## theta[1] 0.80 0.00 0.09 0.55 0.77 0.82 0.85 0.90 553 1.01 ## theta[2] 0.20 0.00 0.09 0.10 0.15 0.18 0.23 0.45 553 1.01 ## p[1,1] 0.03 0.00 0.06 0.00 0.01 0.01 0.03 0.18 593 1.00 ## p[1,2] 0.97 0.00 0.06 0.82 0.97 0.99 0.99 1.00 593 1.00 ## p[2,1] 0.04 0.00 0.06 0.00 0.01 0.02 0.04 0.20 599 1.00 ## p[2,2] 0.96 0.00 0.06 0.80 0.96 0.98 0.99 1.00 599 1.00 ん、確かに確率が空間的に滑らかにつながったように見えなくもないが、依然として隣り合ったセル間の差が大きいところもあるな… $\\rho$を微妙に大きく1.2にして、いびつさをもう少し和らげたガウス過程にしてみよう。 data \u0026lt;- list(D=D,N=N,Z=Z,loc=loc,alpha=30, rho=1.2, delta_sq=0.01, K=K) fit2 \u0026lt;-sampling(stanmodel2, pars = c(\u0026#34;Z_mu\u0026#34;,\u0026#34;theta\u0026#34;,\u0026#34;p\u0026#34;), data=data, iter=1300, warmup=300, seed=123) (以降、省略) ハイパーパラメータの値を少しだけ変えただけなのに、今度は手のひらを返したかのように優柔不断な分類結果が得られてしまった。どのセルも確率がほぼ0.5ではないか。 もっと、クラスター平均がある程度離れたまま、空間的に滑らかで急な変化の少ない確率群が得られるかと予想していたのだが… はじめは実装に問題があるのかと思ったのですが、組み立てたモデルの動作を想像すると原因がすぐにわかりました。 $\\rho$をある程度大きくしてなだらかな曲線を描くガウス過程にすると、まず「High Efficiency」だろうと言えるセルのとなりの「Low Efficiecy」っぽいセルまでもが、「High Efficiency」であるという確率が高くなってしまい、その結果二つのクラスターの平均値が近づいて行ってしまうようです。 組み立てたモデルがうまくいかないとき、つい実装が悪いのではと疑ってしまいますが、そもそも組み立てたモデルが自分の意図したとおりに動くものなのか、ということを再確認することも大切なんだなと思いました。 本当は空間的自己相関を確認してからこういうモデルを検討すべきなのでしょうが、空間的自己相関の知識がまだ中途半端なのでここでは割愛します \u0026#x21a9;\u0026#xfe0e;"
  },
  {
    url: "https://sucre-stat.com/tags/%E3%82%AC%E3%82%A6%E3%82%B9%E9%81%8E%E7%A8%8B/",
    title: "ガウス過程",
    date: "2020-12-24T00:00:00Z",
    body: "ガウス過程"
  },
  {
    url: "https://sucre-stat.com/tags/%E5%88%86%E9%A1%9E/",
    title: "分類",
    date: "2020-12-24T00:00:00Z",
    body: "分類"
  },
  {
    url: "https://sucre-stat.com/2020/12/corresp-and-bayes/",
    title: "Stanで対応分析の付置にベイズ信頼区間をもたせる",
    date: "2020-12-11T00:00:00Z",
    body: "Stanで対応分析の付置にベイズ信頼区間をもたせる はじめに この記事はStan Advent calendar12月12日の記事です。 普段よりもこのページを見る人が多いと思います、私のことはこちらで紹介しています。匿名主義なので何の情報もありませんが… ここでは多変量解析の一つである対応分析を題材にします。 対応分析は多変量のカテゴリカルデータに用いられる分析で、クロス集計表の結果を視覚的に表現するために使われる統計的手法です。 実は対応分析は私の修士研究で使用した解析手法なのですが、対応分析の付置はデータ数に依存しないことから、座標を得るだけでその信頼性が確認できないところに当時問題を感じていました。 大学を卒業してからベイズ統計に関心を持ち、ある程度勉強したところで当時のことを思い出し、rstanを使ってこの問題に取り組もうと思ったのが本記事の執筆動機です。 本記事の構成は以下のとおりです。 はじめに 対応分析について 対応分析の同時付置図は信頼できるのか 付置は標本数に依らない？ 分割表の一様性の検定 同時付置図と一様性の帰無仮説の関係 モデル作成 分割表のモデリング MCMCサンプルより生成量を得る値 主成分分析の対象$X$ 固有ベクトル$\\boldsymbol{l}_k$ モデルの実装 結果の確認 おまけ～私が相撲に参加すると？～ まとめ 参考にした論文は前回と同様のこちらです。 この論文はもうだいぶ古いですが、既に対応分析の付置の信頼性の問題に着目しています。ただし解析的な正規分布への近似をもとに信頼区間を求めているようなので、本記事ではこの論文とは別のベイズ的なアプローチをとることにします。 ベイズ的なアプローチの部分は先行文献が見当たらなかったのでオリジナルです。そんな変なことはしていないと思うのですが…いや、どうなんだろう。 対応分析について 対応分析とはクロス集計表など、カテゴリカルな行と列のデータを視覚的に表現することで、項目間の関係を把握しようとする手法です。コレスポンデンス分析とも呼ばれ、数理的には林先生の数量化理論第Ⅲ類と同等のものとされています。 対応分析の数理的な内容については、前回の記事で説明しているのでそちらを覗いてください。 対応分析の同時付置図は信頼できるのか ここでは対応分析の同時付置図の信頼性について考えてみます。 付置は標本数に依らない？ 前回の記事を振り返り、対応分析について復習します。 $i$行$j$列が$f_{ij}$（$i=1 … M$、$j = 1 … N$）である$M$行$N$列の分割表について考えたとき、対応分析の同時付置図作成までの過程は以下のようになっていました。 ここで各行・列および全項目の観測数の総和を前回と同様以下のように表記します。 $$\rf_{i.} = ∑_{j=1}^{N}f_{ij} ~,~~ f_{.j} = ∑_{i=1}^{M}f_{ij} ~,~~ Sum = ∑_{j=1}^{N} ∑_{i=1}^{M} f_{ij}\r$$\r 確率行列 $$\r\\boldsymbol{P} _ I = \\mathrm{diag} \\left[ p_{1.},\\ldots, p_{M.} \\right] ~~~ p _{i.} = f _{i.}/Sum\r$$\r$$\r\\boldsymbol{P} _ J = \\mathrm{diag} \\left[ p_{.1}, …, p_{.N} \\right]~~~p_{.j} = f_{.j}/Sum\r$$\r$$\r\\boldsymbol{P} _ {IJ}=\\left(f_{ij}/N\\right)\r$$\r より$M$行$N$列の行列$\\boldsymbol{X}$ $$\r\\boldsymbol{X} = \\boldsymbol{P}_{I}^{-1} \\boldsymbol{P}_{IJ} \\boldsymbol{P}_{J}^{-1/2}\r$$\rを作成する。 $\\boldsymbol{X}$の主成分分析を計算し、最大固有値から順に$\\lambda_{1},\\lambda_{2}\\ldots,\\lambda_{N-1}$、およびこれらに対応する固有ベクトル$\\boldsymbol{l} _1,\\ldots,\\boldsymbol{l} _{K}$ ($K = \\rm{min}(\\textit{M},\\textit{N})-1$)を得る1。 第$k$主成分ベクトルによる項目$I$の数量化スコアを下記式より計算する。 $$\r\\boldsymbol{z} _k = \\boldsymbol{X} \\boldsymbol{l} _k = \\boldsymbol{P} _I^{-1} \\boldsymbol{P} _{IJ} \\boldsymbol{P} _{J}^{-1/2}\\boldsymbol{l} _k \\tag{1}\r$$\r 項目$J$の数量化スコアを、下記式に基づき項目$I$の数量化スコアから求める。 $$\r\\boldsymbol{z} _k^* = \\cfrac{1}{\\sqrt{λ_k}} \\boldsymbol{P}_J^{-1} \\boldsymbol{P}_{IJ}\\boldsymbol{z} _k \\tag{2}\r$$\r $\\boldsymbol{z}_k$、$\\boldsymbol{z}^{*}_k$をもとに行項目・列項目の同時付置図を作成する。 ここで、$(1)$$(2)$式を見ると、すべての数量化スコアが確率行列のみに依存しており、標本数$Sum$に影響されないことが確認できます。つまり、標本数が違う2つの分割表があったとして、それらの確率行列$P_{IJ}$が一致する場合、同時付置図は全く同じものになると… よって、同時付置図はそれのみでは付置がどの程度信頼できるかが確認できないようになっているのです。 分割表の一様性の検定 上記問題の解決というわけではないですが、分割表の一様性の検定というものがありまして、分割表の各行の確生起確率$(p_{i1},\\ldots,p_{iN})$が同じであるといえるかどうかを判定する検定があります。分割表の検定の結果下に述べる帰無仮説が棄却された場合、存在すると考えられる生起確率の差の傾向を対応分析で明瞭に把握できるだろう、というわけです2。 この検定の帰無仮説は \r$H_0$：すべての$1 \\leq j\rで3、検定統計量は $$\rT = ∑_{i=1}^{M}∑_{j=1}^{N}\\cfrac{\\left(f_{ij} - f_{i.}p_{.j}\\right)^2}{f_{i.}p_{.j}} \\tag{3}\r$$\r です。$T$が漸近的に自由度$(M-1)(N-1)$の$χ^2$分布に従うことを用いて検定を行います。 試しに前回の記事と同じ相撲データについて一様性の検定をしてみましょう。 # smo_dataの作成 ---------------------------------------------------------- smo_data \u0026lt;- matrix(data=c(15,15,0,0,1,0,1,19,9,7,12,1,3,3,4,22,0,11,2,0,4, 14,3,11,3,1,1,6,24,7,5,5,0,0,2,30,2,6,2,2,0,2, 11,13,5,6,2,1,4,25,8,10,7,5,3,1,13,31,3,3,0,2,3, 8,2,19,3,2,0,4,28,8,8,2,1,0,7,9,3,14,11,2,0,4, 5,3,12,11,4,0,7,7,1,18,0,1,0,11,12,6,1,12,7,2,2, 25,2,11,3,1,0,1,16,4,18,3,0,0,5,23,2,6,5,1,0,2, 7,17,2,16,3,0,1,2,8,1,11,1,0,2),byrow=TRUE, ncol=7) colnames(smo_data) \u0026lt;- c(\u0026#34;寄り\u0026#34;,\u0026#34;押し\u0026#34;,\u0026#34;投げ\u0026#34;,\u0026#34;引き\u0026#34;,\u0026#34;送り\u0026#34;,\u0026#34;突き\u0026#34;,\u0026#34;その他\u0026#34;) rownames(smo_data) \u0026lt;- c(\u0026#34;小錦\u0026#34;,\u0026#34;琴錦\u0026#34;,\u0026#34;貴闘力\u0026#34;,\u0026#34;霧島\u0026#34;,\u0026#34;栃ノ和歌\u0026#34;,\u0026#34;水戸錦\u0026#34;,\u0026#34;若ノ花\u0026#34;,\u0026#34;貴ノ花\u0026#34;,\u0026#34;武蔵丸\u0026#34;, \u0026#34;大翔山\u0026#34;,\u0026#34;安芸ノ島\u0026#34;,\u0026#34;三杉里\u0026#34;,\u0026#34;旭道山\u0026#34;,\u0026#34;舞の海\u0026#34;,\u0026#34;寺尾\u0026#34;,\u0026#34;琴の若\u0026#34;,\u0026#34;貴ノ浪\u0026#34;, \u0026#34;琴富士\u0026#34;,\u0026#34;隆三杉\u0026#34;,\u0026#34;春日富士\u0026#34;) # smo_dataの一様性検定 ---------------------------------------------------------- my_uniformity_test \u0026lt;- function(data){ data_teststat \u0026lt;- matrix(NA, nrow=nrow(data), ncol=ncol(data)) p_j \u0026lt;- rep(NA, length=n) for(j in 1:n){ p_j[j] \u0026lt;- sum(data[,j])/sum(data) } for(i in 1:m){ for(j in 1:n){ data_teststat[i,j] \u0026lt;- (data[i,j] - rowSums(data)[i]*p_j[j])^2 / (rowSums(data)[i]*p_j[j]) } } T_stat \u0026lt;- sum(data_teststat) cat(sprintf(\u0026#34;p-value:%.5f\u0026#34;,pchisq(T_stat, df=((m-1)*(n-1)), lower.tail = FALSE))) } my_uniformity_test(smo_data) ## p-value:0.00000 帰無仮説は有意水準0.1%以下で棄却されました。では、このデータの各度数を4分の1にしたデータではどうでしょうか4。 my_uniformity_test(smo_data/4) ## p-value:0.39973 p値は約0.4ですので、とても帰無仮説を棄却できません。 そんな訳なので、同じ付置図が得られても標本数によって信頼性に差があるため、付置図だけからは正しい解釈ができない可能性があるんです。 同時付置図と一様性の帰無仮説の関係 対応分析の同時付置図がどのようになっているときに、一様性の帰無仮説が棄却されやすいかを考えます。 生起確率が全体の平均に等しく$(p_{.1},\\ldots,p_{.n})$である個体$i$の第$k$数量化スコアは、 $$\r\\left(\\cfrac{p_{.1}}{p_{i.}\\sqrt{p_{.1}}},\\ldots,\\cfrac{p_{.N}}{p_{i.}\\sqrt{p_{.N}}}\\right)^T \\boldsymbol{l} _k = \\cfrac{1}{p_{i.}}\\left(\\sqrt{p_{.1}},\\ldots,\\sqrt{p_{.N}}\\right)^T \\boldsymbol{l} _k = 0 \\tag{4}\r$$\r なので5、同時付置図の原点が帰無仮説に対応する点になっています。 また、$(3)$式を展開すると、 $$\rT = ∑_{i=1}^{M}∑_{j=1}^{N} f_{i.}\\cfrac{\\left(\\cfrac{p_{ij}}{p_{i.}}-p_{.j}\\right)^2}{p_{.j}}\r= ∑_{i=1}^{M}f_{i.}∑_{j=1}^{N}\\cfrac{\\left(\\cfrac{p_{ij}}{p_{i.}}-p_{.j}\\right)^2}{p_{.j}} \\tag{5}\r$$\r となることから、帰無仮説の点（同時付置図の原点）から離れている行$i$で、行和$f_i$が大きいものがある場合に$T$が大きくなり、一様性の帰無仮説が棄却されやすい6ことが分かります。 以上を踏まえ、同時付置図にそれぞれのポイントの信頼度を表示することができれば、分割表の情報を余すことなく付置図に表現でき、視覚的な結果の解釈や項目の分類の手助けになるのでは、というのが本記事の狙いです。 モデル作成 分割表の生成過程にモデルを設定して、MCMCによってそのパラメータを推定し、同時付置図における各ポイントのベイズ信頼区間（またはベイズ予測区間）を求めることを考えます7。 分割表のモデリング 分割表の生成過程は、分割表の性質により以下の2パターンのいずれかを仮定することができます。 \r観測度数の総和が固定されており、全観測度数がひとつの多項分布に従うとする仮定\r\r\r\r各行の総和が固定されており、各行の観測度数が独立の多項分布に従うとする仮定\r\r\r対応分析にかける分割表の場合、後者の場合が多いかと思います。一様性の検定の際にも、後者の仮定を設定して、検定をしていました。 $$\r\\left(f_{i1},\\ldots,f_{iN}\\right) \\sim \\rm{Multinom} (\\mathcal{f}_{\\mathcal{i}.}\r, \\boldsymbol{\\theta}_\\mathcal{i} ) \\tag{6}\r$$\r$$\r\\boldsymbol{\\theta}_{i} = (\\theta_{i1},\\ldots,, θ_{iN}) \\tag{7}\r$$\r$$\r∑_{j=1}^{N}\\theta_{ij} = 1 \\tag{8}\r$$\r$$\ri=1,\\ldots,M\r$$\r $(6)$式とデータによる尤度に基づいたMCMCにより、各行ごとの観測度数の生成確率$\\boldsymbol{\\theta} _ {i}$の事後分布及びMCMCサンプルが得られます。 観測度数の行の総和$F_{i.}$が小さい行の$\\boldsymbol{\\theta}_{i}$ほど、事後分布の推定幅が広くなります。このMCMCサンプルに対する主成分ベクトルの射影を得ることで、同時付置図における項目$I$（行項目）の各ポイントの信頼区間を表示できると考えられます。 項目$J$（列項目）についても、各列の観測度数に独立の多項分布を仮定することで、各ポイントの座標について信頼区間が得られると考えられますが、今回の実装では項目$J$を変量とみなし、列毎の観測度数の総和は試行ごとに一定でないと考えるので、列毎に独立の多項分布を仮定しない（列項目のポイントの座標の信頼区間は求めない）ことにします8。 事前分布 $\\boldsymbol{\\theta}_i$について以下の事前分布を設定しています。これは、相撲データの性質を踏まえて設定したもので、決まり手には比較的メジャーで頻繁に使われる技もあれば、めったに決まる、もしくは使われることのない技もあるだろう、ということを考慮しました。 $$\r\\boldsymbol{\\theta} _{i} \\sim \\mathrm{dirichlet}((p _{.1},\\ldots,p _{.J})) \\tag{9}\r$$\r $(9)$式のように事前分布を設定すると、ディリクレ分布の性質により$\\theta_{ij}$の期待値と分散は以下のようになります。 $$\rE\\left[\\theta_{ij}\\right] = \\cfrac{p_{ij}}{p_{i.}} = \\cfrac{f_{ij}}{f_{i.}} \\tag{10}\r$$\r$$\rV\\left[\\theta_{ij}\\right] = \\cfrac{p_{ij}\\left(p_{i.}-p_{ij}\\right)}{p_{i.}^2\\left(p_{i.}+1\\right)} = \\cfrac{p_{ij}(1-p_{ij})}{2} \\tag{11}\r$$\r なので、$(10)$式より各行毎のセルの値の生成確率$\\theta_{ij}$の期待値は全観測度数に占める列毎の観測度数の総和の割合$\\cfrac{f_{ij}}{f_{i.}}$に等しくなります。 分散については深く考えて決めたものではありませんが、ディリクレ分布の全パラメータの比はそのままに和を大きくしていくと、出力の期待値は一定のまま分散が減少するようになっているので、この性質を利用して$(9)$式の$(p_{.1},\\ldots,p_{.J})$を等倍していって事前分布の強さを変化させていっても面白そうです。 MCMCサンプルより生成量を得る値 対応分析の分析過程のなかのどの数値に対し、MCMCサンプルより生成量を得るかを考えます。$(1)$式より、座標は$\\boldsymbol{X}$及び固有ベクトル$\\boldsymbol{l}_k$ により計算されますから、それぞれについて考えます。 主成分分析の対象$\\boldsymbol{X}$ 行列$\\boldsymbol{X}$は、統計的に独立な$M$つの多項分布からの生成量より構成されるものです。 これの生成量を素直に得ようとすると、$M$個の独立な生成過程がかかわってしまいます。考え方は色々あると思いますが、ここでは、個体$i$の同時付置図の信頼区間には、個体$i$の従う多項分布のパラメータ$\\boldsymbol{\\theta}_i$の影響しか反映させないものとし、$(12)$の行列から$\\boldsymbol{X}$を計算することにします9。 $$\r\\left(\r\\begin{array}{ccc}\rf_{11} \u0026 f_{12} \u0026 \\cdots \u0026 f_{1N} \\\\\\\\\r\\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\\\\\\\\r\\theta_{i1}f_{i.} \u0026 \\theta_{i2}f_{i.} \u0026 \\cdots \u0026 \\theta_{iN}f_{i.} \\\\\\\\\r\\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\\\\\\\\rf_{M1} \u0026 f_{M2} \u0026 \\cdots \u0026 f_{MN}\r\\end{array}\\right) \\tag{12}\r$$\r 固有ベクトル$\\boldsymbol{l}_k$ 分割表の生成過程のモデリングにより、各セルの観測度数の期待値がMCMCサンプルから計算できます。それらをもとに新しい分割表を生成し、新たに主成分ベクトルを得ることができるにはできるのですが、そうすると軸がMCMCサンプル毎に異なってしまいます。最終的に作成する同時付置図は軸を固定して示したいのでこれは不都合です。 今回のモデルでは、観測値を真の値とみなすのと同様に、観測値から得られた主成分ベクトルを真のベクトルであるとみなし、同時付置図も観測値から計算された主成分ベクトル上で付置するものとします。固有値や寄与率についても同様に観測値から計算された値を真の値とします。 モデルの実装 以上のモデルを実装したStanコードを載せます。 data{}ブロックでは分割表に関する数値を指定するだけですが、通常の対応分析を実行するパートはStan外で行うことにしたので、事前に得られた固有ベクトルをvector[N] eigenvector[K]で指定しています。 transformed data{}ブロックでは、後のgenerated quantities{}ブロックでの計算に必要な値$p_{i.}$、$P_{i.}$や事前分布の計算に必要な$p_{.j}$を指定します。 ちなみにStanで実装されている関数eigenvalues_sym()やeigenvectors_sym()を使えば、このブロック内で対応分析を済ませることも可能です。私はStan内で主成分ベクトルを計算すると、外で計算したものと異なってくるのでクレバーではないと判断しました。 {parameters{}ブロックでは項目$I$について仮定した各行毎に独立の多項分布のパラメータ$\\boldsymbol{\\theta_{i}}$を指定しています。 model{}ブロックでは$(6)$式のモデル及び$(9)$式の事前分布を指定しています。 generated quantities{}ブロックでは、data{}ブロックで指定した固有ベクトルやtransformed data{}で指定した行列・ベクトル、及びMCMCサンプルを用いて座標の生成量を求めています。項目$I$のポイントについては2通り計算しており、観測度数の期待値から分割表を作成し求めた各ポイントの座標の生成量（Z_EST）と、観測度数の期待値から乱数を発生させて作成した分割表から求めた座標の生成量（Z_RNG）があります。 // model.stan data { int\u0026lt;lower=0\u0026gt; Sum; //全観測数の和 int\u0026lt;lower=0\u0026gt; N; //分割表の列数 int\u0026lt;lower=N\u0026gt; M; // 分割表の行数 int\u0026lt;lower=0\u0026gt; K; // min(N,M)-1 対応分析で得られる次元数 int d[M,N]; //分割表 vector[N] eigenvector[K]; } transformed data{ matrix[M,N] d_numeric; //分割表 確率行列を作成するためにint型の分割表は使えない vector[M] p_i; //行ごとの観測値全体に占める割合 vector[N] p_j; //列ごとの観測値全体に占める割合 matrix[M,M] P_I; for(j in 1:N){ for(i in 1:M){ d_numeric[i,j] = d[i,j]; } } for(i in 1:M){ p_i[i] = sum(d_numeric[i,]) / Sum; } for(j in 1:N){ p_j[j] = sum(d_numeric[,j])/Sum; } P_I = diag_matrix(p_i); } parameters{ simplex[N] theta[M]; } model { //モデル部分 for(i in 1:M){ d[i,] ~ multinomial(theta[i]); } //事前分布 for(i in 1:M){ theta[i] ~ dirichlet(p_j); } } generated quantities{ vector[M] Z_EST[K]; //求めたい座標（期待値） vector[M] Z_RNG[K]; //求めたい座標（事後分布からの乱数生成） //期待値の座標を計算 { matrix[M,N] P_IJ_EST; matrix[M,N] P_IJ_RNG; int d_RNG[M,N]; matrix[M,N] d_numeric_RNG; matrix[N,N] sq_P_J_EST; matrix[N,N] sq_P_J_RNG; matrix[M,N] X_EST; matrix[M,N] X_RNG; //以降は行毎に必要な操作 for(i in 1:M){ //着目する行によってP_IJは異なる for(m in 1:M){ //P_IJの生成 if(m==i){ P_IJ_EST[m,] = (theta[i] * (sum(d_numeric[i,])) / Sum)\u0026#39;; //対象の行のみ期待値を用いる }else{ P_IJ_EST[m,] = d_numeric[m,] / Sum; } } //着目する行によってP_Jも異なる { vector[N] sq_p_j_EST; for(n in 1:N){ sq_p_j_EST[n] = sqrt(sum(P_IJ_EST[,n])); } sq_P_J_EST = diag_matrix(sq_p_j_EST); } X_EST = inverse(P_I) * P_IJ_EST * inverse(sq_P_J_EST); for(k in 1:K){ Z_EST[k,i] = X_EST[i] * eigenvector[k]; } } //乱数生成したときの座標を計算 for(i in 1:M){ for(m in 1:M){ //P_IJの生成 if(m==i){ d_RNG[m,] = multinomial_rng(theta[m],sum(d[m,])); }else{ d_RNG[m,] = d[m,]; } } for(n in 1:N){ for(m in 1:M){ d_numeric_RNG[m,n] = d_RNG[m,n]; } } P_IJ_RNG = d_numeric_RNG / Sum; { vector[N] sq_p_j_RNG; for(n in 1:N){ sq_p_j_RNG[n] = sqrt(sum(P_IJ_RNG[,n])); } sq_P_J_RNG = diag_matrix(sq_p_j_RNG); } X_RNG = inverse(P_I) * P_IJ_RNG * inverse(sq_P_J_RNG); for(k in 1:K){ Z_RNG[k,i] = X_RNG[i] * eigenvector[k]; } } } } 結果の確認 以下でMCMCを走らせ、$\\hat{R}$で収束を確認します。モデル部分が簡素なのですぐ終わりますし、収束もばっちりですな。 library(rstan) # 行列Xの作成 ------------------------------------------------------------ N \u0026lt;- sum(smo_data) m \u0026lt;- nrow(smo_data) n \u0026lt;- ncol(smo_data) K \u0026lt;- min(n,m) - 1 p_i \u0026lt;- rep(NA, length=m) for(i in 1:m){ p_i[i] \u0026lt;- sum(smo_data[i,])/N } P_i \u0026lt;- diag(p_i) p_j \u0026lt;- rep(NA, length=n) for(j in 1:n){ p_j[j] \u0026lt;- sum(smo_data[,j])/N } P_j \u0026lt;- diag(p_j) P_ij \u0026lt;- smo_data/N matpow \u0026lt;- function(x, pow=2) { y \u0026lt;- eigen(x) y$vectors %*% diag( (y$values)^pow ) %*% t(y$vectors) } X \u0026lt;- solve(P_i) %*% P_ij %*% matpow(P_j, pow=(-1/2)) # 論文の方法に則った対応分析 ----------------------------------------------------------- X_bar \u0026lt;- matrix(rep(colSums(X)/nrow(X),nrow(X)), byrow=T, nrow=nrow(X)) X_cov \u0026lt;- t((X - X_bar)) %*% P_i %*% (X - X_bar) X_pca \u0026lt;- eigen(X_cov) rikishi_coord \u0026lt;- (X %*% X_pca$vectors[,1:K]) waza_coord \u0026lt;- matrix(NA, nrow=n, ncol=K) for(k in 1:K){ waza_coord[,k] \u0026lt;- 1/sqrt(X_pca$values[k]) * solve(P_j) %*% t(P_ij) %*% rikishi_coord[,k] } waza_coord \u0026lt;- data.frame(dim=waza_coord, target=c(\u0026#34;寄り\u0026#34;,\u0026#34;押し\u0026#34;,\u0026#34;投げ\u0026#34;,\u0026#34;引き\u0026#34;,\u0026#34;送り\u0026#34;,\u0026#34;突き\u0026#34;,\u0026#34;その他\u0026#34;)) varsum \u0026lt;- sum(X_pca$values[1:6]) cat(paste(sprintf(\u0026#34;\\nContribution Rate of dim%.f: %.3f\u0026#34;, 1:6,X_pca$values[1:6]/varsum))) ## Contribution Rate of dim1: 0.463 ## Contribution Rate of dim2: 0.248 ## Contribution Rate of dim3: 0.165 ## Contribution Rate of dim4: 0.060 ## Contribution Rate of dim5: 0.038 ## Contribution Rate of dim6: 0.026 var_rate \u0026lt;- X_pca$values[1:6]/varsum # stanを走らせる ------------------------------------------------------------ data \u0026lt;- list(Sum=N, N=n, M=m, d=smo_data, K=K, eigenvector=t(X_pca$vectors[,1:K])) library(rstan) rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores()) fit \u0026lt;- stan(file=\u0026#34;model.stan\u0026#34;, data=data, chains = 4, iter=1300, warmup = 300) print(fit, pars=\u0026#34;theta\u0026#34;) ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## theta[1,1] 0.47 0 0.08 0.30 0.41 0.47 0.53 0.63 6965 1 ## theta[1,2] 0.46 0 0.08 0.30 0.40 0.46 0.52 0.62 6147 1 ## theta[1,3] 0.01 0 0.01 0.00 0.00 0.00 0.00 0.04 4527 1 ## theta[1,4] 0.00 0 0.01 0.00 0.00 0.00 0.00 0.03 4572 1 ## theta[1,5] 0.03 0 0.03 0.00 0.01 0.02 0.04 0.11 3747 1 ## theta[1,6] 0.00 0 0.00 0.00 0.00 0.00 0.00 0.00 4123 1 ## theta[1,7] 0.03 0 0.03 0.00 0.01 0.02 0.05 0.11 4463 1 ## ～（以下略、全部Rhat1でした）～ 次にインスタ映えプロットを作ります。今回のインスタ映えプロットは観測値から得られる（真の）第1軸と第2軸をもとに付置した対応分析の同時付置図です。項目$I$の各ポイントについてそのベイズ信頼区間を示しました10。 library(tidyr) library(dplyr) library(stringr) library(tibble) library(ggplot2) library(ggrepel) # MAP 推定値を得る関数 MAP \u0026lt;- function(x){ dens \u0026lt;- density(x) mode_i \u0026lt;- which.max(dens$y) mode_x \u0026lt;- dens$x[mode_i] return(mode_x) } # 集計 ---------------------------------------------------------------------- rikishi_label \u0026lt;- c(\u0026#34;小錦\u0026#34;,\u0026#34;琴錦\u0026#34;,\u0026#34;貴闘力\u0026#34;,\u0026#34;霧島\u0026#34;,\u0026#34;栃ノ和歌\u0026#34;,\u0026#34;水戸錦\u0026#34;,\u0026#34;若ノ花\u0026#34;,\u0026#34;貴ノ花\u0026#34;,\u0026#34;武蔵丸\u0026#34;, \u0026#34;大翔山\u0026#34;,\u0026#34;安芸ノ島\u0026#34;,\u0026#34;三杉里\u0026#34;,\u0026#34;旭道山\u0026#34;,\u0026#34;舞の海\u0026#34;,\u0026#34;寺尾\u0026#34;,\u0026#34;琴の若\u0026#34;,\u0026#34;貴ノ浪\u0026#34;, \u0026#34;琴富士\u0026#34;,\u0026#34;隆三杉\u0026#34;,\u0026#34;春日富士\u0026#34;) fit %\u0026gt;% rstan::extract() %\u0026gt;% data.frame()%\u0026gt;% select(starts_with(\u0026#34;Z_EST\u0026#34;)) %\u0026gt;% pivot_longer(everything(), names_to=\u0026#34;key\u0026#34;, values_to = \u0026#34;val\u0026#34;) %\u0026gt;% mutate(dim=as.numeric(str_sub(key, start=7,end=7)), target=as.numeric(str_sub(key,start=9, end=10)), key=NULL) %\u0026gt;% group_by(target, dim) %\u0026gt;% nest() %\u0026gt;% pivot_wider(names_from = dim, values_from = data)%\u0026gt;% unnest() %\u0026gt;% group_by(target) %\u0026gt;% rename(dim1=val, dim2=val1, dim3=val2, dim4=val3, dim5=val4, dim6=val5) %\u0026gt;% summarise_all(funs(MAP=MAP(.),lower=quantile(., 0.25),upper=quantile(.,0.75))) %\u0026gt;% arrange(target) %\u0026gt;% mutate(target=factor(seq(1,m), labels=rikishi_label)) -\u0026gt; plot_row_EST.df fit %\u0026gt;% rstan::extract() %\u0026gt;% data.frame() %\u0026gt;% select(starts_with(\u0026#34;Z_RNG\u0026#34;)) %\u0026gt;% pivot_longer(everything(), names_to=\u0026#34;key\u0026#34;, values_to = \u0026#34;val\u0026#34;) %\u0026gt;% mutate(dim=as.numeric(str_sub(key, start=7,end=7)), target=as.numeric(str_sub(key,start=9, end=10)), key=NULL) %\u0026gt;% group_by(target, dim) %\u0026gt;% nest() %\u0026gt;% pivot_wider(names_from = dim, values_from = data) %\u0026gt;% unnest() %\u0026gt;% group_by(target) %\u0026gt;% rename(dim1=val, dim2=val1, dim3=val2, dim4=val3, dim5=val4, dim6=val5) %\u0026gt;% summarise_all(funs(MAP=MAP(.),lower=quantile(., 0.25),upper=quantile(.,0.75))) %\u0026gt;% arrange(target) %\u0026gt;% mutate(target=factor(seq(1,m), labels=rikishi_label)) -\u0026gt; plot_row_RNG.df fit %\u0026gt;% rstan::extract() %\u0026gt;% data.frame() %\u0026gt;% select(starts_with(\u0026#34;Z_EST\u0026#34;)) %\u0026gt;% pivot_longer(everything(), names_to=\u0026#34;key\u0026#34;, values_to = \u0026#34;val\u0026#34;) %\u0026gt;% mutate(dim=as.numeric(str_sub(key, start=7,end=7)), target=str_sub(key,start=9, end=10), key=NULL) %\u0026gt;% group_by(target, dim) %\u0026gt;% nest() %\u0026gt;% pivot_wider(names_from = dim, values_from = data) %\u0026gt;% unnest() %\u0026gt;% rename(dim1=val, dim2=val1, dim3=val2, dim4=val3, dim5=val4, dim6=val5) %\u0026gt;% ungroup() %\u0026gt;% mutate(target=factor(target,levels=seq(1,m), labels=rikishi_label))-\u0026gt; plot_row_EST_range.df fit %\u0026gt;% rstan::extract() %\u0026gt;% data.frame() %\u0026gt;% select(starts_with(\u0026#34;Z_RNG\u0026#34;)) %\u0026gt;% pivot_longer(everything(), names_to=\u0026#34;key\u0026#34;, values_to = \u0026#34;val\u0026#34;) %\u0026gt;% mutate(dim=as.numeric(str_sub(key, start=7,end=7)), target=str_sub(key,start=9, end=10), key=NULL) %\u0026gt;% group_by(target, dim) %\u0026gt;% nest() %\u0026gt;% pivot_wider(names_from = dim, values_from = data) %\u0026gt;% unnest() %\u0026gt;% rename(dim1=val, dim2=val1, dim3=val2, dim4=val3, dim5=val4, dim6=val5) %\u0026gt;% ungroup() %\u0026gt;% mutate(target=factor(target,levels=seq(1,m), labels=rikishi_label))-\u0026gt; plot_row_RNG_range.df # Plot -------------------------------------------------------------------- library(RColorBrewer) mycol \u0026lt;- c(brewer.pal(11,\u0026#34;Paired\u0026#34;),brewer.pal(9,\u0026#34;Set1\u0026#34;)) # Z_ESTを用いたプロット p \u0026lt;- ggplot() + theme_light(base_size=11) + guides(alpha=FALSE) + stat_density_2d(data=plot_row_EST_range.df, aes(x=dim1, y=dim2, alpha=..nlevel.., fill=target), geom=\u0026#34;polygon\u0026#34;, bins=7)+ geom_errorbar(data=plot_row_EST.df, aes(x=dim1_MAP, y=dim2_MAP,ymin=dim2_lower, ymax=dim2_upper),col=\u0026#34;grey30\u0026#34;, width=0.1,alpha=1) + geom_errorbarh(data=plot_row_EST.df, aes(y=dim2_MAP,xmin=dim1_lower, xmax=dim1_upper),col=\u0026#34;grey30\u0026#34;, height=0.1,alpha=1) + geom_point(data=waza_axis, aes(x=dim.1, y=dim.2),size=2, shape=17) + geom_point(data=plot_row_EST.df, aes(x=dim1_MAP, y=dim2_MAP,fill=target),shape=21,size=2) + geom_text_repel(data=plot_row_EST.df,aes(x=dim1_MAP,y=dim2_MAP,label=target)) + geom_text_repel(data=waza_axis, aes(x=dim.1, y=dim.2, label=target)) + labs(title=\u0026#34;Correspondence Analysis with Bayesian 50% confidence intervas \u0026amp; density\u0026#34;, x=sprintf(\u0026#34;dim1(%.3f%%)\u0026#34;, var_rate[1]*100), y=sprintf(\u0026#34;dim2(%.3f%%)\u0026#34;, var_rate[2]*100)) + theme(legend.title = element_blank()) + scale_fill_manual(values=mycol) + scale_alpha_continuous(range=c(0.1,0.5)) p 今回は1次元・2次元だけでなく3次元以降も可視化できるようにしてます。 It\u0026rsquo;s so brilliant! どちらの図も、付置が縄跳び状ですね。対応分析の付置図はこのようになわとびのような形になる（馬蹄形効果）ことが多いようです。それ自体が悪いことなのかよく知らないのですが、これに対する対応策もあるようです（今後の自分への宿題）。 対応分析の結果の解釈は前回の記事に譲り、項目$I$の各ポイントの信頼区間について確認してみます。 白星の最も多い力士は貴乃花で59、最も少ない力士は春日富士で25でした。そこで両者の付置の信頼区間をみると、春日富士の方がやはり貴乃花よりも推定幅が広いようです。がしかしその差は第1・第2主成分ベクトルの付置図ではそれほど明瞭でありません。主成分ベクトルによる写像の影響も絡んでいるのでしょう。 一応貴ノ花と春日富士の従う多項分布のパラメータの事後分布を確認します。 春日富士の方がやはり事後分布の幅が広い？ ほかの力士についても言及すると、第1・第2主成分ベクトルの付置図では小錦や武蔵丸などは他の力士と分布がほぼかぶっていないので、他の力士とは性格の異なる力士であるということが自信をもって言えそうです。逆に分布のかぶり具合で力士同士の類似性もわかる？ パラメータの事後分布から乱数生成して求めた各ポイントの座標の予測区間も示しておきます11。誤差を考慮したので当然着色部の幅が広くなっています。 おまけ～私が相撲に参加すると？～ 標本数の違いによる信頼区間の幅の差があまり実感出来なかったので、極端な例で試してみました。 私(R.morta)が相撲に参加した体で、新たな行を作成します。ただ私は相撲などしたことがない一般人なので、当然力士に勝てる見込みもありません。それでは分割表が作れないので、八百長をした体にして、「引き」での勝ち数が多いことにしてみましょう12。 smo_data \u0026lt;- matrix(data=c(15,15,0,0,1,0,1,19,9,7,12,1,3,3,4,22,0,11,2,0,4, 14,3,11,3,1,1,6,24,7,5,5,0,0,2,30,2,6,2,2,0,2, 11,13,5,6,2,1,4,25,8,10,7,5,3,1,13,31,3,3,0,2,3, 8,2,19,3,2,0,4,28,8,8,2,1,0,7,9,3,14,11,2,0,4, 5,3,12,11,4,0,7,7,1,18,0,1,0,11,12,6,1,12,7,2,2, 25,2,11,3,1,0,1,16,4,18,3,0,0,5,23,2,6,5,1,0,2, 7,17,2,16,3,0,1,2,8,1,11,1,0,2, 3,0,1,5,0,0,2),byrow=TRUE, ncol=7) colnames(smo_data) \u0026lt;- c(\u0026#34;寄り\u0026#34;,\u0026#34;押し\u0026#34;,\u0026#34;投げ\u0026#34;,\u0026#34;引き\u0026#34;,\u0026#34;送り\u0026#34;,\u0026#34;突き\u0026#34;,\u0026#34;その他\u0026#34;) rownames(smo_data) \u0026lt;- c(\u0026#34;小錦\u0026#34;,\u0026#34;琴錦\u0026#34;,\u0026#34;貴闘力\u0026#34;,\u0026#34;霧島\u0026#34;,\u0026#34;栃ノ和歌\u0026#34;,\u0026#34;水戸錦\u0026#34;,\u0026#34;若ノ花\u0026#34;,\u0026#34;貴ノ花\u0026#34;,\u0026#34;武蔵丸\u0026#34;, \u0026#34;大翔山\u0026#34;,\u0026#34;安芸ノ島\u0026#34;,\u0026#34;三杉里\u0026#34;,\u0026#34;旭道山\u0026#34;,\u0026#34;舞の海\u0026#34;,\u0026#34;寺尾\u0026#34;,\u0026#34;琴の若\u0026#34;,\u0026#34;貴ノ浪\u0026#34;, \u0026#34;琴富士\u0026#34;,\u0026#34;隆三杉\u0026#34;,\u0026#34;春日富士\u0026#34;,\u0026#34;R.morita\u0026#34;) ～（以下略）～ 私の従う多項分布のパラメータ事後分布幅はやはり広いですね。 インスタ映えプロットも見てみましょう。 期待通りの結果です。私の信頼区間だけ他と比べて広いです。特に「引き」の寄与が大きい「組んで取る相撲」-「離れて取る相撲」の第2軸についてその傾向が大きく、座標の正負もあやしい状態です。 以上で対応分析の同時付置図に各ポイントの信頼区間を示すことが出来ていることを確認できました。 まとめ 対応分析の同時付置図にベイズ信頼区間を表示する試みを紹介しました。やったことは単純で、対応分析の同時付置図には抜け落ちてしまっている標本数や付置の信頼度の情報を、多項分布モデルの事後分布幅に読み替え、MCMCサンプルの分布を同時付置図上に加えただけです。 同時付置図を基に項目をパターン分けしたりする際、今回のような方法で同時付置図上にポイントの信頼区間を表示することで、誤った判断を下すことを防げるのではないかと思っています。 あとは図がとても美しいのがウリですね。 $N$個の列変量に対する次元削減を狙いとした主成分分析なので、$N$個の固有値・固有ベクトルが得られます。そのうち最小固有値は自明な解$\\lambda_{N}≃0$、$l_{N}=(\\sqrt{p_{.1}},\\ldots,\\sqrt{p_{.N}})$であり、それを除いた$N-1$次元が得られる次元になるようです。（論文では自明な解$\\lambda_{N}≃1$と記載されていたが計算すると自明な固有ベクトルに対応する固有値は0に近かった。どちらが正しいのか検算・理解が追い付かなかった…）さらに$N\u0026gt;M$のときは$M-1$次元までを採用することになります \u0026#x21a9;\u0026#xfe0e; 行列$X$のユークリッド距離が$\\cfrac{f_{ij}}{f_{i.}}$に関する行項目間の$χ^2$距離になっているので、分割表の一様性の検定における検定対象は対応分析において視覚的に強調しようとしている対象そのものになっています \u0026#x21a9;\u0026#xfe0e; 参考論文では帰無仮説：$\\cfrac{p_{ij}}{p_{i.}} = p_{.j}$となっていますが同じことです。分かりにくいナ \u0026#x21a9;\u0026#xfe0e; 4で割ると整数にならない観測度数がでてきますが気にしないようにしましょう。整数じゃなくても検定はできます。 \u0026#x21a9;\u0026#xfe0e; 自明な固有ベクトルとの内積になっているので0です \u0026#x21a9;\u0026#xfe0e; 最右辺の$\\cfrac{\\left(\\cfrac{p_{ij}}{p_{i.}}-p_{.j}\\right)^2}{p_{.j}}$は、対応分析で各ポイントと原点からの距離として視覚的に表示される対象そのものです。分割表の一様性検定における検定統計量が$(5)$式のように分解されることからも、対応分析の同時付置図には標本数の情報がすっぽり抜き取られている\rことが確認できます。 \u0026#x21a9;\u0026#xfe0e; ベイズ信頼区間は、パラメータのMCMCサンプルより分割表の各セルの期待値を計算し、各ポイントの分布を求めたものとし、ベイズ予測区間はパラメータのMCMCサンプルから分割表の各セルの値を乱数生成した上で各ポイントの分布を求めたものとします \u0026#x21a9;\u0026#xfe0e; 列項目については$項目間のχ^2$距離を最大限説明できる軸を解析的に得るのみにして、生成過程を仮定してMCMCサンプルを得る、ということはしない、という考えです \u0026#x21a9;\u0026#xfe0e; 個体$i$の付置の予測区間を求める際は、$(12)$式の$i$行目に$\\boldsymbol{\\theta_{i}}$のMCMCサンプルを用いた乱数生成量をいれます \u0026#x21a9;\u0026#xfe0e; エラーバーで各座標の50%信頼区間を示し、着色で二次元カーネル密度推定結果を、等高線の最大値を1としたときの0.2以上の範囲を描画しています。 \u0026#x21a9;\u0026#xfe0e; Z_RNGをZ_ESTのかわりに用いることで得られます。集計までのコードも一緒に載せています \u0026#x21a9;\u0026#xfe0e; 八百長での決まり手には「引き」がよく採用されるようです \u0026#x21a9;\u0026#xfe0e;"
  },
  {
    url: "https://sucre-stat.com/tags/%E5%A4%9A%E5%A4%89%E9%87%8F%E8%A7%A3%E6%9E%90/",
    title: "多変量解析",
    date: "2020-12-11T00:00:00Z",
    body: "多変量解析"
  },
  {
    url: "https://sucre-stat.com/2020/11/correspondenceanalysis/",
    title: "対応分析について",
    date: "2020-11-07T00:00:00Z",
    body: "対応分析について はじめに 秋は晴天の日が多いですネ。晴れた空の日曜日は外に出かけてみたくもなりますが、草野さんは部屋で昨日の夢を思い出しながら妄想するのもいいと言っています。なるほど… さてこの記事はStan Advent calendar12月12日にエントリーしている記事（未投稿）を補完するために先に作成した記事になります。 この記事では多変量解析の一つである対応分析を取り上げます。 対応分析は多変量のカテゴリカルデータに用いられる分析で、分割表の結果を視覚的に表現するために使われる統計的手法です。 実は対応分析は私の修士研究で使用した解析手法なのですが、対応分析の付置はデータ数に依存しないことから、座標を得るだけでその信頼性が確認できないところに当時問題を感じていました。 この問題に対しベイズ的なアプローチをとることで解決できないかと錯誤した結果、うまくいったぽいので、Stanアドベントカレンダーではその結果について記事にする予定です。 本記事ではその前段階として、対応分析の理論的な枠組みと結果の解釈の方法などについて理解した範囲でまとめます。 本記事の構成は以下のとおりとします。 はじめに 対応分析について 対応分析法がやろうとしていること 行項目・列項目の座標の求め方 得られた軸の性質 分析例 Rを用いた計算例 結果の解釈 終わりに 今回説明できなかったこと 次回触れたいこと 参考にした論文はこちらです。 この論文はもうだいぶ古いものですが、対応分析の理論が簡潔に記載されています。また、先に述べた対応分析の付置の信頼性の問題を解決してくれています1が、今回は信頼区間の問題には極力触れずにいきます。 対応分析について 対応分析とは分割表2など、カテゴリカルな行と列のデータを視覚的に表現することで、項目間の関係を把握しようとする手法です。コレスポンデンス分析とも呼ばれ、数理的には林先生の数量化理論第Ⅲ類と同等のものとされています。 対応分析法がやろうとしていること $i$行$j$列が$f_{ij}$（$i=1 … M$、$j = 1 … N$）である$M$行$N$列の分割表について考えます。 以下、この分割表の行項目$I$を、関係性を把握したい対象、列項目$J$を変量とみなして説明します。 各行・列および全項目の総和を以下のように表記します。 $$\rf_{i.} = ∑_{j=1}^{N}f_{ij} ~,~~ f_{.j} = ∑_{i=1}^{M}f_{ij} ~,~~ Sum = ∑_{j=1}^{N} ∑_{i=1}^{M} f_{ij}\r$$\r 対応分析は、結局のところ以下の$M$×$N$行列$\\boldsymbol{X}$を$M$個の$N$変量のデータととらえた主成分分析と言えます。 $$\r\\boldsymbol{X} = \\boldsymbol{P} _{I}^{-1} \\boldsymbol{P} _{IJ} \\boldsymbol{P} _{J}^{-1/2}\r$$\r ここで、$\\boldsymbol{P} _{ij}$ は $f _{ij}/N$を$(i,j)$成分にもつ$M$×$N$行列、$\\boldsymbol{P}_I$と$\\boldsymbol{P}_J$は以下の単位行列です。 $$\r\\boldsymbol{P}_I = \\mathrm{diag} \\left[ p_{1.}, …, p_{M.} \\right] ~,~~ p_{i.} = f_{i.}/Sum\r$$\r$$\r\\boldsymbol{P}_J = \\mathrm{diag} \\left[ p_{.1}, …, p_{.N} \\right] ~,~~ p_{.j} = f_{.j}/Sum\r$$\r $X$の($i,j$)成分$x_{ij}$は以下のようになっています。 $$\rx_{ij} = \\cfrac{p_{ij}}{p_{i.} \\sqrt{p_{,j}}}　\\tag{1}\r$$\r $p_{ij}$をそのまま使うのではなくその行・列の全体の割合で調整しているようです。この意味合いは次の$\\mathcal{\\chi}^2$距離について考えると理解できます。 行項目$I$の$i_1$番目と、$i_2$番目の個体の間の$\\mathcal{\\chi}^2$距離は、 $$\r\\chi^2_{i_{1}i_{2}} = \\sqrt{\\sum^{N}_{j=1}\r\\cfrac{\\left( \\cfrac{p_{i_{1}j}}{p_{i_{1}.}} - \\cfrac{p_{i_{2}j}}{p_{i_{2}.}}\r\\right)^2}{p_{.j}}} = \\sqrt{\\sum^{N}_{j=1}\r\\cfrac{\\left( \\cfrac{f_{i_{1}j}}{f_{i_{1}.}} - \\cfrac{f_{i_{2}j}}{f_{i_{2}.}}\r\\right)^2}{p_{.j}}} \\tag{2}\r$$\r で計算されます。これは、観測度数が少ない変量ほどより大きく距離に影響するように重みづけられた$f_{ij}/f_{i.}$に関するユークリッド距離になっています（二番目の等号参照）。 そしてこれは、$\\boldsymbol{X}$に対するユークリッド距離の計算をすることで求めることができるようになっています（一番目の等号参照）。 対応分析が$(1)$式で計算される行列の主成分分析であるということは、つまり、対応分析とは$(2)$式で定義された$\\mathcal{\\chi}^2$距離に関する変量の関係を最大限に説明できる軸を求め、それらの軸上に各項目を配置することで、項目間の関係性を視覚的に表示しようとする分析手法である、ということになります3。 行項目・列項目の座標の求め方 ここからは基本的に$\\boldsymbol{X}$に関する主成分分析についての話です。項目$J$についても同様の行列計算・固有値分解を実行することで軸・座標を得ることができます。ただ、項目$I$と項目$J$それぞれで同じ軸が得られるというところの理論がよくわかりません。ここではそのへんの話は「そういうもの」とさせてください… $\\mathbf{1}_m = (1,\\ldots,1) ∈ R^m$として $$\r\\boldsymbol{\\bar{X}} = \\left(\r\\begin{array}{ccc}\r\\cfrac{1}{M}\\sum_{i=1}^{M}x_{i1} \u0026 \\cfrac{1}{M}\\sum_{i=1}^{M}x_{i2} \u0026 \\cdots \u0026 \\cfrac{1}{M}\\sum_{i=1}^{M}x_{iN} \\\\\\\\\r\\cfrac{1}{M}\\sum_{i=1}^{M}x_{i1} \u0026 \\ddots \u0026 \\cdots \u0026 \\cfrac{1}{M}\\sum_{i=1}^{M}x_{iN} \\\\\\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\\r\\cfrac{1}{M}\\sum_{i=1}^{M}x_{i1} \u0026 \\cfrac{1}{M}\\sum_{i=1}^{M}x_{i2} \u0026 \\cdots \u0026 \\cfrac{1}{M}\\sum_{i=1}^{M}x_{iN}\r\\end{array}\\right) = \\cfrac{1}{m} \\mathbf{1}_m^T \\mathbf{1}_m \\tag{3}\r$$\r とする4と、$\\boldsymbol{X}$の分散共分散行列$\\boldsymbol{Σ}$は $$\r\\boldsymbol{Σ} = \\left(\\boldsymbol{X}-\\boldsymbol{\\bar{X}}\\right)^T \\boldsymbol{P}_I \\left(\\boldsymbol{X}-\\boldsymbol{\\bar{X}}\\right) \\tag{4}\r$$\r となります。 …いや冗談だろう、$\\boldsymbol{X}$の分散共分散行列は $$\r\\boldsymbol{Σ} = \\cfrac{1}{N}\\left(\\boldsymbol{X}-\\boldsymbol{\\bar{X}}\\right)^T\\left(\\boldsymbol{X}-\\boldsymbol{\\bar{X}}\\right) \\tag{4'}\r$$\r だろ、とはじパタで主成分分析を学んだ私は思ったのですが、$\\boldsymbol{P} _{I}$の対角成分が$f _{i.}/Sum$であることを踏まえると、分割表で集計された1つのセルを1観測値とするのではなく、1つの観測事象を1観測値としたときの分散共分散行列を計算する、というような計算をしているっぽいです。錚々たる専門家集団から査読・Acceptされたであろう参考論文にそう書かれているので、ここでは$(4)$式を正としましょう… とにかく、$(4)$式の$\\boldsymbol{\\Sigma}$について固有値問題を解いて、得られた固有値を最大固有値から順に$\\lambda_{1},\\lambda_{2}\\ldots,\\lambda_{N}$、これらに対応する固有ベクトルを順に$\\boldsymbol{l}_1,\\boldsymbol{l}_2,\\boldsymbol,\\boldsymbol{l}_N$とします。これらを用いて、第$k$主成分ベクトルによる項目$I$の数量化スコア$\\boldsymbol{z}_{k} = (z_{1k}, \\ldots, z_{Nk})$を計算します。 $$\r\\boldsymbol{z} _{k} = \\boldsymbol{X} \\boldsymbol{l} _{k} = \\boldsymbol{P} _{I}^{-1} \\boldsymbol{P} _{IJ} \\boldsymbol{P} _{j}^{-1/2} \\boldsymbol{l} _{k} \\tag{5}\r$$\r これは主成分分析のスコアの計算と同じですね。純粋に項目$I$について主成分ベクトルに対する写像を得ています。 項目$J$の数量化スコア$\\boldsymbol{z}^{*}_k$は、項目$I$と同様にして計算することもできますが、項目$I$の数量化スコアから求めることもできるようです。証明は未確認ですが、この式を信用していくことにします。 $$\r\\boldsymbol{z}_k^* = \\cfrac{1}{\\sqrt{λ_k}}\\boldsymbol{P}_J^{-1}\\boldsymbol{P}_{IJ}\\boldsymbol{z}_k \\tag{6}\r$$\r $(5)$式および$(6)$式により得られた数量化スコアを同じ図の中に付置したものを同時付置図といい、同時付置図をもとに項目間の関係性をみることになります。 得られた軸の性質 対応分析によって得られた軸に関する性質をまとめておきます。これらの性質は付置図について考察する際の前提にもなります。またこれらの性質はすべて主成分分析からきたものです。ここで$K=\\rm{min}(\\mathcal{m},\\mathcal{n}) -1$56とします。 \r第$k$数量化スコアの平均は0$\\left(∑_{k=1}^{K} f_{i.}z_{ik}= 0\\right)$\r\r\r\r第$k$数量化スコアの分散は$\\lambda_k$\r\r\r\r各固有ベクトルは互いに直行する=数量化スコアは無相関($Cov(z_{k1}, z_{k2}) = 0$) \r\r\r各数量化スコアによる全データ変動の説明割合は、$\\cfrac{\\lambda_{k}}{\\sum_{k=1}^{K}\\lambda_k}$となる\r\r\r分析例 Rを用いた計算例 実際に対応分析をやってみます。 サンプルデータは参考論文にあった貴乃花現役時代の大相撲6場所の幕内力士20人の勝ち数と決まり手の関係です。 smo_data \u0026lt;- matrix(data=c(15,15,0,0,1,0,1,19,9,7,12,1,3,3,4,22,0,11,2,0,4, 14,3,11,3,1,1,6,24,7,5,5,0,0,2,30,2,6,2,2,0,2, 11,13,5,6,2,1,4,25,8,10,7,5,3,1,13,31,3,3,0,2,3, 8,2,19,3,2,0,4,28,8,8,2,1,0,7,9,3,14,11,2,0,4, 5,3,12,11,4,0,7,7,1,18,0,1,0,11,12,6,1,12,7,2,2, 25,2,11,3,1,0,1,16,4,18,3,0,0,5,23,2,6,5,1,0,2, 7,17,2,16,3,0,1,2,8,1,11,1,0,2),byrow=TRUE, ncol=7) colnames(smo_data) \u0026lt;- c(\u0026#34;寄り\u0026#34;,\u0026#34;押し\u0026#34;,\u0026#34;投げ\u0026#34;,\u0026#34;引き\u0026#34;,\u0026#34;送り\u0026#34;,\u0026#34;突き\u0026#34;,\u0026#34;その他\u0026#34;) rownames(smo_data) \u0026lt;- c(\u0026#34;小錦\u0026#34;,\u0026#34;琴錦\u0026#34;,\u0026#34;貴闘力\u0026#34;,\u0026#34;霧島\u0026#34;,\u0026#34;栃ノ和歌\u0026#34;,\u0026#34;水戸錦\u0026#34;,\u0026#34;若ノ花\u0026#34;, \u0026#34;貴ノ花\u0026#34;,\u0026#34;武蔵丸\u0026#34;,\u0026#34;大翔山\u0026#34;,\u0026#34;安芸ノ島\u0026#34;,\u0026#34;三杉里\u0026#34;,\u0026#34;旭道山\u0026#34;,\u0026#34;舞の海\u0026#34;, \u0026#34;寺尾\u0026#34;,\u0026#34;琴の若\u0026#34;,\u0026#34;貴ノ浪\u0026#34;,\u0026#34;琴富士\u0026#34;,\u0026#34;隆三杉\u0026#34;,\u0026#34;春日富士\u0026#34;) 分析例は以下になります7。変量の数は7なので、得られる軸は6つですが、同時付置図は第1軸と第2軸をもとに作成します。 # 主成分分析の対象行列作成 ------------------------------------------------------------ # apply()とか使わないでごめんなさい N \u0026lt;- sum(smo_data) m \u0026lt;- nrow(smo_data) n \u0026lt;- ncol(smo_data) p_i \u0026lt;- rep(NA, length=m) for(i in 1:m){ p_i[i] \u0026lt;- sum(smo_data[i,])/N } P_i \u0026lt;- diag(p_i) p_j \u0026lt;- rep(NA, length=n) for(j in 1:n){ p_j[j] \u0026lt;- sum(smo_data[,j])/N } P_j \u0026lt;- diag(p_j) P_ij \u0026lt;- smo_data/N matpow \u0026lt;- function(x, pow=2) { y \u0026lt;- eigen(x) y$vectors %*% diag( (y$values)^pow ) %*% t(y$vectors) } X \u0026lt;- solve(P_i) %*% P_ij %*% matpow(P_j, pow=(-1/2)) # 論文の方法に則った対応分析 ----------------------------------------------------------- X_bar \u0026lt;- matrix(rep(colSums(X)/nrow(X),20), byrow=T, nrow=nrow(X)) X_cov \u0026lt;- t((X - X_bar)) %*% P_i %*% (X - X_bar) X_pca \u0026lt;- eigen(X_cov) ## eigen() decomposition ## $values ## [1] 2.507433e-01 1.341368e-01 8.920454e-02 3.256496e-02 2.038708e-02 1.430728e-02 ## [7] 6.775222e-17 ## $vectors ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 0.22994960 0.71371157 -0.2438985 0.15461675 0.08409387 -0.06865717 ## [2,] -0.68444371 0.08147953 0.5365504 -0.03442796 -0.09073808 0.19007387 ## [3,] 0.57769184 -0.34733619 0.2671700 -0.07516444 -0.47057317 0.25705425 ## [4,] -0.30345943 -0.48187904 -0.5352658 0.36673289 -0.18451979 -0.27445628 ## [5,] -0.05982687 -0.19188089 -0.3935578 -0.38378721 0.44535231 0.64529649 ## [6,] -0.09307838 0.04510096 -0.1558085 -0.82883709 -0.24428825 -0.45225825 ## [7,] 0.20149856 -0.30376746 0.3399617 -0.02240822 0.68643479 -0.44363261 ## [,7] ## [1,] -0.5852867 ## [2,] -0.4375669 ## [3,] -0.4255399 ## [4,] -0.3812200 ## [5,] -0.2065814 ## [6,] -0.1176471 ## [7,] -0.2881753 rikishi_coord1 \u0026lt;- X %*% X_pca$vectors[,1] rikishi_coord2 \u0026lt;- X %*% X_pca$vectors[,2] waza_coord1 \u0026lt;- 1/sqrt(X_pca$values[1]) * solve(P_j) %*% t(P_ij) %*% rikishi_coord1 waza_coord2 \u0026lt;- 1/sqrt(X_pca$values[2]) * solve(P_j) %*% t(P_ij) %*% rikishi_coord2 # 寄与率の表示 ------------------------------------------------------------------ varsum \u0026lt;- sum(X_pca$values[1:6]) cat(paste(sprintf(\u0026#34;\\nContribution Rate of dim%.f: %.3f\u0026#34;, 1:6,X_pca$values[1:6]/varsum))) ## Contribution Rate of dim1: 0.463 ## Contribution Rate of dim2: 0.248 ## Contribution Rate of dim3: 0.165 ## Contribution Rate of dim4: 0.060 ## Contribution Rate of dim5: 0.038 ## Contribution Rate of dim6: 0.026 # プロット -------------------------------------------------------------------- library(ggplot2) library(ggrepel) p \u0026lt;- ggplot() + theme_light(base_size=11) + geom_point(data=data.frame(x=rikishi_coord1, y=rikishi_coord2), aes(x=x,y=y), shape=1, col=\u0026#34;red\u0026#34;) + geom_point(data=data.frame(x=waza_coord1, y=waza_coord2), aes(x=x,y=y), shape=2, col=\u0026#34;blue\u0026#34;) + geom_text_repel(data=data.frame(x=rikishi_coord1, y=rikishi_coord2, label=rownames(smo_data)), aes(x=x,y=y,label=label)) + geom_text_repel(data=data.frame(x=waza_coord1, y=waza_coord2, label=colnames(smo_data)), aes(x=x,y=y,label=label)) + labs(title=\u0026#34;Correspondence Analysis\u0026#34;, x=\u0026#34;dim1\u0026#34;, y=\u0026#34;dim2\u0026#34;) p 結果の解釈 以上の結果の解釈をしてみます。 まず、軸の寄与率を確認すると、第1軸で0.463、第2軸で0.248です。累積寄与率は0.711ですから、作成した同時付置図でデータの全分散の71%を説明できることになります。第3軸以降を用いて付置図を作成することも寄与率によっては勧められますが、ここでは71%の寄与率で十分とします。 では図の解釈に移ります。 同時付置図は各ポイントの相対的な位置関係と各軸に対する配置を基に考察されます。 まずはポイントの相対的な位置関係から。 ポイント間の距離は、主成分ベクトルによる写像を受けながらも、$\\mathbf{χ}^2$距離に由来したものであることから、ポイント間の類似性を示します。ここで注意しなければならないことは、行項目、列項目は同じ軸上に付置されるものの、行項目同士・列項目同士の距離は定義されるが、行項目と列項目間の距離は定義されていない、ということです。 なので、例えば図の左下のほうに付置した貴闘力、隆三杉、春日富士は似たような決まり手を持つ力士である、というように解釈していくことになります。 次に各軸に対する配置を見てみます。 ここでは各ポイントの配置から、軸に解釈を与えたりします。参考の論文では以下のような解釈をしています。 第1主成分ベクトルでは「押し」、「引き」の係数が正の値で、「投げ」の係数が負の値で絶対値が大きく、第1軸は「突き押し型」^「投げを得意とする型」を表していると考えられる。第2主成分ベクトルでは「引き」、「投げ」、「その他」が正の値で、「寄り」が負の値で絶対値が大きく、第2軸は「組んで取る相撲」-「離れて取る相撲」を表していると考えられる。 実際に数名の力士の得意技を確認して確かめてみました。 春日富士は、突き、押しが得意な力士だそうで、同時付置図では左下に位置しています。第1軸に関して見れば確かに「突き押し型」の方向に位置することから、春日富士の得意な決まりてが反映された結果になっているようです。 舞の海秀平は関取時代は「平成の牛若丸」、「技のデパート」などと呼ばれたようで、豊富な技を使う力士だったようです。対照的な力士としては安芸乃島勝巳が挙げられ、「寄り」が得意な力士であったようです。第2軸に関して見れば、確かに春日富士は「離れて取る相撲」の方に位置しており、逆に「安芸乃島」は「組んで取る相撲」の方にいます。 このように、対応分析では分割表の数字の羅列から特に意味のある軸を作成し、視覚的に項目間の関係性を把握することができるようになります。 終わりに 対応分析の実践において有用であるにもかかわらず今回説明しなかったことや、次回触れたいことについてまとめておきます。 今回説明できなかったこと こちらの文献に、ここで挙げる今回説明できなかったことが説明されています。修士のときも分からん！といいながらもお世話になっていました。 座標軸へのポイントの寄与 これは、座標軸のベクトルを決定するのに寄与しているポイントを意味するもので、各軸にとって重要なポイントを量的に示したものになります。 同時付置図の視覚的判断によらない軸の解釈方法とでもいうべきか？ ポイントへの軸の寄与 これは、ポイントが、各座標軸によってどの程度表現されているかを示した数値になります。各ポイントの性質を同時付置図の視覚的判断に依らずに確認できる方法になるのかな？ サプリメンタリーポイント これは、一旦分割表の全行・列を用いて対応分析を実行したとき、同時付置図上で特定のポイントのみが他のポイントから極端に離れて付置される場合にとる手段です。 そのポイントを主成分分析の対象から一旦外し、得られたベクトルもとにそのポイントの写像を得る、という対処をします。 次回触れたいこと 次回は、座標の不確実性について考えたいと思っています。気付いたかもしれませんが、対応分析の同時付置図における座標は標本数に依存しないので、付置はできるがその信頼区間が分からない、という状態になっています。ベイズモデリングはこの問題への解決策の一つなのかなと考えています。 多項分布の正規近似に基づいて、解析的に信頼区間を求めているようで、私が試した方法とは別のアプローチをとっています。 \u0026#x21a9;\u0026#xfe0e; 「クロス集計表」とも呼ばれます。 \u0026#x21a9;\u0026#xfe0e; 主成分分析は変量の次元削減に用いられる手法です。はじパタに分かりやすい説明があります。Webならこちらとか。 \u0026#x21a9;\u0026#xfe0e; 文献によれば$(3)$式ではなく、$\\sqrt{p_{j.}}$こそが$\\boldsymbol{X}$の各列の平均値であると仰っているのですが、こちらについては簡単な計算で誤っていると確認したので、参考論文の$(3)$式を正とすることにします。 \u0026#x21a9;\u0026#xfe0e; 次元数が多く得られた項目の方については余剰の次元数を寄与率から度外視するのか…？ \u0026#x21a9;\u0026#xfe0e; 行項目、列項目に対する主成分分析の結果のうち、得られた次元数が少ない方を次元の数とする、ということなのだが、$\\mathrm{min}(m,n)$とはならないのは何故？ \u0026#x21a9;\u0026#xfe0e; RのFactoMineR::CAパッケージなどを使った整合確認は今後の自分に課す課題にします。参考論文における結果と異なるのであやしい気がする…←確認しました。今回の結果とFactoMineR::CAの結果はほぼ一致します。座標に関して言えば小数点第3位程度まで一致しました \u0026#x21a9;\u0026#xfe0e;"
  },
  {
    url: "https://sucre-stat.com/2020/10/modeling/",
    title: "モデリングと情報量基準その１～モデリングとは？～",
    date: "2020-10-03T00:00:00Z",
    body: "モデリングと情報量基準その１～モデリングとは？～ はじめに 少しご無沙汰してしまい、また読者様から重くないやつを定期的にと助言いただきましたので、少し短めの投稿を記事作成のリハビリもかねてしてみようと思います 今回はそもそもこのブログで扱っているモデリングとは何だったのか？について改めて書いてみようと思います。 さらに今後の記事では続きとしてモデル選択の基準、特にベイズで利用できるWAIC（広く使える情報量基準）について書いてみようと思っています。 ただし、難しいことまではよくわからないので、感覚で理解できているところまで。 モデリング モデリングとは そもそもの話です。 統計解析ではデータが生成されるメカニズムを組み立てることでデータの解釈を進めていきます。このような活動をモデリングと呼んでいます。ただし、あるデータに対する数理モデルの候補は通常一つではありません。 例として、今回は回帰分析等のサンプルデータとしてよく用いられるアヤメデータを用います。 アヤメデータにはいくつかの変数がありますが、GGally::ggpairs()で一気に視覚化・相関係数を算出してみます。これぞ業務効率化。 library(GGally) p \u0026lt;- GGally::ggpairs(iris, aes(colour=Species)) p 結果を見ると、花びらの長さ（Peral.Length）と幅（Petal.Width）には強い正の相関（0.963）があることが分かります。他にも様々な関係性が確認できますが、以降では花びらの長さを説明するためのモデルを構築していきます。 モデル1 はじめは最も単純なモデルから。まずは花びらの幅のみで花びらの長さを説明する式です。 $$ \\mu_n = \\alpha x_n + \\beta \\tag{1} $$ $$ y_n \\sim \\rm{Normal}(\\mu_n, \\sigma) \\tag{2} $$ $$ n = 1,2,\\ldots,N $$ ここで、$N$はデータの数、$Y=\\left( y_1, y_2, \\ldots, y_N \\right)$は花びらの長さ、$X=\\left( x_1, x_2, \\ldots, x_N \\right)$は花びらの幅とします。 上の式の意味を見てみましょう。 まず、これまで全く説明していませんでしたが、$(2)$式で使用した数学記号「$\\sim$」は「確率変数（左辺）が確率分布（右辺）に従う」という意味です。 また$Normal()$は正規分布（ガウス分布）を意味します。確率変数の記号の後ろにつく「$()$」には各確率分布のパラメータを明記するのが常です。 正規分布の確率密度関数$f(x)$は以下となり、パラメータは平均$\\mu$、標準偏差$\\sigma$となります。 $$ f(x) = \\cfrac{1}{\\sqrt{2\\pi}\\sigma}exp\\left[\\cfrac{-\\left(x-\\mu\\right)^2}{s\\sigma^2}\\right] $$ よって、$(2)$式は確率変数$Y_n$が平均$\\mu_n$、標準偏差$\\sigma$の正規分布に従うことを意味します。 さらに$(1)$式では$\\mu_n$が$\\alpha x_n + \\beta$という$x$を用いた線形予測子によって計算されるとしています。 ちなみに先に挙げた式を用いて平均0、標準偏差1の正規分布の確率密度関数を視覚化すると、以下のようになります。 library(ggplot2) x \u0026lt;- seq(-5,5,0.1) y \u0026lt;- (1/sqrt(2*pi))*exp(-x^2/2) p \u0026lt;- ggplot(data=data.frame(X=x,Y=y)) + theme_light()+ geom_line(aes(x=X,y=Y)) + xlab(NULL) + ylab(NULL) p このように、正規分布は左右対称であり、平均と標準偏差自体がパラメータとなる使いやすい分布であるため、様々な統計解析に活用されます。最もよく用いられるのは、今回の例のように連続型変数の誤差の分布を仮定するときではないだろうか？ glm()を用いてこのモデルのパラメータを推測した結果が以下になります。 library(ggeffects) res \u0026lt;- glm(data=iris, formula = Petal.Length ~ Petal.Width, family=gaussian) summary(res) ## ## Call: ## glm(formula = Petal.Length ~ Petal.Width, family = gaussian, ## data = iris) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.33542 -0.30347 -0.02955 0.25776 1.39453 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 1.08356 0.07297 14.85 \u0026lt;2e-16 *** ## Petal.Width 2.22994 0.05140 43.39 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.2286808) ## ## Null deviance: 464.325 on 149 degrees of freedom ## Residual deviance: 33.845 on 148 degrees of freedom ## AIC: 208.35 ## ## Number of Fisher Scoring iterations: 2 res_p \u0026lt;- ggeffects::ggpredict(res, terms=\u0026#34;Petal.Width\u0026#34;) ggplot() + theme_light(base_size=11) + geom_point(data=iris, aes(x=Petal.Width, y=Petal.Length), shape=1) + geom_line(data=res_p, aes(x=x, y=predicted)) + geom_ribbon(data=res_p, aes(x=x, ymin=conf.low, ymax=conf.high), alpha=0.1) 結果がいろいろと書いてありますが、今回はCoefficientsのところから、構築したモデルに対する以下の結果を確認するのみとします(Devianceなどについて復習するのが面倒になった顔)。信頼区間の算出方法も実はよくわかっていません…。ベイズ的なアプローチならこのあたりの理論を事後分布で回避できるのに… $$ \\mu_n = 1.08356 X_n + 2.22994 $$ ここまで読んで、エクセルのグラフ機能についている近似曲線（線形近似）と何が違うのか、と思ったかもしれません。実は以上の分析はエクセルでもは全く同じ結果が得られるはずです。違うのは解析手法（最小二乗法か最尤法）くらいかもしれません。しかし単に線形補完をしているのだ、という認識ではなく、上のように統計的なモデルが背景にあるということを理解していると、データに対してより適切な仮定を置くことが可能になります。 はっきり言いますが、ガウス分布を仮定した線形回帰の場合、①目的変数はすべての実数を定義域に持つ連続変数、②目的変数の誤差が正規分布に従うと仮定するため、これらの条件を満たしたデータでないとガウス分布を仮定した線形回帰の結果を信頼することはできない。ということ！ 上記の仮定を無視した例としては、離散型変数を目的変数に置いたり、ガウス分布を仮定した線形回帰をあてはめた際の誤差の分布をQQプロットや正規性の検定等で確認しない場合が挙げられます。 モデル2 モデル1は単回帰と呼ばれ、一つの説明変数しか設定しない分析でしたが、説明変数は一つである必要はありません。より多くの情報を持たせた方がモデルの精度が向上することも十分あります。複数の説明変数が存在する場合、重回帰と呼ばれます。 GGally::ggpairs()の結果からアヤメの種類（Species）も花びらの長さに影響しそうだと判断し、説明変数に先ほどの花びらの長さに加えてアヤメの種類（Species）を追加してみます。モデル式は以下になります。 $$ \\mu_n = \\alpha x_{n} + \\beta_1 Versicolor + \\beta_2 Virginia + \\gamma $$ $$ y_n \\sim \\rm{Normal}(\\mu_n, \\sigma) $$ $$ n = 1,2,\\ldots,N $$ 説明変数に$Versicolor$と$Virginia$を追加しました。これらはアヤメの種類を指しますが、$n=1,2,3\u0026hellip;$としたときに種類がそれぞれに該当したときのみ1をとり、そうでない場合は0をとります。カテゴリカルな説明変数はダミー変数と呼ばれ、通常このような対応をとります。 res \u0026lt;- glm(data=iris, formula = Petal.Length ~ Petal.Width + Species, family=gaussian) summary(res) ## ## Call: ## glm(formula = Petal.Length ~ Petal.Width + Species, family = gaussian, ## data = iris) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.02977 -0.22241 -0.01514 0.18180 1.17449 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 1.21140 0.06524 18.568 \u0026lt; 2e-16 *** ## Petal.Width 1.01871 0.15224 6.691 4.41e-10 *** ## Speciesversicolor 1.69779 0.18095 9.383 \u0026lt; 2e-16 *** ## Speciesvirginica 2.27669 0.28132 8.093 2.08e-13 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 0.1426948) ## ## Null deviance: 464.325 on 149 degrees of freedom ## Residual deviance: 20.833 on 146 degrees of freedom ## AIC: 139.57 ## ## Number of Fisher Scoring iterations: 2 res_p \u0026lt;- ggeffects::ggpredict(res, terms=c(\u0026#34;Petal.Width[all]\u0026#34;,\u0026#34;Species\u0026#34;), rawdata=T) library(RColorBrewer) col=brewer.pal(3,\u0026#34;Set1\u0026#34;) ggplot() + theme_light(base_size=11) + geom_point(data=iris, aes(x=Petal.Width, y=Petal.Length, colour=Species), shape=1) + geom_line(data=res_p, aes(x=x, y=predicted, colour=group)) + geom_ribbon(data=res_p, aes(x=x, ymin=conf.low, ymax=conf.high, fill=group), alpha=0.3) + scale_fill_manual(values=col) + scale_color_manual(values=col) 推定結果は以下の通りです。 $$ \\mu_n = 1.01871 X_n + 1.69779 Versicolor + 2.27669 Virginica + 1.21140 $$ このように、モデリングではある変数を説明するための変数を追加したり取り除いたりし、結果を確認しながら最終的にどの変数を用いるか検討していきます。 モデル3 モデル1およびモデル2は、目的変数の誤差に正規分布を仮定したもので、一般線形モデルとも呼ばれるモデルでした。しかし目的変数の性質によっては誤差が正規分布でかていできない場合もあります。その場合に有効なのが一般化線形モデル（GLM）です。GLMでは誤差に正規分布だけでなく二項分布やポアソン分布、負の二項分布など様々な分布を一般化して扱います。 今回の例の場合、花びらの長さは負の値をとらないことから厳密には正規分布を仮定できません。そこで非負の値を定義域に持つ連続変数に適用できるガンマ分布を誤差が従う分布に仮定します。 モデル式は以下になります。ガンマ分布はshapeパラメータ$k$とrateパラメータ$\\lambda$をもち、$k$は常に一定、$\\lambda$は線形予測子の変化に応じて変化すると仮定します。また目的変数の期待値が非負の値をとることを考慮し、リンク関数として$log$をを設定しています。線形予測子と目的変数の期待値を関連させるのがここでのリンク関数の役割です。下の$(4)$式を変形すると$log(E(y_n))=\\mu_n$となり、$exp$の逆関数である$log$が目的変数の期待値を線形予測子と関連させていることになります。こうすることで$(2)$式の目的変数の期待値が非負の値をとることがないという特性を満足させることが出来ます。 $$ \\mu_n = \\alpha x_{n} + \\beta_1 Versicolor + \\beta_2 Virginia + \\gamma \\tag{3} $$ $$ E(y_n) = k/\\lambda_n = \\rm{exp}(\\mu_n) \\tag{4} $$ $$ y_n \\sim \\rm{Gamma}( k, \\lambda_n) \\tag{5} $$ $$ n = 1,2,\\ldots,N $$ res \u0026lt;- glm(data=iris, formula = Petal.Length ~ Petal.Width + Species, family=Gamma(link=\u0026#34;log\u0026#34;)) summary(res) ## ## Call: ## glm(formula = Petal.Length ~ Petal.Width + Species, family = Gamma(link = \u0026#34;log\u0026#34;), ## data = iris) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.34682 -0.05608 -0.00637 0.05856 0.28685 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.31996 0.01716 18.643 \u0026lt; 2e-16 *** ## Petal.Width 0.24062 0.04005 6.008 1.43e-08 *** ## Speciesversicolor 0.80728 0.04760 16.960 \u0026lt; 2e-16 *** ## Speciesvirginica 0.90676 0.07400 12.253 \u0026lt; 2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## (Dispersion parameter for Gamma family taken to be 0.009874458) ## ## Null deviance: 44.6546 on 149 degrees of freedom ## Residual deviance: 1.4566 on 146 degrees of freedom ## AIC: 93.256 ## ## Number of Fisher Scoring iterations: 4 res_p \u0026lt;- ggeffects::ggpredict(res, terms=c(\u0026#34;Petal.Width[all]\u0026#34;,\u0026#34;Species\u0026#34;), rawdata=T) library(RColorBrewer) col=brewer.pal(3,\u0026#34;Set1\u0026#34;) ggplot() + theme_light(base_size=11) + geom_point(data=iris, aes(x=Petal.Width, y=Petal.Length, colour=Species), shape=1) + geom_line(data=res_p, aes(x=x, y=predicted, colour=group)) + geom_ribbon(data=res_p, aes(x=x, ymin=conf.low, ymax=conf.high, fill=group), alpha=0.3) + scale_fill_manual(values=col) + scale_color_manual(values=col) 推定結果は以下の通りです。 $$ \\mu_n = 0.24062 x_{n} + 0.80728 Versicolor + 0.90672 Virginia + 0.31996 $$ 結果の解釈はお任せしますが、モデルの背景にある仮定をデータの特徴に合わせてより適切なものに修正した形になります。 まとめ 今回はモデリングとは？ということで記事を書いてみました。まとめると以下のような作業がデータの生成過程を組み立てる一連の活動を構成するのかな、と思います。 変数の取捨選択 確率変数やその誤差が従う分布を仮定 次はモデルの取捨選択を手助けする情報量基準についてまとめてみようかなとおもっています。"
  },
  {
    url: "https://sucre-stat.com/tags/%E3%83%8E%E3%83%B3%E3%83%91%E3%83%A9%E3%83%A1%E3%83%88%E3%83%AA%E3%83%83%E3%82%AF%E3%83%99%E3%82%A4%E3%82%BA%E3%83%A2%E3%83%87%E3%83%AB/",
    title: "ノンパラメトリックベイズモデル",
    date: "2020-07-12T00:00:00Z",
    body: "ノンパラメトリックベイズモデル"
  },
  {
    url: "https://sucre-stat.com/2020/07/multinom-gp/",
    title: "多項ロジスティック回帰・ガウス過程モデル",
    date: "2020-07-12T00:00:00Z",
    body: "多項ロジスティック回帰・ガウス過程モデル はじめに いい夢の色は緑色だそうだ。私もうさぎさんにとっての牧草色の夢を見ることもありますが、現実は柵に引っかかってばかりです。 さて、回帰に関する記事です。 以前の記事では、対象が3つ以上のクラスに分類されるとき、それぞれのクラスに属する確率を予測するモデルである多項ロジスティック回帰について書きました。 次の記事では、同様のモデルを、マルコフ連鎖モンテカルロ法(MCMC)を実行するための汎用ソフトであるStanを用いて実装し、ベイズ統計の立場から分析しました。MCMCおよびベイズ統計についてはこちらの記事で(走り書きで)書いています。 上で見た記事ではいずれも対象が各クラスに属する確率のオッズ比に着目し、オッズ比の線形性のみを考慮したモデルです。このように統計モデルでは変数の背後に何かしらの分布を想定したり、変数間に線形的な関係を想定したりすることでモデルを構築します。 一方で、特定の分布や関係を仮定せず、与えられたデータに柔軟に対応することのできるモデルも存在します。そのようなモデルの例としてこちらの記事ではガウス過程回帰について取り上げました。 またガウス過程を様々なデータやモデルに応用できるよう、前回の記事ではガウス過程潜在変数モデルやカテゴリカルな変数に対応できるカーネル、予測分布の計算方法について説明しました。 今回の記事はこれらの記事の内容をフル活用し、多項ロジスティック回帰にガウス過程を適用したモデルを実装します。 最終目標は、対象が各クラスに属する確率の予測値を、データに柔軟にフィットさせることです。 本記事の構成は以下の通りとします。 はじめに データの入手 多項ロジスティック・ガウス過程モデル モデルの確認 カーネル関数の設定方法 モデル１の実装と結果の確認 モデル２の実装と結果の確認 まとめ 当初本記事と前回の記事はひとつの記事として公開していましたが、余りにも長すぎる記事だったので、二つに分けて公開しなおしました。 データの入手 以前の記事でRのnnetパッケージを使って多項ロジスティック回帰分析をしたときに用いたものと同じデータを用いますある学校の生徒の属性と各生徒が選択した授業に関するデータです。 library(foreign) ml \u0026lt;- read.dta(\u0026#34;https://stats.idre.ucla.edu/stat/data/hsbdemo.dta\u0026#34;) head(ml) ## id female ses schtyp prog read write math science socst honors ## 1 45 female low public vocation 34 35 41 29 26 not enrolled ## 2 108 male middle public general 34 33 41 36 36 not enrolled ## 3 15 male high public vocation 39 39 44 26 42 not enrolled ## 4 67 male low public vocation 37 37 42 33 32 not enrolled ## 5 153 male middle public vocation 39 31 40 39 51 not enrolled ## 6 51 female high public general 42 36 42 31 39 not enrolled ## awards cid ## 1 0 1 ## 2 0 1 ## 3 0 1 ## 4 0 1 ## 5 0 1 ## 6 0 1 今回も、general, academic, vocation の3つの授業の中から生徒が選択した結果(prog)を出力（目的変数）、write(書く力を得点化したもの)と家庭の経済状況の指標ses(low, middle, highに分類)の2変数を入力(説明変数)とし、モデルを組み立てていきます。 多項ロジスティック・ガウス過程モデル モデルの確認 出力を$(N×1)$ベクトル$\\mathrm{y}=(y_1,\\ldots,y_N)^T$、入力を$(N×(I+J))$行列$\\mathrm{W}=(\\mathrm{w}_1,\\ldots, \\mathrm{w}_N)^T$とします。 $$ \\mathrm{w}_n = (\\mathrm{x}_n^T,\\mathrm{z}_n^T) \\tag{1} $$ $\\mathrm{x}_n$、$\\mathrm{z}_n$はそれぞれ要素数$I$の質的変数、要素数$J$の質的変数です。 $$ \\left(x_{n1},\\ldots,x_{nI}\\right)^T=\\mathrm{x}_{n} $$ $$ \\left(z_{n1},\\ldots,w_{nJ}\\right)^T=\\mathrm{w}_{n} $$ $\\mathrm{y}$が$K$個の値をとるとき、$\\mathrm{y}$が各値をとる確率を表す$(N×K)$行列$\\mathrm{\\Theta}=(\\mathrm{\\theta}_1, \\ldots, \\mathrm{\\theta}_K)$を導入します。 ここで$(\\theta_{k1},\\ldots,\\theta_{kN})^T=\\mathrm{\\theta}_k~~~(k=1,\\ldots,K)$です。 $$ \\mathrm{y} \\sim \\rm{Categorical}(\\Theta)\\tag{2} $$ $\\Theta$は1行の要素の和をとると1になるので、各要素が$(-\\infty,\\infty)$の値をとる$(N×K)$行列$\\mathrm{P}=(\\mathrm{p}_1,\\ldots,\\mathrm{p}_K)$を導入し、下記のようにします。 ここで、$(p_{k1},\\ldots,p_{kN})^T=\\mathrm{p}_k~~(k=1,\\ldots,K)$です。 $$ (\\theta_{1n},\\ldots,\\theta_{Kn})^T = \\rm{softmax}(\\mathrm{P}_n^T)~~~(n=1,\\ldots,N) \\tag{3} $$ ここで$(p_{1n},p_{2n},\\ldots,p_{Kn})=\\mathrm{P}_n$です。 ガウス過程で推定する対象は、上記モデルの$\\mathrm{P}$になります。多項ロジスティック回帰では、出力が任意の特定の値をとる確率を固定する必要があったので、それを踏まえて下記のようにおきます。 $$ \\mathrm{p}_k = \\begin{cases} 0~~~\\mathrm{if}~k=1\\\\ \\mathrm{L}\\eta_k~~~\\mathrm{if}~k=2,\\ldots,K \\end{cases}\\tag{4} $$ $$ \\mathrm{LL^T} = \\mathrm{K}\\tag{5} $$ $$ \\eta_k=(\\eta_{k1},\\ldots,\\eta_{kN}) \\sim \\rm{Normal}(0,1) ~~(k=2,\\ldots,K)\\tag{6} $$ ここで、$\\mathrm{K}$は$(N×N)$のカーネル行列で、$(m,n)$成分をカーネル関数$k(\\mathrm{w}_m,\\mathrm{w}_n)$とします。カーネル関数の設定を工夫することで、線形モデルから得られた知見やデータの特徴(カテゴリカル変数が含まれる点)などをモデルに反映させていきます。 カーネル関数の設定方法 本記事では2つのカーネル関数を設定し、2段階に分けて多項ロジスティック回帰・ガウス過程モデルを実行します。 モデル１ 線形カーネル + isotropic correlationカーネル 量的変数writeの影響は線形カーネルで取り入れ、カテゴリカル変数sesの影響をPDUDEである$\\mathrm{T}$で考慮する、という構造です。$\\mathrm{T}$の各要素はisotropic correlation functionで出力されます。 このカーネル関数をロジスティック回帰・ガウス過程モデルに用いることで、これまでの記事(1)、(2)で得られた結果と同じ結果が得られることを確認し、モデルの妥当性チェックを行います。 カーネル関数は下になります。 $$ \\theta_1\\sum_{i=1}^{I}x_{mi}x_{ni} + \\theta_2\\sum_{j=1}^J\\mathrm{T}(z_{nj},z_{mj}) = k(\\mathrm{w}_m,\\mathrm{w}_n) \\tag{7} $$ ここで、 $$ \\mathrm{T} = \\left( \\begin{array}{ccc} 1 \u0026amp; c \u0026amp; \\cdots \u0026amp; c \\\\ c \u0026amp; 1 \u0026amp; \\cdots \u0026amp; c \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ c \u0026amp; c \u0026amp; \\cdots \u0026amp; 1 \\end{array} \\right)\\tag{8} $$ は、前回の記事の式$(22)$、$(23)$あたりで説明したものす。 ハイパーパラメータは$\\theta_1$、$\\theta_2$、$c$の3つです。 なお、$(7)$式第一項の線形カーネルの部分は、ガウス過程として扱わないで前回の記事の式$(1\u0026rsquo;)$の$\\beta\\mathrm{f}(\\mathrm{w})$で扱うこともできるのですが、今回はフルガウス過程で実行してみます。 モデル２ 線形カーネル + (ガウスカーネル × isotropic correlationカーネル) 量的変数writeの影響をモデル１のように線形的に把握するだけでなく、線形モデルでは誤差として扱われてしまう要素まで結果に取り入れるため、線形カーネルとガウスカーネルを組み合わせて量的変数の影響を予測します。質的変数の影響はモデル１と同様にisotropic correlationカーネルで予測します。 カーネル関数は下になります。 $$ \\theta_1\\sum_{i=1}^{I}x_{mi}x_{ni} +\\theta_2\\rm{exp}\\left(-\\cfrac{1}{2\\rho^2}\\sum_{i=1}^{I}(x_{im}-x_{in})^2-\\sum_{j=1}^{J}\\rm{ln}\\left(\\cfrac{1}{c}\\right)I[r\\neq{s}]\\right)　\\tag{9} $$ ハイパーパラメータは$\\theta_1$,$\\theta2$,$\\rho$,$c$の4つです。 モデル１の実装と結果の確認 モデル１を実行するStanコードを以下のようになります。 //model2 data{ int\u0026lt;lower=2\u0026gt; K; //カテゴリ数 int\u0026lt;lower=1\u0026gt; N1; //データ数 int N2; //予測入力数 int\u0026lt;lower=1\u0026gt; I; //量的変数の数 int\u0026lt;lower=1\u0026gt; J; //質的変数の数 int M[J]; //各質的変数のカテゴリ数 int\u0026lt;lower=1, upper=K\u0026gt; y[N1]; //出力ラベル int\u0026lt;lower=1, upper=max(M)\u0026gt; x1_j[N1,J]; //入力(質的変数) vector[I] x1_i[N1];//入力(量的変数) int\u0026lt;lower=1, upper=max(M)\u0026gt; x2_j[N2,J]; //予測したい点(質的変数) vector[I] x2_i[N2]; //予測したい点(量的変数) } transformed data{ real delta = 1e-9; int\u0026lt;lower=1\u0026gt; N = N1 + N2; int\u0026lt;lower=1, upper=max(M)\u0026gt; x_j[N,J]; //入力(質的変数)と予測入力(質的変数)を縦に繋げたもの vector[I] x_i[N]; //入力(量的変数)と予測入力(量的変数)を縦に繋げたもの //以下でx1_iとx2_i,x1_jとx2_jを縦に結合し、新たな行列x_i,x_jをそれぞれ作成する for(n in 1:N1){ for(j in 1:J){ x_j[n,j] = x1_j[n,j]; } } for(n in 1:N2){ for(j in 1:J){ x_j[(N1+n),j] = x2_j[n,j]; } } for(n in 1:N1) x_i[n] = x1_i[n]; for(n in 1:N2) x_i[N1+n] = x2_i[n]; } parameters{ vector[N] eta[(K-1)]; //潜在変数 vector\u0026lt;lower=0\u0026gt;[2] theta; vector\u0026lt;lower=0, upper=1\u0026gt;[J] C; } transformed parameters{ vector[N] f[(K-1)]; row_vector[K] p[N]; //ソフトマックス関数に投げる値 //この中でカーネル関数を定義、ガウス過程の関数fを作成 { matrix[N,N] L_K[(K-1)]; matrix[N,N]linear_kernel; matrix[N,N]isotropic_correlation_kernel = rep_matrix(0,N,N);//初期値を0に設定。 matrix[N,N] kernel_matrix[(K-1)]; matrix[max(M),max(M)] PDUDE[J]; //compound symmetric correlation matrix を作成 for(j in 1:J){ for(n in 1:(max(M)-1)){ PDUDE[j][n,n] = 1; for(m in (n+1):max(M)){ PDUDE[j][n,m] = C[j]; PDUDE[j][m,n] = PDUDE[j][n,m]; } } PDUDE[j][max(M),max(M)] = 1; } //isotropic_correlation_kernelを生成 for(j in 1:J){ for(n in 1:N){ for(m in 1:N){ isotropic_correlation_kernel[n,m] += PDUDE[j][x_j[n,j],x_j[m,j]]; } } } //linear_kernel_matrixを生成。切片項はisotropic_correlation_kernelで捉えることにした for(n in 1:N){ for(m in1:N){ linear_kernel[n,m] = dot_product(x_i[n],x_i[m]); } } //kernel_matrixを作成 for(k in 1:(K-1)){ kernel_matrix[k] = theta[1] * linear_kernel + theta[2] * isotropic_correlation_kernel; for(n in 1:N){ kernel_matrix[k][n,n] += delta; } } for(k in 1:(K-1)){ L_K[k] = cholesky_decompose(kernel_matrix[k]); f[k] = L_K[k] * eta[k]; } } // pの作成 1列目は0に固定 2列目以降に独立のガウス過程を指定 for(n in 1:N){ p[n,1] = 0; for(k in 1:(K-1)){ p[n,(k+1)] = f[k,n]; } } } model{ //事前分布 theta ~ student_t(4,0,2); C ~ normal(0,0.1); //モデル部分 for(k in 1:(K-1)){ for(n in 1:N){ eta[k,n] ~ std_normal(); } } for(n in 1:N1){ y[n] ~ categorical_logit(p[n]\u0026#39;); } } generated quantities{ vector[K] pred[N2]; for(n in 1:N2){ pred[n] = softmax(p[(N1+n)]\u0026#39;); } } 入力データを命令するdata{}ブロックでは、入力データ(x1_i、x1_j)を量的変数・質的変数で分けて指定しています。また、予測したい入力点(x2_i、x2_j)も指定しています。 transformes data{}ブロックでは、式$(12)$の計算を実行するため、入力(実現値)と予測したい入力点のデータを量的変数・質的変数毎に縦に繋げています。 transformed parameter{}ブロックでは、まず、式$(8)$の行列をPDUDEという呼称で作成しています。次に、issotropic_correlation_kernelとして、PDUDEを参照しながらcompound symmetric correlation matrixを作成しています。 また、linear_kernelとして線形カーネルの要素を作成しています。線形カーネルはStanに実行されたdot_product()が便利です。 さらに、kernel_matrixとして式$(7)$のカーネル関数を各要素に持つカーネル関数を作成します。 このように、線形カーネル・isotropic_correlation_kernelカーネルを作成し、それらを結合させてカーネル行列を作成し、最後に既述の方法でガウス過程に従う$\\mathrm{f}$の定義までをtransformed parameter{}で命令しています。 model{}ブロックでは、まず事前分布を式$(7)$の$\\theta_1$、$\\theta_2$、式$(8)$の$c$で、適当に指定しています。 また、前回記事式$(9)$中段の設定をeta ~ std_normal()として指定し、多項ロジスティック回帰モデルの式$(2)$、式$(3)$をy[n] ~ categorical_logit(p[n]')としています。 generated quantities{}ブロックでは、modelブロックでは作成しなかった入力点x2_i、x2_jにおける予測値をpredとして指定しています。 このStanファイルを実行するコードは以下になります。 # progの3要素を数字に置き換えるための表を作成 progid \u0026lt;- c(1,2,3) names(progid) \u0026lt;- c(\u0026#34;academic\u0026#34;,\u0026#34;general\u0026#34;,\u0026#34;vocation\u0026#34;) # sesの3要素を数字に置き換えるための表を作成 sesid \u0026lt;- c(1,2,3) names(sesid) \u0026lt;- c(\u0026#34;low\u0026#34;,\u0026#34;middle\u0026#34;,\u0026#34;high\u0026#34;) library(makedummies) library(tidyr) library(dplyr) d2 \u0026lt;- ml %\u0026gt;% mutate(sesid = sesid[paste(ses)]) %\u0026gt;% mutate(progid = progid[paste(prog)]) %\u0026gt;% mutate(write=(write-mean(write))/sd(write)) %\u0026gt;% select(c(sesid, write, progid)) #x1:入力点 x1_j \u0026lt;- data.frame(d2[,-c(2,3)]) # 入力(質的変数) x1_i \u0026lt;- data.frame(d2[,-c(1,3)]) # 入力(量的変数) N1 \u0026lt;- nrow(x1_i) #x2:予測入力点 x2_j \u0026lt;- data.frame(sesid = c(rep(1,41),rep(2,41),rep(3,41))) # 予測入力点(質的変数) x2_i \u0026lt;- data.frame(write = (rep(c(30:70),3)-mean(ml$write))/sd(ml$write)) # 予測入力点(量的変数) N2 \u0026lt;- nrow(x2_i) #y:出力点 y \u0026lt;- d2[,3] K \u0026lt;- 3 J \u0026lt;- 1 #質的変数の数 I \u0026lt;- 1 #量的変数の数 M \u0026lt;- c(3) #各量的変数のカテゴリ数 dim(M) \u0026lt;- 1 data \u0026lt;- list(x1_i=x1_i,x1_j=x1_j,x2_i = x2_i,x2_j=x2_j,N1=N1,N2=N2,K=K,y=y,J=J,I=I, M=M) rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores()) fit_cate1 \u0026lt;- stan(file=\u0026#34;model2.stan\u0026#34;, data=data, pars = c(\u0026#34;pred\u0026#34;,\u0026#34;theta\u0026#34;,\u0026#34;C\u0026#34;), warmup = 400, iter = 1500, chains=4, seed=1234) 計算にかかった時間はsurface laptop2 Corei5-8250Uで約3000秒でした。 ガウス過程は逆行列の計算などを含むので、工夫をしないとどうしても計算に時間がかかってしまうようです。 ハイパーパラメータの事後分布は以下のようになりました。 予測結果は以下のようになりました。描画の為のコードは以前の記事を参照してください。 rのパッケージnnetのmultinom()関数を使ったときや、Rstanで線形予測子Versionの多項ロジスティック回帰を実行したときの結果と同じ結果が得られていることが分かります。 以上、sotropic correlationカーネルを含んだモデル全体が正常に動くことを確認し、次の分析に進みます。 モデル２の実装と結果の確認 モデル２を実行するStanコードを以下のようになります。 //model3 data{ int\u0026lt;lower=2\u0026gt; K; //カテゴリ数 int\u0026lt;lower=1\u0026gt; N1; //入力データの数 int N2; //予測したい入力点の数 int\u0026lt;lower=1\u0026gt; I; //量的変数の数 int\u0026lt;lower=1\u0026gt; J; //質的変数の数 int M[J]; //各質的変数のカテゴリ数 int\u0026lt;lower=1, upper=K\u0026gt; y[N1]; //出力ラベル int\u0026lt;lower=1, upper=max(M)\u0026gt; x1_j[N1,J]; //入力(質的変数) vector[I] x1_i[N1];//入力(量的変数) int\u0026lt;lower=1, upper=max(M)\u0026gt; x2_j[N2,J]; //予測した入力点(質的変数) vector[I] x2_i[N2]; //予測したい入力点(量的変数) } transformed data{ real delta = 1e-9; int\u0026lt;lower=1\u0026gt; N = N1 + N2; int\u0026lt;lower=1, upper=max(M)\u0026gt; x_j[N,J]; //入力(質的変数)と予測入力(質的変数)を縦に繋げたもの vector[I] x_i[N]; //入力(量的変数)と予測入力(量的変数)を縦に繋げたもの matrix[max(M),max(M)] inv_I; //対角成分が0、それ以外が1の行列を生成 //以下でx1_iとx2_i,x1_jとx2_jを縦に結合し、新たな行列x_i,x_jをそれぞれ作成する for(n in 1:N1){ for(j in 1:J){ x_j[n,j] = x1_j[n,j]; } } for(n in 1:N2){ for(j in 1:J){ x_j[(N1+n),j] = x2_j[n,j]; } } for(n in 1:N1) x_i[n] = x1_i[n]; for(n in 1:N2) x_i[N1+n] = x2_i[n]; //inv_Iの作成 for(n in 1:(max(M)-1)){ inv_I[n,n] = 0; for(m in (n+1):max(M)){ inv_I[n,m] = 1; inv_I[m,n] = 1; } } inv_I[max(M),max(M)] = 0; } parameters{ vector[N] eta[(K-1)]; //潜在変数 vector\u0026lt;lower=1\u0026gt;[2] //theta;線形カーネルと「ガウスカーネル・isotropic correlationカーネル」の重みを決定するハイパーパラメータ vector\u0026lt;lower=0, upper=1\u0026gt;[J] C; //isotropic correlationカーネルのハイパーパラメータ real\u0026lt;lower=0, upper=0.9\u0026gt; rho; //ガウスカーネルのshapeパラメータ } transformed parameters{ vector[N] f[(K-1)]; row_vector[K] p[N]; //ソフトマックス関数に投げる値 //この中でカーネル関数を定義、ガウス過程に従う関数fを作成 { matrix[N,N] L_K[(K-1)]; //カーネル行列をコレスキー分解した行列L。（出力がとる値）-1の数だけ準備する matrix[N,N]linear_kernel; //線形カーネル matrix[N,N]distance_L2_01_kernel; //。ガウスカーネル×isotropic correlation カーネル。logスケールでL2距離と0-1距離の成分を含んでいる matrix[N,N] kernel_matrix[(K-1)]; //最終的に作成するカーネル関数 //linear_kernelを生成 for(n in 1:N){ for(m in1:N){ linear_kernel[n,m] = dot_product(x_i[n],x_i[m]); } } //distanceL2_01_kernelを生成 { matrix[N,N] distance_L2; //L2距離 matrix[N,N] distance_01 = rep_matrix(0,N,N); //inv_Iに依存した0-1距離 for(n in 1:N){ for(m in 1:N){ distance_L2[n,m] = dot_self((x_i[n]-x_i[m]) ./ rho); } } for(j in 1:J){ for(n in 1:N){ for(m in 1:N){ distance_01[n,m] += log(1/C[j])*inv_I[x_j[n,j],x_j[m,j]]; } } } for(n in 1:N){ for(m in 1:N){ distance_L2_01_kernel[n,m] = exp(-0.5 * distance_L2[n,m] -distance_01[n,m]); } } } //kernel_matrixを作成 for(k in 1:(K-1)){ kernel_matrix[k] = theta[1] * linear_kernel + theta[2] * distance_L2_01_kernel; for(n in 1:N){ kernel_matrix[k][n,n] += delta; } } for(k in 1:(K-1)){ L_K[k] = cholesky_decompose(kernel_matrix[k]); f[k] = L_K[k] * eta[k]; } } // pの作成 1列目は0に固定 2列目以降に独立のガウス過程を指定 for(n in 1:N){ p[n,1] = 0; for(k in 1:(K-1)){ p[n,(k+1)] = f[k,n]; } } } model{ //事前分布 theta ~ student_t(4,1,2); rho ~ inv_gamma(0.1, 0.1); C ~ normal(0, 0.1); //モデル部分 for(k in 1:(K-1)){ for(n in 1:N){ eta[k,n] ~ std_normal(); } } for(n in 1:N1){ y[n] ~ categorical_logit(p[n]\u0026#39;); } } generated quantities{ vector[K] pred[N2]; for(n in 1:N2){ pred[n] = softmax(p[(N1+n)]\u0026#39;); } } モデル１との違いは、transformed parameters{}ブロックにおけるカーネル行列作成の部分と、model{}ブロックにおける事前分布設定の部分になります。 transformed parameters{}ブロックでは、linear_kernelとして式$(9)$第1項の部分（線形カーネル）の$\\theta_1$を除いた部分を、distance_L2_01_kernelとして式$(9)$第2項の$\\theta_2$を除いた部分を作成しています。またdistance_L2_01_kernelは、distance_L2として$\\sum_{i=1}^{I}(x_{im}-x_{in})^2$を、distance_01_kernelとして$\\sum_{j=1}^{J}ln\\left(\\cfrac{1}{c}\\right)I[r\\neq{s}]$をそれぞれ作成し、それらを式$(9)$に従って合成することで作成しています。 ハイパーパラメータの事前分布の設定はかなり苦戦しました。最終的に以下の事前分布を採用しています。 $$ \\theta_1 \\sim \\rm{Student\\verb|_|t}(4,1,2) ~~~\\theta_1 \\geq 1 $$ $$ \\theta_2 \\sim \\rm{Student\\verb|_|t}(4,1,2) ~~~\\theta_2 \\geq 1 $$ $$ \\rho \\sim \\rm{invGamma}(0.1,0.1)~~~0 \\leq \\rho \\leq 0.9 $$ $$ c \\sim \\rm{Normal}(0,0.1) $$ $\\theta_1$、$\\theta_2$については弱情報事前分布として、自由度4、期待値1、スケールパラメータ1の半t分布を採用しています。 $\\rho$については、Stanマニュアルを参照して、0付近の値を避けることができつつも小さな値にとがった山を持ち、かつ十分大きな値にも対応可能な逆ガンマ分布を採用しています。 $c$については、0付近の値をとることが想定されるため、期待値0、標準偏差0.1の切断正規分布を採用しています。 様々な事前分布を試していたのですが、ガウスカーネルにおいて、shapeパラメータ$\\rho$とrateパラメータ$\\theta$の比が重要なようで、shapeパラメータに比べてrateパラメータが十分大きいと、出力値の変化の傾きが小さくなり、前回記事の式$(1)$の誤差項を捉えてくれなくなってしまいます。この点についてはStanマニュアルにも以下の記載があります。 Perhaps most importantly, the parameter $\\rho$ and $\\alpha$ are weakly identified Zhang(2004). The ratio of the rwo parameters is well-identified\u0026hellip; 今回の場合、$\\rho$に値の上限を設定しないとどうしても$\\rho$が大きくなってしまい、予測結果もモデル式１と変わらなくなってしまいました。しかしそれはこのモデルの意図した結果ではありません。 以前の[ガウス過程のシミュレーション結果](https://rmorita-stat.github.io/2020/06/gaussianprocess/# ガウス過程のシミュレーション)を見ると、標準化されたデータの場合、shapeパラメータ、rateパラメータともに1前後でちょうどよいガウス過程からの出力が得られそうであることが確認できます。よって、今回はrateパラメータに0.9の上限を設け、shapeパラメータも下限値1を設定することで、少し変化の傾きが急な出力を得られるように強要することにします。 上記のStanファイルを実行するコードは以下になります。 data \u0026lt;- list(x1_i=x1_i,x1_j=x1_j,x2_i = x2_i,x2_j=x2_j,N1=N1,N2=N2,K=K,y=y,J=J,I=I, M=M) rstan_options(auto_write = TRUE) options(mc.cores = parallel::detectCores()) fit_cate2 \u0026lt;- stan(file=\u0026#34;model3.stan\u0026#34;, data=data, pars = c(\u0026#34;pred\u0026#34;,\u0026#34;rho\u0026#34;,\u0026#34;theta\u0026#34;,\u0026#34;C\u0026#34;), warmup = 400, iter = 1500, chains=4, seed=1234) 計算にかかったた時間は確かおよそ9800秒でした。2時間以上かかっていますね。PCもうなり声をあげていたので冷却対策など必要かもしれません。 ハイパーパラメータの事後分布は以下のようになります。 posterior_fit0_2 \u0026lt;- rstan::extract(fit_cate2) library(bayesplot) plot_title \u0026lt;- ggtitle(\u0026#34;Posterior distribution of hyper parameters\u0026#34;, \u0026#34;with medians and 95% intervals\u0026#34;) p1 \u0026lt;- mcmc_areas(as.matrix(fit_cate2), regex_pars = c(\u0026#34;theta\u0026#34;),prob=0.95, area_method = \u0026#34;equal height\u0026#34;) + scale_y_discrete(labels=c(\u0026#34;theta1\u0026#34;,\u0026#34;theta2\u0026#34;)) + theme_bw(base_size=12) p2 \u0026lt;- mcmc_areas(as.matrix(fit_cate2), regex_pars = c(\u0026#34;C\u0026#34;,\u0026#34;rho\u0026#34;),prob=0.95, area_method = \u0026#34;equal height\u0026#34;) + scale_y_discrete(labels=c(\u0026#34;c\u0026#34;,\u0026#34;rho\u0026#34;)) + theme_bw(base_size=12) library(gridExtra) g1 \u0026lt;- ggplot_gtable(ggplot_build(p1)) g2 \u0026lt;- ggplot_gtable(ggplot_build(p2)) Width \u0026lt;- unit.pmax(g1$widths, g2$widths) Height \u0026lt;- unit.pmin(g1$heights, g2$heights) g1$widths \u0026lt;- Width g2$widths \u0026lt;- Width g1$heights \u0026lt;- Height g2$heights \u0026lt;- Height p \u0026lt;- gridExtra::grid.arrange(g1,g2,ncol=1, top=\u0026#34;Posterior distribution of hyper parameters (with medians and 95% intervals)\u0026#34;) $\\rho$が頑張って大きな値をとろうとしている様子が見えますが、そこは抑えてもらっています。何だかかわいそう\u0026hellip; 最後に、予測結果を描画します。 線形モデルでは読み取ることが出来なかった傾向がうまく捉えられています。例えば、読み書きの能力が50前後のses=lowの生徒はgeneralの授業をとる傾向にあること、読み書きの能力が45前後のses=highの生徒はacademicの授業をとる確率とvocationの授業をとる確率が同程度である様子などが確認できます。 It\u0026rsquo;s so brilliant\u0026gt;🐢 このように、線形モデルでは誤差として結果に反映されなかった事象もうまくとらえることが出来るのがガウス過程の魅力です。パラメータの事後分布や推測値よりデータの生成過程を考察する、という目的には不向きかもしれませんが、予測の観点から見れば非常に便利ではないでしょうか？。 まとめ 今回はガウス過程を多項ロジスティック回帰に取り込んだモデルの実装を行いました。その過程で、ガウス過程潜在変数モデルやカテゴリカルデータを取り入れたガウス過程等、前回の記事で説明したガウス過程の応用手法を用い、それらが正常に機能することを確かめました。 また、ガウス過程のように特定の分布を想定しないで、データに応じてモデルの複雑さを決定するパラメータを調整するベイズモデルはノンパラメトリックベイズモデルと呼ばれています。 この記事で、以前に述べたガウス過程の活用方法の１つ目(下記)を紹介した形です。 一般化線形モデルの線形予測子をガウス過程に置き換え、柔軟なモデルに豹変させる 多項ロジスティック回帰の記事も3つ目になりましたが、これで最後になります。最近はアウトプットに力を注いでいて投稿頻度も多かったですが、今後暫くはインプットに集中したいと考えており、投稿しない月が続くかもしれません。 Enjoy Stan!"
  },
  {
    url: "https://sucre-stat.com/2020/07/gaussianprocess2/",
    title: "ガウス過程の応用",
    date: "2020-07-11T00:00:00Z",
    body: "ガウス過程の応用 はじめに 前回の記事では、特定の分布や関係を仮定せず、与えられたデータに柔軟に対応することのできるモデルということで、ガウス過程回帰について取り上げました。 本記事ではガウス過程をさらに深堀りし、Stanなどでガウス過程を自在に扱うための土台を固めたいと思います。 本記事の構成は以下の通りとします。 はじめに ガウス過程の導入 ガウス過程潜在変数モデル 多変量正規分布のサンプリング ガウス過程潜在変数モデルとは Stanでの実装 ガウス過程の予測分布 カテゴリカルな変数を用いたカーネル 質的変数が1つの場合 質的変数が2つ以上の場合 制約のあるPDUDE まとめ 特に以下2章は力を入れました。 「ガウス過程潜在変数モデル」 Stan等でガウス過程を様々なモデルに活用するために不可欠 「カテゴリカルな変数を用いたカーネル」 質的変数が入力に含まれる場合にも、ガウス過程を適用できるようにするための方法を説明 当初本記事と次回の記事はひとつの記事として公開していましたが、余りにも長すぎる記事だったので、二つに分けました。 ガウス過程の導入 まず、ガウス過程を用いたモデルについて一般化します。 入力の要素数を数を$I$とし、入力データの1サンプルを$\\boldsymbol{x} = (x_1, \\ldots, x_I)^T$と表記し、全入力を$N × I$行列$\\boldsymbol{x}$を用いて$\\boldsymbol{X} = (\\boldsymbol{x}_1 ,\\ldots, \\boldsymbol{x}_N)^T$とおきます。また出力データを$\\boldsymbol{y} = (y_1, \\ldots, y_N)^T$とおきます。 ガウス過程モデルの一般式は以下になります。 $$ y(\\boldsymbol{x}) = \\boldsymbol{\\beta}\\boldsymbol{f}(\\boldsymbol{x}) + \\epsilon(\\boldsymbol{x}) \\tag{1} $$ ここで$\\boldsymbol{f} = (f_1(\\boldsymbol{x}), \\ldots, f_l(\\boldsymbol{x}))$、$\\boldsymbol{\\beta} = (\\beta_1, \\ldots, \\beta_l )$はそれぞれ、ガウス過程モデルとは別で設定された特徴ベクトルとその重みです。これらはガウス過程を適用する以前からデータにあてはめられたモデルになります。 $\\epsilon(\\boldsymbol{x})$は右辺第一項のモデルで説明しきれなかった残差としての扱いですが、この残差がガウス過程に従うと仮定します。ガウス過程モデルは得られたデータに柔軟に近づこうとする挙動をとりますので、この性質を利用して右辺第一項で説明できなかった部分をガウス過程で補おうという目論見です。 各入力の誤差項が同じ標準偏差$\\sigma$をとると設定できたとき、$\\boldsymbol{\\epsilon}(\\boldsymbol{x}) = \\left(\\epsilon(\\boldsymbol{x}_1), \\ldots, \\epsilon(\\boldsymbol{x}_N)\\right)$が以下のガウス過程に従うとします。 $$ \\boldsymbol{\\epsilon}(\\boldsymbol{x}) \\sim \\mathrm{Normal}(0, \\sigma^2\\boldsymbol{K}) \\tag{2} $$ 上式では$\\epsilon$が残差を説明するものであることから多変量正規分布の平均を0としています。また分散共分散行列$\\boldsymbol{K}$は、ハイパーパラメータ${\\phi}$を持つカーネル関数$k_{\\phi}(\\boldsymbol{x}_m, \\boldsymbol{x}_n)$を要素に持つ$N$×$N$行列です($m,n = 1,\\ldots,N$)。 $$ \\boldsymbol{K}(m,n) = k_{\\phi}(\\epsilon(\\boldsymbol{x}_m), \\epsilon(\\boldsymbol{x}_n)) \\tag{3} $$ 各入力の標準偏差を$\\sigma$で設定している為、$\\boldsymbol{K}$の$(m,n)$成分は、$\\epsilon(\\boldsymbol{x}_m)$と$\\epsilon(\\boldsymbol{x}_n)$の相関に等しくなり、 $$ k_{\\phi}(\\epsilon(\\boldsymbol{x}_m), \\epsilon(\\boldsymbol{x}_n)) = \\mathrm{cor}(\\epsilon(\\boldsymbol{x}_m), \\epsilon(\\boldsymbol{x}_n)) \\tag{4} $$ となります。 ガウス過程では、カーネル関数によって$\\boldsymbol{x}_m$と$\\boldsymbol{x}_n$の距離を定める空間を決定し、入力$\\boldsymbol{x}_m$と$\\boldsymbol{x}_n$の距離によって出力$\\epsilon(\\boldsymbol{x}_m)$と$\\epsilon(\\boldsymbol{x}_n)$の近さを決定します。また、カーネル関数によって決まる値は、$\\mathrm{cor}(\\epsilon(\\boldsymbol{x}_m),\\epsilon(\\boldsymbol{x}_n))$と解釈することができる、ということです。 ガウス過程潜在変数モデル 多変量正規分布のサンプリング $(2)$式で用いられる多変量正規分布について、ランダムにサンプルを得る方法を紹介します。 平均0、分散共分散行列$\\boldsymbol{\\Sigma}$の多変量正規分布からのサンプルを得る場合、まず $$ \\boldsymbol{\\Sigma} = \\boldsymbol{L}\\boldsymbol{L}^T \\tag{5} $$ を満たす行列$\\boldsymbol{L}$を求めます。$(4)$式のような行列の分解はコレスキー分解と呼ばれます。 次に、標準正規分布からの乱数$\\boldsymbol{x} = (x_1, \\ldots, x_N)$を生成します。 $$ \\boldsymbol{x} \\sim \\mathrm{Normal}(0,1) \\tag{6} $$ $\\boldsymbol{y} = \\boldsymbol{L}\\boldsymbol{x}$の分布は、 $$\rp(\\boldsymbol{x}) = \\cfrac{1}{(\\sqrt{2\\pi}^N \\sqrt{\\mathrm{det}\\boldsymbol{\\Sigma}})}\\exp\\left(-\\cfrac{1}{2}(\\boldsymbol{x}^T \\boldsymbol{I}^{-1} \\boldsymbol{x}) \\right) \\propto \\exp\\left(-\\cfrac{1}{2}\\boldsymbol{x}^T\\boldsymbol{I}^{-1}\\boldsymbol{x}\\right) \\tag{7}\r$$\r に$\\boldsymbol{x} = \\boldsymbol{L}^{-1}\\boldsymbol{y}$を代入すると、変数変換による空間の単位当たり面積の変動を調整するヤコビアン$|\\partial{\\boldsymbol{y}}/\\partial{\\boldsymbol{x}}|$は定数だから、 $$\rp(\\boldsymbol{Lx}) \\propto \\exp\\left(-\\cfrac{1}{2}\\left(\\boldsymbol{L}^{-1}\\boldsymbol{y}\\right)^T \\boldsymbol{I}^{-1}\\boldsymbol{L}^{-1}\\boldsymbol{y}\\right)\r\\left|\\cfrac{\\partial{\\boldsymbol{y}}}{\\partial{\\boldsymbol{x}}}\\right|\r= \\exp\\left(-\\cfrac{1}{2}\\boldsymbol{y}^{-1}\\left(\\boldsymbol{L}^{-1}\\right)^T\\boldsymbol{L}^{-1}\\boldsymbol{y}\\right)\r= \\exp\\left(-\\cfrac{1}{2}\\boldsymbol{y}^{-1}\\left(\\boldsymbol{L}\\boldsymbol{L}^T\\right)^{-1}\\boldsymbol{y}\\right)\r= \\exp\\left(-\\cfrac{1}{2}\\boldsymbol{y}^T\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{y}\\right) \\tag{8}\r$$\r となります。 このことから、$\\mathrm{Normal} (0,\\boldsymbol{\\Sigma})$に従う乱数を生成するには、標準正規分布に従う$\\boldsymbol{x}$をランダムに生成し、$\\boldsymbol{y}=\\boldsymbol{Lx}$と変換すればよいと分かります。 ガウス過程潜在変数モデルとは モデルの残差$\\epsilon(\\boldsymbol{x})$がガウス過程に従うとした$(2)$式を、先ほど紹介した多変量正規分布の乱数生成法を用いて変形すると、 $$ \\boldsymbol{K} = \\boldsymbol{L}\\boldsymbol{L}^T $$ $$ \\boldsymbol{\\eta} \\sim \\rm{Normal}(0,1) \\tag{9} $$ $$ \\boldsymbol{\\epsilon}({\\boldsymbol{x}}) = \\boldsymbol{L}\\boldsymbol{\\eta} $$ となります。（$\\boldsymbol{\\eta} = (\\eta_1, \\ldots, \\eta_n)$） このように、潜在変数$\\boldsymbol{\\eta}$を用いたガウス過程は、ガウス過程潜在変数モデル(Latent variable GP)と呼ばれ、出力が正規分布でないとき等に有用です。 Stanでの実装 以下、Stanマニュアルを引用してLatent variable GPの実装について軽く触れておきます。 Latent variable GPのStanでの実装は以下のようになります。 data{ int\u0026lt;lower=1\u0026gt; N; real x[N]; vector[N] y; } transformed data{ real delta = 1e-9; } parameters { real\u0026lt;lower=0\u0026gt; rho; real\u0026lt;lower=0\u0026gt; alpha; real\u0026lt;lower=0\u0026gt; sigma; vector[N] eta; } model { vector[N] f; { matrix[N, N] L_K; matrix[N, N] K = cov_exp_quad(x, alpha, rho); // diagonal elements for (n in 1:N) K[n, n] = K[n, n] + delta; L_K = cholesky_decompose(K); f = L_K * eta; } eta ~ std_normal(); y ~ normal(f, sigma); } ここで、K = cov_exp_quad(x, alpha, rho)はガウスカーネルをつくる便利な関数で、 $$\r\\boldsymbol{K}(m,n) =k_{\\alpha, \\rho}(\\epsilon(\\boldsymbol{x}_m),\\epsilon(\\boldsymbol{x}_n))\r=\\alpha^2 \\exp\\left(-\\cfrac{1}{2\\rho^2}\\sum_{i=1}^{I}(\\boldsymbol{x}_{m,i}-\\boldsymbol{x}_{n,i})^2\\right) \\tag{10}\r$$\r を要素に持つカーネル行列$\\boldsymbol{K}$を作成してくれます。 また、for (n in 1:N) K[n, n] = K[n, n] + delta;とすることで、カーネル行列の対角要素に微小な値を加えていますが、こうすることでカーネル行列の逆行列の計算を安定化させています。また、コレスキー分解はその対象が正定値行列であることが必須ですが、対角要素に微小量を加えることで、その行列が正定値行列であることを保証することができます。 式$(9)$の3式の計算は、それぞれL_K = cholesky_decompose(K);、eta ~ std_normal();、f = L_K * eta;と指定しています。 上のコードでは、残差ではなく出力$\\boldsymbol{y}$の平均値が$\\boldsymbol{f} \\sim \\mathrm{Normal}(0, \\boldsymbol{K}_{\\phi})$に従うと設定し、y ~ Normal(f, sigma)とすることで、平均$\\boldsymbol{f}$の正規分布に従うと設定していますが、この部分をポアソン分布等他の分布にすることで、様々なモデルを構築することが出来ます。 例えば、0か1のみをとる出力$\\boldsymbol{y}$にベルヌーイ分布を仮定し、$y_n=1$となる確率$\\boldsymbol{p} = (p_1, \\dots, p_N)$を、入力$\\boldsymbol{x}_n$のガウス過程を用いて説明する場合、 $$ \\boldsymbol{y} \\sim \\mathrm{Binomial}(\\boldsymbol{p}) $$ $$ \\boldsymbol{p} =\\mathrm{inverselogit}(\\boldsymbol{f})　\\tag{11} $$ $$ \\boldsymbol{f} \\sim \\mathrm{Normal}(\\mu, \\boldsymbol{K}) $$ と表現でき、これをStanで実行する場合、以下のようになります。 data{ int\u0026lt;lower=1\u0026gt; N; real x[N]; vector[N] y; ... } parameters{ real mu; //muはpの期待値 観測データが近くに無い場合に漸近する値 ... } transformed parameters{ vector[N]\u0026lt;lower=0, upper=1\u0026gt; p; ... p = mu + f; ... } ... model { mu ~ std_normal() ... y ~ bernoulli(p); } ガウス過程の予測分布 ガウス過程モデルにおいて、入力$\\boldsymbol{x}$に含まれない値$\\boldsymbol{X}^* = (\\boldsymbol{x}^*_1,\\ldots,\\boldsymbol{x}_N^*)$に対応する出力の値$\\boldsymbol{y}^* = (y^*_1, \\ldots, y^*_M)$を予測したい場合、$\\boldsymbol{y}$と$\\boldsymbol{y}^*$の同時分布を次のようにすればよいです。 $$ \\left( \\begin{array}{ccc} y_1 \\\\ \\vdots \\\\ y_N \\\\ y_1^* \\\\ \\vdots \\\\ y_M^* \\end{array} \\right) \\sim \\rm{Normal} \\left(\\vec{0}, \\left( \\begin{array}{ccc} \\boldsymbol{K} \u0026amp; \\boldsymbol{k}^* \\\\ \\boldsymbol{k}^{*T} \u0026amp; \\boldsymbol{k}^{**} \\\\ \\end{array} \\right)\\right) \\tag{12} $$ ここで、$\\boldsymbol{k}^*(n,m) = k_{\\phi}(\\boldsymbol{x}_n, \\boldsymbol{x}^*_m)$、$\\boldsymbol{k}^{**}(m,m) = k_{\\phi}(\\boldsymbol{x}_m^*, \\boldsymbol{x}^*_m)$です。 カテゴリカルな変数を用いたカーネル 前回記事も含めこれまでは連続型変数を扱うことを前提にしていましたが、連続的な値をとらず、絶対的な大小関係ももたない質的変数（カテゴリカルな変数）が入力に含まれる場合、量的変数と質的変数の両方の性質を考慮した空間を定義することのできるカーネルを設定する必要があります。しかし、質的変数には「距離」の概念が無いため、ガウスカーネル等のように、各入力の「近接性」を再現するカーネルで対応することはできません。では、どのようにカーネル関数を設定すればよいのでしょうか。 質的変数が1つの場合 まず、量的変数と質的変数を含んだ入力を$\\boldsymbol{w} = (\\boldsymbol{x}^T, \\boldsymbol{z}^T)^T$とし、$\\boldsymbol{x} = (x_1, \\ldots, x_I)$を量的変数、$\\boldsymbol{z} = (z_1, \\ldots, z_J)$を質的変数とします。それに従い、$(1)$式、$(2)$式を $$ y(\\boldsymbol{w}) = \\boldsymbol{\\beta}\\boldsymbol{f}(\\boldsymbol{w}) + \\epsilon(\\boldsymbol{w}) \\tag{1\u0026rsquo;} $$ $$ \\epsilon(\\boldsymbol{z}) \\sim \\mathrm{Normal}(0, \\sigma^2\\boldsymbol{K}) \\tag{2\u0026rsquo;} $$ としておきます。 簡略のため、$m_1$個の値をとる一つの質的変数$z_1$について考えます。 $\\boldsymbol{w}= (\\boldsymbol{x}^T, z_1) = (\\boldsymbol{x}^T, u)$($u = 1,\\ldots,m_1$)における$\\boldsymbol{\\epsilon}(\\boldsymbol{x})$を、 $$ \\boldsymbol{\\epsilon}^*(\\boldsymbol{x}) = \\left( \\begin{array}{ccc} \\epsilon_1(\\boldsymbol{x}) \\\\ \\vdots \\\\ \\epsilon_{m_1}(\\boldsymbol{x}) \\end{array} \\right) \\tag{13} $$ と定義します。すると、量的変数については$\\boldsymbol{\\epsilon}^*(\\boldsymbol{x})$の各要素内でのガウス過程で完結させ、質的変数の影響については、$\\boldsymbol{\\epsilon}^*(\\boldsymbol{x})$の各要素間の分散共分散行列を決定すれば、量的変数・質的変数双方の差異を考慮した相関関数$\\mathrm{cor}(\\epsilon(\\boldsymbol{w}_m),\\epsilon(\\boldsymbol{w}_n))$を指定できそうです。そこで、$\\boldsymbol{\\epsilon}^*(\\boldsymbol{x})$を $$ \\boldsymbol{\\epsilon}^*(\\boldsymbol{x}) = \\boldsymbol{A}\\boldsymbol{\\eta}(\\boldsymbol{x}) \\tag{14} $$ と推定することにします。 ここで、$\\boldsymbol{\\eta}(\\boldsymbol{x}) = (\\eta_1(\\boldsymbol{x}), \\ldots, \\eta_{m1}(\\boldsymbol{x}))^T$は量的変数における「距離」を考慮する部分で、各要素がそれぞれ独立に、標準偏差$\\sigma$、相関関数$\\boldsymbol{K}$のガウス過程に従って生成されるものとします。 また、$m_1×m_1$行列$\\boldsymbol{A}$は質的変数の影響を考慮する部分で、単位行ベクトル$\\boldsymbol{a}_u$($\\boldsymbol{a}_u\\boldsymbol{a}_u^T = 1$、$u = 1, \\ldots, m_1$)を用いて $$ \\boldsymbol{A} = \\left( \\begin{array}{ccc} \\boldsymbol{a} _ 1 \\\\ \\vdots \\\\ \\boldsymbol{a} _ {m1} \\end{array} \\right) \\tag{15} $$ とし、$\\epsilon_i(\\boldsymbol{x})$($i = 1,\\ldots, m_1$)を単位行ベクトル$\\boldsymbol{a}_i$の指定する重みに基づく$\\boldsymbol{\\eta}(\\boldsymbol{x})$の要素の線形和で表現することにします。 すると、 $$\r\\mathrm{cor}(\\eta_{z_1m}(\\boldsymbol{x}_n),\\eta_{z_1n}(\\boldsymbol{x}_m))=\\left(\r\\begin{array}{ccc}\rk_{\\phi}(\\boldsymbol{x}_m,\\boldsymbol{x}_n)\u00260\u0026\\cdots\u00260 \\\\\\\\\r0\u0026k_{\\phi}(\\boldsymbol{x}_m,\\boldsymbol{x}_n)\u0026\\cdots\u00260\\\\\\\\\r\\vdots\u0026 \\vdots\u0026 \\ddots\u0026 \\vdots \\\\\\\\\r0\u00260\u0026\\cdots\u0026k_{\\phi}(\\boldsymbol{x}_m,\\boldsymbol{x}_n)\r\\end{array}\r\\right) \\tag{16}\r$$\r ($\\eta_{i}(\\boldsymbol{x}_n)$、$\\eta_{i\u0026rsquo;}(\\boldsymbol{x}_m)$は$i=i'$のときのみ$k_{\\phi}(\\boldsymbol{x}_m,\\boldsymbol{x}_n)$の相関をとる)だから、2つの入力$\\boldsymbol{w}_i = (\\boldsymbol{x}_i^T, z_i)^T$($i=m,n$)の相関関数$\\rm{cor}(\\epsilon(\\boldsymbol{w}_m), \\epsilon(\\boldsymbol{w}_n))$について、 $$\r\\boldsymbol{a}_{z_1m}\\boldsymbol{a}_{z_1n}^Tk_{\\phi}(\\boldsymbol{x}_m, \\boldsymbol{x}_n)=\r\\mathrm{cor}(\\boldsymbol{a}_{z_1m}\\boldsymbol{\\eta}(\\boldsymbol{x}_m),\\boldsymbol{a}_{z_1n}\\boldsymbol{\\eta}(\\boldsymbol{x}_n))=\r\\mathrm{cor}(\\epsilon_{z_1m}(\\boldsymbol{x}_m),\\epsilon_{z_1n}(\\boldsymbol{x}_n))=\r\\mathrm{cor}(\\epsilon(\\boldsymbol{w}_m),\\epsilon(\\boldsymbol{w}_n))\\tag{17}\r$$\r が成り立ちます($zm,zn = 1, \\ldots,m_1$)。 ここで、$\\tau_{r,s} = \\boldsymbol{a}^T_r\\boldsymbol{a}_s$($r=zm, s=zn, r,s=1,\\ldots,m_1,$)とおくと、半正定値行列$\\boldsymbol{T} = \\boldsymbol{A}\\boldsymbol{A}^T$は、 $$\r\\boldsymbol{T} = \\boldsymbol{A}\\boldsymbol{A}^t =\r\\left(\r\\begin{array}{ccc}\ra_1 \\\\\\\\\r\\vdots \\\\\\\\\ra_{m1}\r\\end{array}\r\\right)\r\\left(\r\\begin{array}{ccc}\ra_1 \u0026\r\\ldots \u0026\ra_{m1}\r\\end{array}\r\\right)=\r\\left(\r\\begin{array}{ccc}\r1 \u0026 a_1a_2^T \u0026 \\cdots \u0026 a_1a_{m1}^T \\\\\\\\\ra_2a_1^T \u0026 1 \u0026 \\cdots \u0026 a_2a_{m1}^T \\\\\\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\\ra_{m1}a_1^T \u0026 a_{m1}a_{m2}^T \u0026 \\cdots \u0026 1\r\\end{array}\r\\right) \\tag{18}\r$$\r と、$\\tau_{r,s}$を$(r,s)$成分にもつ対角成分が1の行列(positive definite matrix with unit diagonal elements)になります。 以降、この性質をもつ行列をPDUDEと書きます。 以上のことから、 $$ \\boldsymbol{T}(r,s)k_{\\phi}(\\boldsymbol{x}_m,\\boldsymbol{x}_n)=\\rm{cor}(\\epsilon(\\boldsymbol{w}_m),\\epsilon(\\boldsymbol{w}_n)) \\tag{19} $$ は、質的変数と量的変数の影響を考慮することのできる相関関数ととらえることができます。 質的変数が2つ以上の場合 一般的なケースとして、$J$個の質的変数$\\boldsymbol{z}=(z_1,\\ldots,z_J)^T$の場合を考えます。 ここで、$z_j(j=1,\\ldots,J)$は$1,\\ldots,m_j$の値をとるものとします。すると、式$(19)$の拡張により、$\\epsilon(\\boldsymbol{w})$の相関は関数は以下のようになります。 $$ \\prod_{j=1}^{J}\\left( \\tau_{z_{j,r,s}}k_{\\phi}(\\boldsymbol{x}_m,\\boldsymbol{x}_n) \\right)=\\rm{cor}(\\epsilon(\\boldsymbol{w}_m),\\epsilon{\\boldsymbol{w}_n}) \\tag{20} $$ $\\tau_{j,r,s}$は、$J$番目のPDUDE$\\boldsymbol{T}_j$の$(r,s)$成分です。 特に、$k_{\\phi}(\\boldsymbol{x}_m,\\boldsymbol{x}_n)$に式$(10)$のガウスカーネルをもちいた場合、$(20)$式は以下のようになります。 $$\r\\prod_{j=1}^{J}\\left( \\tau_{z_{j,r,s}}k_{\\phi}(\\boldsymbol{x}_m,\\boldsymbol{x}_n) \\right)=\r\\prod_{j=1}^{J}\\left(\\tau_{z_{j,r,s}}\\exp\\left(-\\cfrac{1}{2\\rho^2}\\sum_{i=1}^{I}(x_{im},x_{in})^2\\right)\\right)=\r\\left(\\prod_{j=1}^{J}\\tau_{z_{j,r,s}}\\right)\\exp\\left(-\\cfrac{1}{2\\rho^2}\\sum_{i=1}^{I}(x_{im}-x_{in})^2\\right) \\tag{21}\r$$\r 式$(21)$は、量的変数の影響は$exp\\left(-\\cfrac{1}{2\\rho^2}\\sum_{i=1}^{I}(x_{im}-x_{in})^2\\right)$で考慮し、質的変数の影響はそれとは独立に$\\left(\\prod_{j=1}^{J}\\tau_{z_{j,r,s}}\\right)$で考慮する、という構造を持っています。パラメータ$\\tau_{z_{j,r,s}}$は、質的変数$z_j$について$r=z_jm$をとる入力$\\boldsymbol{w}_m$と、$s=z_jn$をとる入力$\\boldsymbol{w}_n$の、$z_j$のみによる共通性(相関)への影響を反映する役割を担っています。なお、式$(21)$ではshapeパラメータ$\\alpha^2$を考慮していませんが、これは$(2)$式でshapeパラメータの役割を$\\sigma$が受け持っている為です。 モデリングにおいては、$\\tau_{z_{j,r,s}}$は正の値をとるように設定し、任意の2点の入力が無相関もしくは正の相関のみをとるようにします。 制約のあるPDUDE 前節では、PDUDEについて制約を設けない相関行列を用いていました。柔軟なモデリングにおいてはこれで問題ないのですが、質的変数が順序尺度であったり、カテゴリカルな変数であったりするということがあらかじめ自明な場合は、PDUDEに制約を持たせることで、その情報をモデルに反映させることができます。ここでは、sesがカテゴリカルな変数であることから、質的変数がカテゴリカルな場合にPDUDEに設ける制約について説明します。 結論からですが、$m$個の値をとる$z$がカテゴリカルな場合、下記の$\\tau_{r,s}$を$(r,s)$成分に持つ等方性を持った$m×m$相関行列$\\boldsymbol{T}$が用いられます。 $$ \\tau_{r,s}= \\begin{cases} c~~~(0\u0026lt;c\u0026lt;1)~~~(r\\neq{s})\\\\ 1~~~(r=s) \\end{cases}　\\tag{22} $$ $r=s$のとき、入力間の相関は$z$に関しては1、$r\\neq{s}$のとき、c(一定)にする、ということです。 $\\boldsymbol{T}$は以下のように分解できます。 $$\r\\boldsymbol{T}=\r(1-c)\r\\left(\r\\begin{array}{ccc}\r1 \u0026 0 \u0026 \\cdots \u0026 0 \\\\\\\\\r0 \u0026 1 \u0026 \\cdots \u0026 0 \\\\\\\\\r\\vdots \u0026 \\vdots \u0026 \\ddots \u0026 \\vdots \\\\\\\\\r0 \u0026 0 \u0026 \\cdots \u0026 1\r\\end{array}\r\\right)+\rc\r\\left(\r\\begin{array}{ccc}\r1 \\\\\\\\\r1 \\\\\\\\\r\\vdots \\\\\\\\\r1\r\\end{array}\r\\right)\r\\left(\r1,1,\\ldots,1\\right) \\tag{23}\r$$\r このとき、任意の$m×1$ベクトル$\\boldsymbol{a}$について、 $$ \\boldsymbol{a}^T\\boldsymbol{T}\\boldsymbol{a}=(1-c)\\boldsymbol{a}^{T}\\boldsymbol{a}+c(\\boldsymbol{a}^{T}1)^2\u0026gt;0 \\tag{24} $$ だから、$\\boldsymbol{T}$は正定値行列なので、PDUDEです。$\\boldsymbol{T}$が正定値行列であることは結構重要で、各要素の値を出力するカーネル関数$k(\\boldsymbol{z}_m,\\boldsymbol{z}_n)$が何かしらの特徴ベクトル空間の内積を表現するために必要な条件です。このあたりの詳細はこちらなどを見てください。また上記$\\boldsymbol{T}$の各要素を出力する関数はisotropic correlation functionと呼ばれ、isotropic correlation functionによる出力を要素に持つ行列はcompound symmetric correlation matrixと呼ばれています。 上記の$\\boldsymbol{T}$をPDUDEに用いる場合、式$(21)$は下記のように変形できます。 $$\r\\left(\\prod_{j=1}^{J}\\tau_{z_{j,r,s}}\\right)\\exp\\left(-\\cfrac{1}{2\\rho^2}\\sum_{i=1}^{I}(x_{im}-x_{in})^2\\right)=\r\\prod_{j=1}^{J}\\exp\\left(-\\mathrm{ln}\\left(\\cfrac{1}{c}\\right)I[r\\neq{s}]\\right)\\exp\\left(-\\cfrac{1}{2\\rho^2}\\sum_{i=1}^{I}(x_{im}-x_{in})^2\\right)=\r\\exp\\left(-\\cfrac{1}{2\\rho^2}\\sum_{i=1}^{I}(x_{im}-x_{in})^2-\\sum_{j=1}^{J}\\mathrm{ln}\\left(\\cfrac{1}{c}\\right)I[r\\neq{s}]\\right) \\tag{25}\r$$\r ここで、$I[r\\neq{s}]$は下記の関数になります。 $$ I[r\\neq{s}]=\\begin{cases} 1~~~(r\\neq{s})\\\\ 0~~~(r=s) \\end{cases}　\\tag{26} $$ 式$(25)$最後の項は、対数をとると $$\r\\log\\left(\\exp\\left(-\\cfrac{1}{2\\rho^2}\\sum_{i=1}^{I}(x_{im}-x_{in})^2-\\sum_{j=1}^{J}\\mathrm{ln}\\left(\\cfrac{1}{c}\\right)I[r\\neq{s}]\\right)\\right)=\r-\\cfrac{1}{2\\rho^2}\\sum_{i=1}^{I}(x_{im}-x_{in})^2-\\sum_{j=1}^{J}\\mathrm{ln}\\left(\\cfrac{1}{c}\\right)I[r\\neq{s}]\\tag{27}\r$$\r となります。よって、対数スケールにおいて、量的変数についてはL2距離を、質的変数については0~1の値をとる距離を使用していることが分かります。 以上、カテゴリカルな変数を用いたカーネルについて説明しました。参考文献はこちらになります。制約のあるPDUDEについては、今回紹介したもののほかにも順序尺度に対するPDUDE,グループ相関に対するPDUDE等紹介されています。 まとめ 今回はガウス過程みまつわる理論を深堀りしてみました。ガウス過程潜在変数モデル、カテゴリカルな変数への対応の2点が重要です。ここで紹介した内容は、次回の記事で実際のデータへ応用し、期待通り機能することを確かめたいと思います。"
  },
  {
    url: "https://sucre-stat.com/2020/06/gaussianprocess/",
    title: "ガウス過程入門",
    date: "2020-06-14T00:00:00Z",
    body: "ガウス過程入門 はじめに 今までに幾度かテーマにしていますが、回帰とよばれる問題があります。 例えば、車の速度とブレーキをかけてから車が止まるまでの距離について、データから両者の関係を把握したい、というような場合。最も単純な関係式でこの目的を果たそうとする場合、一般には以下に示す単回帰が用いられるでしょう。 $$ \\mu_n = ax_n + b $$ $$ y_n \\sim \\rm{Normal}(\\mu_n, \\sigma) $$ $$ n=1, \\ldots, N $$ $Y$は目的変数(説明変数によって説明される変数)、$X$は説明変数(目的変数を説明する変数)、それぞれ$Y=(y_1, \\ldots, y_n, \\ldots, y_N)$、$X=(x_1, \\ldots, x_n, \\ldots, x_N)$です。 こんな需要もあるかもしれません。 上のモデルより少し難しいモデルですが、$X$、$Y$ともに非負の実数であることから、$Y$がガンマ分布に従うとし、リンク関数を$log$とした場合。 $$ \\mu_n = \\rm{exp}(ax_n + b) $$ $$ y_n \\sim \\rm{Gamma}(\\mu_n, \\alpha, \\beta) $$ 上記の内容について理解が追い付かない場合は、こちらのサイトなどを覗いてみてください。分かりやすくまとめられています。 分析の目的が変数間の関係把握であるならば、上述のモデルで事足りる場合も多いと思います。しかし「将来得られる可能性のある任意の値$X_{new}$に対応する$Y_{new}$の値を予測したい」というような場合、話は変わってきます。 これまでに得られたデータ$X$、$Y$の組から将来得られるデータ$X_{new}$に対応する$Y_{new}$の値を予測するとなると、より観測データにフィットできる柔軟なモデルを構築することが理想です(ただし過学習には要注意)。 今回は、上記のような期待に応えるモデルとしてガウス過程を取り上げ、 データに対し柔軟な回帰曲線を得られるようにすることを最終目標とします。 参考図書はこちらです。 こちらのブログも大いに参考にさせていただきました。RもいいですがJuliaも面白そうです。影響を受けてJuliaの参考書を買ってしまいました。 本記事の構成は以下の通りです。 はじめに ガウス過程の定義 ガウス過程の導出 ガウス過程の直感的な性質 カーネル関数 ガウス過程のシミュレーション ガウスカーネルのシミュレーション 線形カーネルのシミュレーション Matern3カーネルのシミュレーション ガウスカーネルと線形カーネルの結合 実際に回帰・パラメータ推定を実行 ガウスカーネルを使った回帰 ガウスカーネル＋線形カーネルで回帰 情報量基準の確認 まとめ ガウス過程の定義 ガウス過程の導出 ガウス過程について特にわかりやすいと思った参考図書の記載を抜粋してガウス過程について説明します。 この節の理解には多変量正規分布($\\rm{MultiNormal}()$)の理解が必要です。多変量正規分布については参考図書などを見て適宜補完してください。 以下の線形回帰モデルを考えます。 特徴ベクトルの要素数を$H$とします。 特徴ベクトルとは機械学習分野の用語で、変換処理によって抽出されるデータの特徴を要素に持つベクトルです。 $\\phi(x)$は説明変数群$X$(機械学習分野では入力と呼びます)の要素$x$に関する特徴ベクトルです。 $$ \\phi(x) = (\\phi_1(x), \\phi_2(x), \\phi_3(x), \\ldots, \\phi_H(x)) $$ $w$は各特徴の重みです。 $$ w = (w_1, w_2,w_3, \\ldots, w_H)^T $$ $\\hat{y}$を目的変数$Y$の要素$y$についての予測値とすると、 $$ \\hat{y} = \\phi(x)w　\\tag{1} $$ とおけます。 さらに式(1)を$(\\hat{y}_1,x_1), \\ldots, (\\hat{y}_N,x_N)$についてまとめると、 $$ \\left( \\begin{array}{ccc} \\hat{y}_1 \\\\ \\hat{y}_2 \\\\ \\vdots \\\\ \\hat{y}_N \\end{array} \\right) = \\left( \\begin{array}{ccc} \\phi_1(x_1) \u0026amp; \\phi_2(x_1) \u0026amp; \\cdots \u0026amp; \\phi_H(x_1) \\\\ \\phi_1(x_2) \u0026amp; \\phi_2(x_2) \u0026amp; \\cdots \u0026amp; \\phi_H(x_2) \\\\ \\cdots \u0026amp; \\cdots \u0026amp; \\ddots \u0026amp; \\cdots \\\\ \\phi_1(x_N) \u0026amp; \\phi_2(x_N) \u0026amp; \\cdots \u0026amp; \\phi_H(x_N) \\end{array} \\right) \\left( \\begin{array}{ccc} w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_H \\end{array} \\right) \\tag{2} $$ とおけます。 ここで$\\phi_{nh} = \\phi_{h}(x_n)$を要素に持つ計画行列(統計モデルの基底関数についての行列)$\\Phi$を使うと、式(2)は $$ \\hat{Y} = \\Phi w　\\tag{3} $$ とまとめられます。 式(3)を使えば、基底関数を自由に設定したり、基底関数の次元を増やすことでほとんど任意の形の関数が表現できそうです。しかし、$x$が高次元であるほど基底関数の数を多く設定する必要があり、そうなるとパラメータ$w$もどんどん増えていってしまい、最終的にはパラメータ$w$の推定が不可能なほどになってしまいそうです。 そこで、パラメータwの周辺化消去(期待値をとって積分消去)を考えます。 $w$が平均0、分散$\\lambda^2I$の互いに独立な正規分布に従うと仮定し、重み$w$が特定の基底関数に偏り、過学習に陥りにくいように設定します。 $$ w \\sim \\rm{MultiNormal}(0, \\lambda^2I) \\tag{4} $$ これによって$w$の期待値を仮定し、周辺化消去を行うのですが、その過程は省略し、結果のみを以下に書きます。 $$ Y \\sim \\rm{MultiNormal}(0, \\lambda^2\\Phi\\Phi^T) \\tag{5} $$ 式(5)がガウス過程を定義する式です。これは式(3)と基本的に同じ機能をもつため、式(3)と同様、ほとんどどんな形でも表現できそうです。ただし、線形回帰モデル式(3)にあったパラメータ$w$が積分消去されているため、$x$の次元がいくら高くなっても推定するパラメータは増えず、$y$の分布はデータ数$N$に依存する共分散行列$\\lambda^2\\Phi\\Phi^T$のみによって決定します。さらに式(3)からの変形で式(4)をかませているため、過学習に陥る可能性が抑えられています。 ガウス過程の直感的な性質 ガウス過程の性質を決定する共分散行列について見ていきます。 $$ K = \\lambda^2\\Phi\\Phi^T $$ とおくと、この$(n, n^{'})$要素は $$ k_{nn^{'}} = \\lambda^2\\phi(x_n)^T\\phi(x_{n^{'}}) $$ なので、これは$x_{n}$と$x_{n^{'}}$の特徴ベクトル$\\phi(x_{n})$と$\\phi(x_{n^{'}})$の内積の$\\lambda^2$倍です。多変量正規分布において２変数の共分散が大きいとき、両者の相関が高いということなので、２変数の平均値が同値かつ共分散が大きいとき、両者は似た値をとりやすくなります。 つまり、$x_{n}$と$x_{n^{'}}$が設定した特徴ベクトル空間において似ている場合、対応する$y_{n}$と$y_{n^{'}}$も似た値が出力されやすくなります。このように、説明変数$x$が似ていれば目的変数の予測値$y$も似た値となる、というのがガウス過程の性質になります。 カーネル関数 $$ k_{nn^{'}} = \\phi(x_n)^T\\phi(x_{n^{'}})　\\tag{6} $$ これを特徴ベクトルから計算しようとすると、複雑な計算が要求されます。そうではなく、式(6)を計算するための関数として、カーネル関数を用います。また、カーネル関数を用いて内積を計算することをカーネルトリックと呼びます。 カーネル関数は、何らかの無限次元の特徴ベクトル空間における２点の内積を表現できる、という特徴をもつ関数で、それぞれに異なる無限次元特徴ベクトルを定義する様々なカーネル関数があります。 例えば、カーネル関数の１種、ガウスカーネル $$ k(x,x_{'}) = \\rm{exp}(-a(x-x^{'})^2) $$ の場合、 $$ \\rm{exp}(-a(x-x^{'}))^2 = \\phi(x)^{T}\\phi(x^{'}) $$ となる特徴ベクトルは、第$r$成分が $$ \\phi_r(x) = \\left(\\cfrac{4a}{\\pi}\\right)^{\\cfrac{1}{4}}\\rm{exp}(-2a(x-r)^2) $$ となります($r$は実数で、$r=-\\infty, \\ldots, \\infty$)。 これは、 $$ \\int_{-\\infty}^{\\infty} \\phi_r(x)\\phi_r(x^{'}) dr = exp(-a(x-x^{'}))^2 $$ を証明することで確認できます。証明はこちらのサイトで見れます。 なお、通常のパラメータとは設定目的の異なる、モデルの複雑さを決定するパラメータはハイーパーパラメータ(超母数)などと呼ばれます。以降、カーネル関数のパラメータもハイパーパラメータと呼ぶことにします。 ガウス過程のシミュレーション ガウス過程の概要を確認したので、ガウス過程に従う確率変数がどのような挙動をするのか、いくつかのカーネル関数を例に見てみます。 シミュレーションの前に、カーネル行列($K$のこと)を作成する関数と、シミュレーションのための関数を定義しておきます。 # カーネル行列を作成する関数を定義 # 引数 kernel：この後に定義するカーネル関数を指定 x：トレーニングデータ # 引数 par:kernelが要求するハイパーパラメータ delta：誤差の要素。ハイパーパラメータとは別で指定することにした kernel_cov \u0026lt;- function(kernel, x,par, delta){ NL \u0026lt;- length(x) Sigma \u0026lt;- matrix(NA, nrow=NL, ncol=NL) for(i in 1:(NL-1)){ Sigma[i,i] \u0026lt;- kernel(x[i],x[i],par) + delta for(j in (i+1):NL){ Sigma[i,j] \u0026lt;- kernel(x[i],x[j],par) Sigma[j,i] \u0026lt;- Sigma[i,j] } } Sigma[NL,NL] \u0026lt;- kernel(x[NL],x[NL],par) + delta return(Sigma) } # シミュレーションのための自作関数を定義 GP_sim \u0026lt;- function(kernel, par){ p \u0026lt;- ggplot() + theme_bw(base_size = 11) i \u0026lt;- 0 xs = seq(-4,4,0.05) repeat{ i \u0026lt;- i + 1 if(i == 5) break p \u0026lt;- p + geom_line(data=data.frame(x = xs, y = MASS::mvrnorm(1, mu=rep(0,length(xs)), kernel_cov(kernel=kernel,x=xs, par=par,delta=1e-8))), aes(x=x,y=y), colour=as.factor(i)) } plot(p) } ガウスカーネルのシミュレーション 前の節で紹介したガウスカーネルのシミュレーションです。改めてガウスカーネルを再定義します。 ガウスカーネルは、下のようにrateパラメータ$\\theta$、shapeパラメータ$\\rho$をもちます。ここでは$\\theta$、$\\rho$ともに１とした場合のシミュレーションをします。 $$ k(x,x_{'}) = \\theta \\rm{exp}\\left(-\\cfrac{(x-x^{'})^2}{\\rho}\\right) $$ ## ガウスカーネルの定義 kernel_cov()で使用できるように、引数は(x1,x2,par)でないといけない ## カーネルのハイパーパラメータはすべてparで指定する Gaussian_kernel \u0026lt;- function(x1, x2, par){ return(par[1]*exp(-(x1 - x2)^2/par[2])) } GP_sim(Gaussian_kernel, par=c(1,1)) ガウスカーネルをカーネル関数に設定したガウス過程は、無限回微分可能な滑らかな曲線になるそうです。 線形カーネルのシミュレーション 線形カーネルは、ハイパーパラメータを持たないカーネル関数です。 $$ k(x,x_{'}) = x^T x^{'} $$ 線形カーネルは、$\\phi(x)=x$としているので、これを式(1)に代入すると、$x$の中に定数項$x_0=1$が含まれているとした場合、通常の重回帰と等価であることが分かります。 ## 線形カーネルを定義。ハイパーパラメータは無し linear_kernel \u0026lt;- function(x1,x2,par){ return(1 + t(x1)%*%x2) } GP_sim(linear_kernel, par=NULL) シミュレーションでも直線が引けることが確認できます。 Matern3カーネルのシミュレーション Maternカーネルは、ガウスカーネルの無限回微分可能という前提がモデル化において強すぎるという主張から提案されたカーネルです。 $$ k_v(x,x^{'}) = \\cfrac{2^{1-\\upsilon}}{\\Gamma(\\upsilon)} \\left( \\cfrac{\\sqrt{2\\upsilon}r}{\\upsilon} \\right)^2 K_v \\left( \\cfrac{\\sqrt{2\\upsilon}r}{\\upsilon} \\right) ~~~ (r=|x-x^{'}|) $$ Maternカーネルを用いたガウス過程から生成される関数は、「$\\upsilon$以下の最大の整数」回分微分可能で、$\\upsilon$は$\\cfrac{3}{2},\\cfrac{5}{2} $などが使われ、それぞれMatern3、Matern5と呼ばれるようです。 Matern3カーネルは以下のようになります。 $$ k_{3/2}(x,x^{'}) = \\left(1 + \\cfrac{\\sqrt{3}r}{\\theta} \\right) exp\\left( -\\cfrac{\\sqrt{3}r}{\\theta} \\right) $$ このMatern3カーネルを$\\theta=1$としてシミュレーションしてみます。 # Matern3カーネルを定義 Matern3_kernel \u0026lt;- function(x1,x2, par){ return((1 + sqrt(3)*abs(x1-x2)/par[1])*exp(-sqrt(3)*abs(x1-x2)/par[2])) } GP_sim(Matern3_kernel,par=c(1,1)) ガウスカーネルと比べていびつな曲線になっていることが分かります。 ガウスカーネルと線形カーネルの結合 カーネル関数は組み合わせて使うことも可能です。 ここではガウスカーネルと線形カーネルを組み合わせてみます。 $$ k(x,x_{'}) = \\theta_1 \\rm{exp}\\left(-\\cfrac{(x-x^{'})^2}{\\rho}\\right) + \\theta_2x^T x^{'} $$ 上の式において、$\\theta_1=0.8, \\theta_2=2, \\rho=0.07$としたときのシミュレーションです。 # ガウスカーネル＋線形カーネルの定義 Gaussian_plus_Linear_kernel \u0026lt;- function(x1,x2,par){ return(par[1] * exp(-(x1 - x2)^2/par[2]) + par[3] * (1 + t(x1)%*%x2)) } GP_sim(Gaussian_plus_Linear_kernel,c(0.8,0.07,2)) ガウスカーネルと線形カーネルがうまく組み合わさっていることが分かります。 実際に回帰・パラメータ推定を実行 ひととおりシミュレーションしたので実践です。 まずは参考図書と同じ、陸上男子100mの世界記録のデータを準備します。$x$は世界記録更新日、$y$は世界記録のタイムです。 # データの準備 x \u0026lt;- as.Date(x=c(\u0026#34;1964/10/15\u0026#34;,\u0026#34;1968/6/20\u0026#34;,\u0026#34;1968/10/13\u0026#34;,\u0026#34;1968/10/14\u0026#34;,\u0026#34;1983/7/3\u0026#34;,\u0026#34;1987/8/30\u0026#34;,\u0026#34;1988/8/17\u0026#34;, \u0026#34;1988/9/24\u0026#34;,\u0026#34;1991/7/14\u0026#34;,\u0026#34;1991/8/25\u0026#34;,\u0026#34;1994/7/6\u0026#34;,\u0026#34;1996/7/27\u0026#34;,\u0026#34;1999/6/16\u0026#34;,\u0026#34;2002/9/14\u0026#34;, \u0026#34;2005/6/14\u0026#34;,\u0026#34;2006/5/12\u0026#34;,\u0026#34;2006/6/11\u0026#34;,\u0026#34;2006/8/18\u0026#34;,\u0026#34;2007/9/9\u0026#34;,\u0026#34;2008/5/31\u0026#34;,\u0026#34;2008/8/16\u0026#34;,\u0026#34;2009/8/16\u0026#34;)) y \u0026lt;- c(10.06,10.03,10.02,9.95,9.93,9.93,9.93,9.92,9.9,9.86,9.85,9.84,9.79,9.78,9.77,9.77,9.77,9.77,9.74,9.72,9.69,9.58) # 標準化 x \u0026lt;- (as.numeric(x)-mean(as.numeric(x)))/sd(as.numeric(x)) y \u0026lt;- (y-mean(y))/sd(y) library(ggplot2) p \u0026lt;- ggplot(data=data.frame(x=x,y=y), aes(x=x,y=y)) + theme_bw(base_size=11) + geom_point() p 分析にあたって、まずはハイパーパラメータの最適な値を推定します。 推定方法にはハイパーパラメータを少しずつ変えてその事後分布を推定するMCMCも使えますが、ここでは計算量の少ない効率的な方法として勾配法を用います。 簡略化のため、ガウス過程のハイパーパラメータを$\\theta=(\\theta_1, \\theta_2,\\ldots)$とまとめておき、カーネル行列も$K_{\\theta}$とします。 確率変数$Y$がガウス過程$GP(0,K_\\theta)$に従うと仮定したとき、観測値に対する尤度は、 $$ p(Y|X,\\theta) = \\rm{MultiNormal}(Y|o,K_{\\theta}) = \\cfrac{1}{(2\\pi)^{N/2}} \\cfrac{1}{|K_{\\theta}|^{1/2}} exp\\left(\\cfrac{1}{2}Y^TK_{\\theta}^{-1}Y\\right) $$ 対数尤度は、 $$ \\log(Y|X,\\theta)~~ = ~~ -\\cfrac{N}{2}\\log(2\\pi)-\\cfrac{1}{2}\\log|K_{\\theta}|-\\cfrac{1}{2}Y^TK_{\\theta}^{-1}Y~~ \\propto~~ -\\log|K_{\\theta}|-Y^TK_{\\theta}^{-1}Y +(定数) \\tag{7}　$$ です。 式(7)を最大にする$\\theta$を求め、ハイパーパラメータの最適な値とします。 式(7)を計算する自作関数を以下で定義します。 # ガウス過程モデルの対数尤度に比例する値を計算する関数を定義 GP_L \u0026lt;- function(x, y, par, kernel){ return(-log(det(kernel_cov(kernel=kernel,x=x,par=exp(par[-length(par)]),delta=exp(par[length(par)])))) -t(y)%*% solve(kernel_cov(kernel=kernel,x=x,par=exp(par[-length(par)]), delta=exp(par[length(par)])))%*%y) } 式(7)を最大にする$\\theta$は、Rの汎用最適化関数のoptim()を使います。参考図書では式(7)を$\\theta$の各ハイパーパラメータで偏微分した式が紹介されています。optim()では引数grで一階偏微分関数を指定でき、簡単に定義できるなら明示的に指定した方が良いのですが、指定しなくても勝手に微分してくれるので今回は横着します。 参考図書には、以下のガウス過程の予測分布の公式が記載されていますので、この公式に倣って予測分布を計算する自作関数を定義します。 $$ p(Y^{\\star}|X^{\\star},\\mathcal{D}) = \\rm{MultiNormal}(k_{\\star}^T K^{-1}Y,k_{\\star\\star}-k_{\\star}^{T}K^{-1}k_{\\star}) $$ ここで$\\mathcal{D}$は観測値$Y$、$X$の$N$個のペア、$Y^{\\star}=(y_1^{\\star},\\ldots,y_M^{\\star})$、$X^{\\star}=(x_1^{\\star}, \\ldots, x_M^{\\star})$はそれぞれ予測値と特徴ベクトル空間における予測したい点の$M$個のペアです。$k_{\\star}$、$k_{\\star\\star}$はそれぞれ $$ k_{\\star}(n,m) = k(x_n,x_m^{\\star})~~~(n=1,\\ldots,N,m=1,\\ldots,M) $$ $$ k_{\\star\\star}(m_1,m_2) = k(x_{m1}^{\\star},x_{m2}^{\\star})~~~(m_1=1,\\ldots,M, m_2=1,\\ldots,M) $$ を要素に持つカーネル行列です。 # 予測値の算出のための関数定義 # 返り値は各予測点の平均と共分散行列 my_predict \u0026lt;- function(x_test, x_train, y_train, kernel, par){ kernel_cov_star \u0026lt;- function(x1,x2,par,kernel){ NL \u0026lt;- length(x1) ML \u0026lt;- length(x2) Sigma \u0026lt;- matrix(NA, nrow=NL, ncol=ML) for(i in 1:NL){ for(j in 1:ML){ Sigma[i,j] \u0026lt;- kernel(x1=x1[i], x2=x2[j],par=par[-length(par)]) } } return(Sigma) } K \u0026lt;- kernel_cov(kernel=kernel,x=x_train, par=par[-length(par)], delta=par[length(par)]) k_star \u0026lt;- kernel_cov_star(kernel=kernel, x1=x_train, x2=x_test,par=par) k_2star \u0026lt;- kernel_cov(kernel=kernel, x=x_test, par=par[-length(par)], delta=par[length(par)]) mu \u0026lt;- t(k_star) %*% solve(K) %*% y_train sigma \u0026lt;- k_2star - t(k_star) %*% solve(K) %*% k_star return(list(mu, sigma)) } ガウスカーネルを使った回帰 上で定義した関数を使い、カーネル関数にガウスカーネルを設定して回帰を実行してみます。 #自作関数GP_L()を使って対数尤度を計算 対数尤度を最大化するハイパーパラメータを推定 res_optim1 \u0026lt;- optim(par=c(0,0,0),fn=GP_L,kernel=Gaussian_kernel, x=x,y=y,control = list(fnscale=-1), method=\u0026#34;BFGS\u0026#34;) par \u0026lt;- exp(res_optim1$par) # 推定したパラメータの値を確認 par ## [1] 1.55308949 0.22898734 0.04299662 #自作関数my_predict()を使って予測分布の平均・ 共分散行列を求める pre \u0026lt;- my_predict(x_test = seq(-2.0,2.0,0.01),x_train=x, y_train=y, kernel=Gaussian_kernel,par=par) # 結果の描画 library(ggplot2) p \u0026lt;- ggplot() + theme_bw(base_size=11) + geom_line(data=data.frame(x=seq(-2.0,2.0,0.01),y=pre[[1]]),aes(x=x,y=y)) p \u0026lt;- p + geom_point(data=data.frame(x=x,y=y),aes(x=x,y=y)) p \u0026lt;- p + geom_ribbon(data=data.frame(x=seq(-2.0,2.0,0.01),ymin=pre[[1]]-2*sqrt(diag(pre[[2]])), ymax=pre[[1]]+2*sqrt(diag(pre[[2]]))), aes(x=x,ymax=ymax,ymin=ymin),fill=\u0026#34;blue\u0026#34;,alpha=0.5) p 最適化したカーネル関数は以下になります。$\\delta(x,x^{'})$はクロネッカーのデルタと呼ばれ、$x=x^{'}$のとき、つまりカーネル行列の対角成分にときのみ1を、それ以外は0を返す関数です。 $$ k(x,x_{'}) = 1.553exp\\left(-\\cfrac{(x-x^{'})^2}{0.229}\\right) + 0.043\\delta(x,x^{'}) $$ 青い領域はガウス事後分布の$\\pm2\\sigma$の誤差範囲を示します。 これまた不思議な予測曲線が得られました。結果を観察すると、観測値の乏しい範囲では誤差範囲が広く推定されており、期待値も平均($=0$)に近づくようになっています。 ハリボーはこう考えました。 データの少ない部分は曖昧に推定するというのは、現実的な判断じゃあないか\u0026gt;🦔 しかしかめきちはこう言っています。 将来世界記録のタイムが伸びるという推定はあまりにもおかしいかめ\u0026gt;🐢 ガウスカーネル＋線形カーネルで回帰 かめきちの意見を踏まえ、カーネル関数でガウスカーネルと線形カーネルを組み合わせてみます。 # ガウスカーネル＋線形カーネを使って回帰 # 自作関数GP_L()を使って尤度を計算 尤度を最大化するハイパーパラメータを推定 res_optim2 \u0026lt;- optim(par=c(0,0,0,0),fn=GP_L,kernel=Gaussian_plus_Linear_kernel, x=x,y=y,control = list(fnscale=-1), method=\u0026#34;BFGS\u0026#34;) par \u0026lt;- exp(res_optim2$par) # 推定したパラメータの値を確認 par ## [1] 0.11098682 0.02720031 0.46865763 0.04742707 # 自作関数my_predict()を使って予測分布の平均・ 共分散行列を求める pre \u0026lt;- my_predict(x_test = seq(-2.0,2.0,0.01),x_train=x, y_train=y, kernel = Gaussian_plus_Linear_kernel,par=par) # 結果の描画 library(ggplot2) p \u0026lt;- ggplot() + theme_bw(base_size=11) + geom_line(data=data.frame(x=seq(-2.0,2.0,0.01),y=pre[[1]]),aes(x=x,y=y)) p \u0026lt;- p + geom_point(data=data.frame(x=x,y=y),aes(x=x,y=y)) p \u0026lt;- p + geom_ribbon(data=data.frame(x=seq(-2.0,2.0,0.01),ymin=pre[[1]]-2*sqrt(diag(pre[[2]])), ymax=pre[[1]]+2*sqrt(diag(pre[[2]]))), aes(x=x,ymax=ymax,ymin=ymin),fill=\u0026#34;blue\u0026#34;,alpha=0.5) p It\u0026rsquo;s so brilliant\u0026gt;🐢 最適化したカーネル関数は以下になります。 $$ k(x,x_{'}) = 0.111exp\\left(-\\cfrac{(x-x^{'})^2}{0.027}\\right) + 0.469x^T x^{'} + 0.047\\delta(x,x^{'}) $$ タイムが短縮される全体的な傾向が線形カーネルでとらえるとともに、細かい変動をガウスカーネルで表現できています。 勾配法の初期値を変えるとどうなるでしょう。 res_optim3 \u0026lt;- optim(par=c(0,0.4,0,0),fn=GP_L,kernel=Gaussian_plus_Linear_kernel, x=x,y=y,control = list(fnscale=-1), method=\u0026#34;BFGS\u0026#34;) par = exp(res_optim3$par) par ## [1] 0.22313442 2.81135418 0.50883359 0.09808983 ~省略~ 最適化したカーネル関数は以下になります。 $$ k(x,x_{'}) = 0.223exp\\left(-\\cfrac{(x-x^{'})^2}{2.811}\\right) + 0.509x^T x^{'} + 0.098\\delta(x,x^{'}) $$ ハイパーパラメータの値が変化し、結果も全く異なります。勾配法によるハイパーパラメータ推定では初期値によって結果が異なることも多く、局所最適解が多い場合はその傾向が強いです。 このような場合、MCMCで推定すると大域的局所解に近づいてくれます。 情報量基準の確認 モデルの良さを表す数値的指標として、各種の情報量基準が提案されています。 ここでは、以下で定義されるAICを計算してみます。 (AICは正しい使い方というのがあるようで私はAICを誤用しているかもしれません。誤りがあればご指摘を！) $$ AIC = -2最大対数尤度＋2自由パラメータの個数 $$ # optim()で対数尤度にマイナスをかけているので、ここでは対数尤度にマイナスをかけない # optim()で最大化したGP_L()は、実際の対数尤度ではなく対数尤度に比例する値なので、ここで正確な対数尤度を計算する my_AIC \u0026lt;- function(res_optim, x){ return(2*(res_optim$value/2 + length(x)/2 * log(2*pi))+2*length(res_optim$par)) } cat(sprintf(\u0026#34;AIC of \\n res1 = %.3f\\n res2 = %.3f\\n res3 = %.3f\u0026#34;,my_AIC(res_optim1,x), my_AIC(res_optim2,x), my_AIC(res_optim3,x))) ## AIC of ## res1 = 60.507 ## res2 = 68.203 ## res3 = 65.642 AICは、小さい値をとるモデルほど良いモデルと考えます。結果を見ると、一番初めのガウスカーネルを使ったモデルが最もAICが小さいです。また、ガウスカーネル・線形カーネルの２モデルの比較では、後のモデルの方がAICが小さいです。 これらの結果から、ガウスカーネルを使ったモデルが最も良いモデルであることが示唆されますが、AICはほかのモデルを完全否定するものではないので、最終的にどのモデルを選択するかは技術者判断と言えます。 私としては最後の結果を支持したいところです…。 まとめ 今回はガウス過程について説明しました。ガウス過程は理論が難しいですが、結果が合理的で、黒魔術かと疑ってしまうような技術です。 その応用範囲も広く、空間統計の分野では割と以前から活用されていたようです。また構造計算で利用される有限要素法においてもデータを完璧に補間するモデルとして広く利用されているそうです。 私はこれまで以下の活用方法を確認しています。 一般化線形モデルの線形予測子をガウス過程に置き換え、柔軟なモデルに豹変させる 空間統計において空間的自己相関を考慮したモデルを構築する ちなみにガウス過程を一般化線形モデルに活用したりするような場合、事後分布は単純なガウス分布ではないため、MCMC等の近似推論法が必要となります。私の大好きなMCMCです。 また、大規模データに対しガウス過程を含むモデルを素直に計算すると、計算量が膨大となってしまいます。そのため、様々な近似手法が提案されているようです。参考図書の後半でその近似手法が述べられているので今後勉強したいと思っています。 ガウス過程の活用例も今後の記事で紹介できればと思っています。楽しみ。"
  },
  {
    url: "https://sucre-stat.com/2020/05/multinom-rstan/",
    title: "rstanを使った多項ロジスティック回帰",
    date: "2020-05-31T00:00:00Z",
    body: "rstanを使った多項ロジスティック回帰 はじめに 回帰に関する記事です。本記事では以前の記事で扱った多項ロジスティック回帰をrstanで実行します。 本記事の構成は以下の通りとします。 はじめに モデルの確認 データの入手・整形 Stanによる多項ロジスティック回帰の実装 結果の確認 MCMCの収束の確認 モデルの係数に着目 オッズ比の変量に着目 結果の描画 まとめ モデルの確認 以前の記事でも紹介した多項ロジスティック回帰モデルの一般式を再掲します。 従属変数$Y$、説明変数$X$について、$Y = (y_1,\\ldots,y_n,\\ldots, y_N)^T$、$X = (x_1,\\ldots, x_n,\\ldots, x_N)^T$とし、さらに $x_n = (x_{1n},\\ldots,x_{dn},\\ldots, x_{Dn})$としたとき、多項ロジスティック回帰のモデル式は以下になります。$N$はサンプルサイズ、$D$は説明変数の次元です。 $$ \\mu_n = \\overrightarrow{a} + \\overrightarrow{b_1}x_{n1} + \\cdots + \\overrightarrow{b_d}x_{nd} + \\cdots + \\overrightarrow{b_D}x_{nD} $$ $$ \\theta_n = \\rm{softmax}(\\mu_n) $$ $$ y_n \\sim \\rm{Categorical}(\\theta_n) $$ $$ (n=1,\\ldots,N) $$ ここで $$ \\mu=(\\mu_1,\\ldots,\\mu_n,\\ldots,\\mu_N) $$ $$ \\theta=(\\theta_1,\\ldots,\\theta_n,\\ldots,\\theta_N) $$ $\\mu_n, \\theta_n,\\overrightarrow{a},\\overrightarrow{b_1},\\ldots,\\overrightarrow{b_D}$は長さ$K$のベクトルです。 データの入手・整形 以前の記事でも扱ったデータを用います。今回もprog(200人の生徒がgeneral、vocation、academicの3つの授業から選んだ授業)を従属変数とし、ses(家庭の経済状況)、write(書く力)を従属変数とします。 以下の通りStanに指定するデータに整形していきます。 library(makedummies) library(tidyr) library(dplyr) library(foreign) ml \u0026lt;- read.dta(\u0026#34;https://stats.idre.ucla.edu/stat/data/hsbdemo.dta\u0026#34;) ## progの3引数を数字に置き換えるための表を作成 progid \u0026lt;- c(1,2,3) names(progid) \u0026lt;- c(\u0026#34;academic\u0026#34;,\u0026#34;general\u0026#34;,\u0026#34;vocation\u0026#34;) ## makedummies()はsesに対してダミー変数を作成するために使用 ## interceptは切片項 d \u0026lt;- ml %\u0026gt;% cbind(makedummies::makedummies(ml,basal_level = F, col = \u0026#34;ses\u0026#34;)) %\u0026gt;% mutate(progid = progid[paste(prog)]) %\u0026gt;% select(c(ses_middle, ses_high, write, progid)) %\u0026gt;% cbind(intercept=rep(1,nrow(ml))) head(d,10) ## ses_middle ses_high write progid intercept ## 1 0 0 35 3 1 ## 2 1 0 33 2 1 ## 3 0 1 39 3 1 ## 4 0 0 37 3 1 ## 5 1 0 31 3 1 ## 6 0 1 36 2 1 ## 7 1 0 36 3 1 ## 8 1 0 31 3 1 ## 9 1 0 41 3 1 ## 10 1 0 37 3 1 ここで、本データ用に設定したモデル式における係数の呼称を以下の通り定義しておきます。 $$\\cfrac{P(prog=general)}{P(prog=academic)} = \\exp(b_{11} + b_{21}(ses=middle) + b_{31}(ses=high) + b_{41}write)$$ $$\\cfrac{P(prog=vocation)}{P(prog=academic)} = \\exp(b_{12} + b_{22}(ses=middle) + b_{32}(ses=high) + b_{42}write)$$ Stanによる多項ロジスティック回帰の実装 多項ロジスティック回帰を実行するStanコードは以下のようになります。 //(model1.stan) //dataブロック：データを指定 data{ int\u0026lt;lower=2\u0026gt; K; //カテゴリ数 int\u0026lt;lower=1\u0026gt; N; //サンプルサイズ int\u0026lt;lower=1\u0026gt; D; //データ項目数+切片項の数（１） int\u0026lt;lower=1, upper=K\u0026gt; y[N]; //prog matrix[N,D] x; //説明変数と切片項 int N_new; //予測点の数 matrix[N_new,D] x_new; //予測点群 } //transformed dataブロック：新しくデータを生成 ここではmuの区別化の為の0ベクトルを生成 transformed data{ vector[D] Zeros; Zeros = rep_vector(0, D); } //parameterブロック：パラメータを定義 parameters{ matrix[D, K-1] b; } //transformed parameterブロック：parameterブロックで指定したパラメータを変形 ここでは0ベクトルと結合 transformed parameters{ matrix[D,K] beta; beta = append_col(Zeros, b); } //modelブロック：モデルを定義 model{ matrix[N,K] mu; mu = x * beta; for(n in 1:N){ y[n] ~ categorical_logit(mu[n]); } } //generated quantitiesブロック：生成量を定義 ここでは確率に関する予測値mu_newとオッズ比の変量exp(b)を生成 generated quantities{ matrix[D, K-1] ratio;//オッズ比の変量 vector[K] pred[N_new];//予測点において各programが選ばれる確率 matrix[N_new, K] mu_new; mu_new = x_new * beta; for(n in 1:N_new){ pred[n,] = softmax(mu_new[n,]); } ratio = exp(b); } parameterブロックで指定した係数$b$の行番号・列番号の組み合わせが、先ほど定義したモデル式における係数の修飾番号に一致します。例えば、$b[1,2]$はモデル式における$b_{12}$に対応します。 Categorical_logit()はStanに実装された便利な関数で、Stan内部でsoftmaxを実行してくれます。 つまり、y[n] ~ categorical_logit(mu[n]')とy[n] ~ Categorical(softmax(mu[n]'))はともに以下に示す処理を実行してくれます。 $$y[n] \\sim \\rm{Categorical}(\\rm{softmax}(mu[n]))$$ (注：上に示した実装ではコード表現の都合上categorical_logit()とsoftmax()の引数をそれぞれmu[n]、mu_new[n,]としていますが、softmax()は列ベクトルにしか対応していないので、実装では必ずベクトルや行列を転置させる命令である'を引数の後ろにつけてください！) この部分についてもう少し補足すると、 $$ P(y[n] = 1) = \\rm{softmax}(mu[n,])[1] $$ $$ P(y[n] = 2) = \\rm{softmax}(mu[n,2])[2] $$ $$ P(y[n] = 3) = \\rm{softmax}(mu[n,3])[3] $$ という関係になっています。 ここでは$beta[,1] = 0$とすることで$mu[,1] = 0$とし、 またデータの整形において$academic \\rightarrow 1,~~~general \\rightarrow 2,~~~vocation \\rightarrow 3$としているので、以下の通り$P(y[n] = 1(academic))$について固定・基準化していることになります。 $$ P(y[n] = 1(academic)) = \\cfrac{1}{\\sum_{k=1}^K \\exp(mu[n,k])} $$ また、上記の実装ではパラメータのbに事前分布を指定していませんが、Stanでは事前分布を指定しない場合、十分に幅の広い一様分布が自動で設定されます。 そのため、パラメータに関する事前の設定要件が無い場合は、事前分布に何も指定しなくても無情報事前分布が設定されるため問題ありません。 model1に基づいてサンプリングを命令するコードは以下のようになります。 #(run_model1) library(rstan) x \u0026lt;- d[,c(5,1,2,3)] y \u0026lt;- d[,\u0026#34;progid\u0026#34;] K \u0026lt;- 3 N \u0026lt;- nrow(x) D \u0026lt;- ncol(x) x_new \u0026lt;- data.frame(rep(1,123),c(rep(0,41),rep(1,41),rep(0,41)),c(rep(0,82),rep(1,41)), write = rep(c(30:70),3)) N_new \u0026lt;- nrow(x_new) fit0 \u0026lt;- stan(file = \u0026#34;model1.stan\u0026#34;, data = list(x=x,y=y,K=K,N=N,D=D,x_new=x_new,N_new=N_new), seed=123, war=500, iter=1500, chains = 4) rstan::stan()の引数について説明しておきます。 file：stanファイルを指定 data：必要なデータをリスト型で指定 war： warm up期間を指定 iter：waru up期間を含んだchainの長さ(iteration)を指定 chain：chain数を指定 seed：乱数の種類を指定 $x_{new}$はパラメータのMCMCサンプルにもとづいて $$ P(y[n_{new}]=1),~P(y[n_{new}]=2),~P(y[n_{new}]=3),~~~~n_{new}=1,\\ldots,N_{new} $$ の予測値を算出する際に、説明変数$x$がとる組み合わせを指定したものです。 予測値は、MCMCでは生成量のサンプリングとして扱うため、generated quantitiesブロックで指定することになります。 結果の確認 MCMCの収束の確認 MCMCの実行後、まずはちゃんと収束していることを確認する必要があります。 以下ではモデルの係数についてtracsplotを描画し、収束の確認を行います。 library(ggmcmc) library(bayesplot) posterior_fit0_1 \u0026lt;- rstan::extract(fit0, inc_warmup=TRUE, permuted=FALSE) color_scheme_set(\u0026#34;mix-blue-pink\u0026#34;) p \u0026lt;- mcmc_trace(posterior_fit0_1, regex_pars = c(\u0026#34;b\u0026#34;), n_warmup = 500, facet_args = list(ncol = 2))+ theme_bw(base_size=12) + theme(legend.position = \u0026#34;bottom\u0026#34;) p どの係数も早い段階で一つの値に収束しているようです。ここではwarm upを500に設定していますが、十分すぎるwarm up であることが確認できます。 MCMCの収束を確認する方法はtracsplotを用いた視覚的な判断だけでなく、数値基準も用意されています。 options(max.print = 80) fit0 ## Inference for Stan model: model1. ## 4 chains, each with iter=1500; warmup=500; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% ## b[1,1] 2.89 0.03 1.16 0.62 2.11 2.90 3.66 5.12 ## b[1,2] 5.36 0.03 1.13 3.17 4.61 5.32 6.14 7.57 ## b[2,1] -0.54 0.01 0.45 -1.41 -0.83 -0.53 -0.24 0.33 ## b[2,2] 0.32 0.01 0.48 -0.64 0.00 0.31 0.64 1.28 ## b[3,1] -1.19 0.01 0.52 -2.27 -1.53 -1.19 -0.84 -0.19 ## b[3,2] -1.01 0.01 0.59 -2.21 -1.40 -1.00 -0.61 0.12 ## b[4,1] -0.06 0.00 0.02 -0.10 -0.07 -0.06 -0.04 -0.02 ## b[4,2] -0.12 0.00 0.02 -0.16 -0.13 -0.12 -0.10 -0.08 ## n_eff Rhat ## b[1,1] 2022 1 ## b[1,2] 1934 1 ## b[2,1] 2701 1 ## b[2,2] 2579 1 ## b[3,1] 2835 1 ## b[3,2] 2514 1 ## b[4,1] 2122 1 ## b[4,2] 1978 1 ## [ reached getOption(\u0026#34;max.print\u0026#34;) -- 759 行を無視しました ] ## ## Samples were drawn using NUTS(diag_e) at Sun May 31 00:51:09 2020. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). R console上でfit0の中身を確認すると、各MCMCサンプルの要約統計量の他にn-eff、Rhatが出力されます。 n-eff Stanが自己相関等から判断した実行サンプルサイズです。ある書籍には分布の推定・統計量の算出のために100程度以上あることが望ましいと紹介されています。 標本自己相関がラグを大きくしてもなかなか減衰しない場合、MCMCサンプルは過去の値に長く依存しており、不変分布である事後分布に関する推論には効率が悪い、ということのようです。Stan開発者はこちらのページでn-effの定義をしています。私もまだちゃんと読んでいないのでいつか読みたいです。 Rhat($\\hat{R}$) こちらはMCMCが収束したかを表す一つの指標です。 Rhatについては少し詳しく紹介しておきます。 いまchain数を$M$、iterationを$n$とし、chain毎に$n$個の標本$\\theta^{(i,t)}$を発生させたとします$(i=1,2,\\ldots,M,~~t=1,2,\\ldots,n)$。 このとき、$g(\\theta^{(i,t)})$の分散$\\sigma_g^2$は、 $$ \\tilde{\\sigma}^2_{BW} = \\cfrac{(n-1)\\tilde{\\sigma}^2_w + \\tilde{\\sigma}^2_B}{n} $$ $$ \\tilde{\\sigma}^2_{W} = \\cfrac{1}{M} \\sum_{i=1}^M s^2_{g_i}, ~~~~ s^2_{g_i} = \\cfrac{\\sum_{t=1}^n ((g(\\theta^{(i,t)}))-\\bar{g}_i)^2}{n-1} $$ $$ \\tilde{\\sigma}^2_B = n\\cfrac{\\sum_{i=1}^M (\\bar{g}_i-\\check{g})}{M-1},~~~~ \\bar{g}_i = \\cfrac{1}{n}\\sum_{t=1}^n g(\\theta^{(i,t)}),~~~~ \\check{g} = \\cfrac{1}{M} \\sum^M_{i=1} \\bar{g}_i $$ の$\\tilde{\\sigma}^2_{BW},~ \\tilde{\\sigma}^2_{W}, ~ \\tilde{\\sigma}^2_B$のいずれでも推定できます。 MCMC標本の自己相関が高く、不変分布である事後分布への収束が遅い場合、$s^2_{g_i}$(=1chain内の不偏分散)は真の分散$\\sigma^2_g$よりも小さくなり、したがって$\\tilde{\\sigma}^2_{W}$($s^2_{g_i}$の平均)も小さくなります。 一方、各連鎖の動きが緩慢で事後分布の一部でしかサンプリングされていないときは、$\\tilde{\\sigma}^2_B/n$(=各chainの標本平均の不偏分散)が大きくなり、したがって$\\tilde{\\sigma}^2_B$も大きくなります。 そこで、下記式で$\\hat{R}$を定義すると、$\\hat{R}$が1に近いかどうかでMCMCの収束を判断することが出来ます。Galman(1996)は$\\hat{R}$が1.1~1.2以下になれば収束したと実用上考えてよいとしているそうです。 $$ \\hat{R} = \\cfrac{\\tilde{\\sigma}^2_{BW}}{\\tilde{\\sigma}^2_{W}} $$ 今回は全係数でRhatが1ですので、MCMCは収束したと判断します。 モデルの係数に着目 R console上でfit0の中身を確認したとき、係数の要約統計量が以下のように算出されていました。 options(max.print = 80) fit0 ## ～省略～ ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% ## b[1,1] 2.89 0.03 1.16 0.62 2.11 2.90 3.66 5.12 ## b[1,2] 5.36 0.03 1.13 3.17 4.61 5.32 6.14 7.57 ## b[2,1] -0.54 0.01 0.45 -1.41 -0.83 -0.53 -0.24 0.33 ## b[2,2] 0.32 0.01 0.48 -0.64 0.00 0.31 0.64 1.28 ## b[3,1] -1.19 0.01 0.52 -2.27 -1.53 -1.19 -0.84 -0.19 ## b[3,2] -1.01 0.01 0.59 -2.21 -1.40 -1.00 -0.61 0.12 ## b[4,1] -0.06 0.00 0.02 -0.10 -0.07 -0.06 -0.04 -0.02 ## b[4,2] -0.12 0.00 0.02 -0.16 -0.13 -0.12 -0.10 -0.08 事後分布の代表値とし上の中央値(50%列の値)も用いられますが、ここでは最尤法による結果との整合性を確認するためMAP推定値も算出してみます。 事後分布のMAP推定値が最尤推定による結果と理論的に一致することについては以前の記事を参照してください。 b_MAP \u0026lt;- apply(posterior_fit0_2$b, c(2,3), function(x){ mode_x \u0026lt;- density(x)$x[which.max(density(x)$y)] }) colnames(b_MAP) \u0026lt;- c(\u0026#34;general\u0026#34;,\u0026#34;vocation\u0026#34;) t(b_MAP) ## Intercept sesmiddle seshigh write ## general 2.898204 -0.5127911 -1.224067 -0.05841702 ## vocation 5.059521 0.2740113 -1.028054 -0.11497210 一方、以前の記事でmultinom()を用いて同じ分析を行った結果が以下です。 ## Call: ## multinom(formula = prog2 ~ ses + write, data = ml) ## ## Coefficients: ## (Intercept) sesmiddle seshigh write ## general 2.852198 -0.5332810 -1.1628226 -0.0579287 ## vocation 5.218260 0.2913859 -0.9826649 -0.1136037 ## ## Std. Errors: ## (Intercept) sesmiddle seshigh write ## general 1.166441 0.4437323 0.5142196 0.02141097 ## vocation 1.163552 0.4763739 0.5955665 0.02221996 ## ## Residual Deviance: 359.9635 ## AIC: 375.9635 ## 両側Z検定の実行 z \u0026lt;- summary(test)$coefficients/summary(test)$standard.errors p \u0026lt;- (1 - pnorm(abs(z),0,1)) p ## (Intercept) sesmiddle seshigh write ## general 7.238305e-03 0.1147190 0.01186928 3.409451e-03 ## vocation 3.649650e-06 0.2703765 0.04947488 1.588023e-07 事後分布のMAP推定値とmultinom()による結果のcoefficients:を比較してみると、おおよそ一致していることがわかります。多少のずれはモンテカルロ誤差などの影響の範囲内と考えます。 このことから、最尤推定に基づく方法とベイズ統計からのアプローチの整合性が確認できました。 multinom()の際には有意差検定を実行していましたので、今回もパラメータが0より大きい(小さい)確率(Bayesian p-value)を算出しておきます。 posterior_fit0_2 \u0026lt;- rstan::extract(fit0) p_coef \u0026lt;- apply(posterior_fit0_2$b,c(2,3), function(x){ sum(x \u0026gt; 0)/length(x) }) rownames(p_coef) \u0026lt;- c(\u0026#34;Intercept\u0026#34;,\u0026#34;sesmiddle\u0026#34;,\u0026#34;seshigh\u0026#34;,\u0026#34;write\u0026#34;) colnames(p_coef) \u0026lt;- c(\u0026#34;general\u0026#34;,\u0026#34;vocation\u0026#34;) t(p_coef) ## ## Intercept sesmiddle seshigh write ## general 0.99325 0.11125 0.009 0.0015 ## vocation 1.00000 0.74550 0.041 0.0000 以上の結果の解釈はmultinom()の時より直感的で、例えば$b_{14}$に着目すると、 $b_{14}$は95%の確率で-0.10から-0.02の値をとる。また中央値は-0.06である。 $b_{14}$が0よりも大きい確率は0.15%である というように解釈できます。 これを知ったかめきちの感想が以下になります。 multinom()の時と比べてずっと分かりやすくないですか？？＞🐢 全結果を数式で表現しておきます(Bayesian p-valueに基づいて$^{***}$：0.1%有意、$^{**}$：1%有意、$^{*}$：5%有意)。 $$ \\cfrac{P(prog=general)}{P(prog=academic)} = \\rm{exp}(2.90^{***}-0.53(ses=middle) -1.19^{**}(ses=high) - 0.06^{**}write) $$ $$ \\cfrac{P(prog=vocation)}{P(prog=academic)} = \\rm{exp}(5.32^{***}-0.31(ses=middle); -1.00^{*}(ses=high) - 0.12^{***}write) $$ オッズ比の変量に着目 オッズ比の変量(説明変数が変化すると、オッズ比は何倍になるか)についても確認しておきます。こちらは事後分布の要約統計量ではなく、事後分布自体を視覚的に見てみることにします。また通常切片項は解釈に用いないため、図の描画では割愛します。 plot_title \u0026lt;- ggtitle(\u0026#34;Posterior distribution\u0026#34;, \u0026#34;with medians and 95% intervals\u0026#34;) mcmc_areas(as.matrix(fit0), pars = c(\u0026#34;ratio[2,1]\u0026#34;,\u0026#34;ratio[3,1]\u0026#34;,\u0026#34;ratio[4,1]\u0026#34;,\u0026#34;ratio[2,2]\u0026#34;,\u0026#34;ratio[3,2]\u0026#34;,\u0026#34;ratio[4,2]\u0026#34;),prob=0.95, area_method = \u0026#34;equal height\u0026#34;) + plot_title+ theme_bw(base_size=12) 上図の事後分布に表現された中央値、95%信頼区間を下で算出しておきます。 ratio_median \u0026lt;- apply(posterior_fit0_2$ratio, c(2,3), median) ratio_quant \u0026lt;- apply(posterior_fit0_2$ratio, c(2,3), quantile, prob=c(0.025, 0.975)) ratio_general \u0026lt;- rbind(ratio_median[,1], ratio_quant[,,1]) ratio_vocation \u0026lt;- rbind(ratio_median[,2],ratio_quant[,,2]) rownames(ratio_general) \u0026lt;- rownames(ratio_vocation) \u0026lt;- c(\u0026#34;median\u0026#34;,\u0026#34;2.5%\u0026#34;,\u0026#34;97.5%\u0026#34;) colnames(ratio_general) \u0026lt;- colnames(ratio_vocation) \u0026lt;- c(\u0026#34;Intercept\u0026#34;,\u0026#34;sesmiddle\u0026#34;,\u0026#34;seshigh\u0026#34;,\u0026#34;write\u0026#34;) ratio_odds \u0026lt;- list(general = ratio_general, vocation=ratio_vocation) show(ratio_odds) ## $general ## Intercept sesmiddle seshigh write ## median 18.08714 0.5897972 0.3041684 0.9428201 ## 2.5% 1.85266 0.2434086 0.1037669 0.9051025 ## 97.5% 166.69899 1.3964119 0.8242418 0.9836004 ## ## $vocation ## Intercept sesmiddle seshigh write ## median 204.48713 1.369324 0.3678701 0.8901682 ## 2.5% 23.69682 0.527517 0.1092642 0.8515944 ## 97.5% 1940.58136 3.594567 1.1219872 0.9260589 上図で一番目立つ$ratio[2,2]$に着目すると、これは$\\exp(b_{22})$ですので、 $$ \\cfrac{\\cfrac{P(prog=vocation(ses=middle))}{P(prog=academic(ses=middle))}}{\\cfrac{P(prog=vocation(ses=low))}{P(prog=academic(ses=low))}} $$ の事後分布を表現しています。 事後分布は95%ベイズ信頼区間内に1を含んでいますし、比較的幅が広い分布ですので、確信をもってこうだといえる結果が得られていないことがわかります。 一方で、$ratio[3,1]=\\exp(b_{21})$は幅が比較的狭く、95%ベイズ信頼区間内に1が含まれていません。このことから、 $$ \\cfrac{\\cfrac{P(prog=general(ses=high))}{P(prog=academic(ses=high))}}{\\cfrac{P(prog=general(ses=low))}{P(prog=academic(ses=low))}} $$ はより確信をもって1以下の代表値(MAP推定値や中央値)付近をとる、ということができます。 このように、ベイズ統計ではパラメータや求めたい値のとりうる分布を推定することができ、大変便利です。 結果の描画 最後に結果(確率に関する予測値の分布)の描画を行います。以下では各programが選ばれる確率を、事後分布の中央値を予測値として、50%ベイズ信頼区間とともに示しています。 library(ggplot2) library(RColorBrewer) p25 \u0026lt;- apply(posterior_fit0_2$pred, c(2,3), quantile, prob=c(0.25)) p50 \u0026lt;- apply(posterior_fit0_2$pred, c(2,3), median) p75 \u0026lt;- apply(posterior_fit0_2$pred, c(2,3), quantile, prob=c(0.75)) colnames(p25) \u0026lt;- paste0(c(\u0026#34;academic\u0026#34;,\u0026#34;general\u0026#34;,\u0026#34;vocation\u0026#34;),\u0026#34;_p25\u0026#34;) colnames(p50) \u0026lt;- paste0(c(\u0026#34;academic\u0026#34;,\u0026#34;general\u0026#34;,\u0026#34;vocation\u0026#34;),\u0026#34;_p50\u0026#34;) colnames(p75) \u0026lt;- paste0(c(\u0026#34;academic\u0026#34;,\u0026#34;general\u0026#34;,\u0026#34;vocation\u0026#34;),\u0026#34;_p75\u0026#34;) data1 \u0026lt;- data.frame(ses = rep(c(\u0026#34;low\u0026#34;,\u0026#34;middle\u0026#34;,\u0026#34;high\u0026#34;),each = 41), write = x_new[,-c(1:3)],y=p50[,\u0026#34;academic_p50\u0026#34;], ymax=p75[,\u0026#34;academic_p75\u0026#34;], ymin=p25[,\u0026#34;academic_p25\u0026#34;], facet=\u0026#34;academic\u0026#34;) data2 \u0026lt;- data.frame(ses = rep(c(\u0026#34;low\u0026#34;,\u0026#34;middle\u0026#34;,\u0026#34;high\u0026#34;),each = 41), write = x_new[,-c(1:3)],y=p50[,\u0026#34;general_p50\u0026#34;], ymax=p75[,\u0026#34;general_p75\u0026#34;], ymin=p25[,\u0026#34;general_p25\u0026#34;], facet=\u0026#34;general\u0026#34;) data3 \u0026lt;- data.frame(ses = rep(c(\u0026#34;low\u0026#34;,\u0026#34;middle\u0026#34;,\u0026#34;high\u0026#34;),each = 41), write = x_new[,-c(1:3)],y=p50[,\u0026#34;vocation_p50\u0026#34;], ymax=p75[,\u0026#34;vocation_p75\u0026#34;], ymin=p25[,\u0026#34;vocation_p25\u0026#34;], facet=\u0026#34;vocation\u0026#34;) cols = RColorBrewer::brewer.pal(3,\u0026#34;Dark2\u0026#34;) data_point \u0026lt;- ml %\u0026gt;% cbind(makedummies::makedummies(ml,basal_level = T, col = \u0026#34;prog\u0026#34;)) %\u0026gt;% select(c(ses, write, prog, prog_academic, prog_general, prog_vocation)) p0 \u0026lt;- ggplot() + theme_bw(base_size=11) + mapply( function(data){ geom_ribbon(data=data, aes(x=write, ymax=ymax, ymin=ymin, fill=ses), alpha=0.5) },list(data1,data2,data3) ) +mapply( function(data){ geom_line(data=data,aes(x=write, y=y, colour=ses)) },list(data1,data2,data3) ) + mapply( function(data,n){ geom_jitter(data=data,aes(x=write, y=data[,n], colour=ses),height=0.1, width=0, size=0.8) },list(data.frame(data_point, facet=\u0026#34;academic\u0026#34;),data.frame(data_point, facet=\u0026#34;general\u0026#34;),data.frame(data_point, facet=\u0026#34;vocation\u0026#34;)), list(4,5,6)) + facet_grid(facet~.) + scale_colour_manual(values=cols) + scale_fill_manual(values=cols) + theme(legend.position = \u0026#34;bottom\u0026#34;) + ylab(\u0026#34;Probability\u0026#34;) + labs(title = \u0026#34;With Rstan\u0026#34;) p0 multinom()による分析の際に描画した図を下に載せますが、この2つの結果はほぼ一致していることがわかります。 まとめ 本記事では多項ロジスティック回帰をRstanを用いて実行し、最尤法(multinom())による結果との比較を行い、ネイマン・ピアソン型統計とベイズ統計の違いを確認しました。 両者がやっていることは実質的には変わりありませんが、解釈の違いなどについては実感できたかと思います。 今後、今回の実装にさらに改良を加え、予測用のモデルを構築したいと思います。"
  },
  {
    url: "https://sucre-stat.com/2020/05/bayesintroduction/",
    title: "ベイズ統計モデリング入門",
    date: "2020-05-29T23:50:14-05:00",
    body: "ベイズ統計モデリング入門 はじめに 本記事では今後の記事でも頻繁に扱う予定のベイズ統計について理解してもらうため、その理論を簡単に説明します。 本記事の構成は以下の通りです。 はじめに ネイマン・ピアソン型統計とベイズ統計 ネイマン・ピアソン型統計 ベイズ統計 ネイマン・ピアソン型統計とベイズ統計の整合性 ネイマン・ピアソン型統計とベイズ統計の違い マルコフ連鎖モンテカルロ法(MCMC) Stanを用いたMCMCサンプリング まとめ ネイマン・ピアソン型統計とベイズ統計 統計学の流派は大きくネイマン・ピアソン型統計とベイズ統計の2つが存在します。 ネイマン・ピアソン型統計 ネイマン・ピアソン型統計では、母集団のパラメータ$\\theta$(母平均や母分散など)を未知ではあるが固定された値であると考え、母集団からの標本$x$を確率的な変動をもって実現した値であるととらえます。 そして、$\\theta$を固定したとき、観察されたデータ$x$がどの程度生じやすいかの指標として、尤度 $$ P(x | \\theta) $$ を計算し、尤度が最も大きくなる値$\\theta$を求めることで$\\theta$の最尤推定量とする手法が、最尤法と呼ばれる、ネイマン・ピアソン型統計において最も重要な手法になります。 最尤推定に限らず、平均値の差の検定のような問題あっても、A群とB群の平均値に差がない($\\mu_A = \\mu_B$)という帰無仮説を設定することから始まり、設定した仮説のもとで、観察されたデータがどの程度の確率で起こるかをP値として求め、帰無仮説の真偽を判定します。 ベイズ統計 ベイズ統計では、ネイマン・ピアソン型統計とは対照的に、データ$x$を確定的な実現値であると考え、母集団のパラメータ$\\theta$の方を確率的な分布を持った値であるとみなします。そのため、最終的に求めようとする対象は $$ P(\\theta|x) $$ となります。 この$P(\\theta|x)$ですが、ネイマン・ピアソン型統計の$P(x|\\theta)$とは扱いが少し異なります。ベイズ統計における$P(\\theta|x)$では「〇〇という条件のもと△△が得られる確率」における「〇〇」に対応する$x$が観測値として与えられています。また$P(\\theta|x)$は$\\theta$について積分すると1になります。このことから、$P(\\theta|x)$は$x$が与えられると決定される$\\theta$の確率密度関数もしくは確率質量関数ととらえることが出来ます。 一方、最尤推定における$P(x|\\theta)$については、「〇〇という条件のもと△△が得られる確率」における「△△」に対応する$x$が観測値として与えられています。よって、$\\theta$を1つの値に固定したとき、その値に応じて$x$の確率分布が変化することになりますが、$x$は観測値として与えられている為その分布自体が関心の対象となることはありません。より正確には、固定した$\\theta$に応じて変わる$x$の確率密度関数・確率質量関数の、観測値の点に対応する値のみが関心の対象となっているといえます。 このあたり、図示すると分かりやすいので、時間を見つけて更新したいです。 ベイズ統計では、ベイズの定理と呼ばれる下記式が$P(\\theta | x)$の推定に使用されます。 $$ P(\\theta | x) = \\cfrac{P(x | \\theta)P(\\theta)}{P(x)} $$ $P(\\theta|x)$を$\\theta$の事後分布、$P(\\theta)$を$\\theta$の事前分布と呼びます。$P(x | \\theta)$はネイマン・ピアソン型統計で紹介した尤度で、$\\theta$を特定の値としたときに実現値$x$が得られる確率を意味します。 右辺の分子$P(x)$はデータ$x$が得られる確率ですが、これは$\\theta$には依存しない、かつ未知の値であるため、$P(\\theta | x)$の正規化定数ととらえ、下記式に基づいて$P(\\theta | x)$を計算します。 $$ P(\\theta | x) \\propto P(x | \\theta)P(\\theta) = (尤度) × (事前分布) $$ ネイマン・ピアソン型統計とベイズ統計の整合性 以上がネイマン・ピアソン型統計とベイズ統計の理論上の違いになりますが、ここで両者のアプローチの整合性について触れておきます。 事後分布$P(\\theta|x)$の値が最大になる点$\\hat{\\theta}$はMAP推定値(maximum a posteriori estimate)と呼ばれますが、この値は$\\theta$の事前分布$P(\\theta)$を十分に分散が大きい正規分布や十分に幅の広い一様分布に設定することで無情報事前分布を指定すると、 $$ \\newcommand{\\argmax}{\\mathop{\\rm arg~max}\\limits} \\hat{\\theta} = \\argmax_{\\theta}~P(x|\\theta)P(\\theta) \\ = \\argmax_{\\theta}~ P(x|\\theta) $$ が成り立ちます。このことから、$\\hat{\\theta}$は最尤推定値と一致することがわかります。 ネイマン・ピアソン型統計とベイズ統計の違い ネイマン・ピアソン型統計とベイズ統計の分析上の違いをまとめておきます。 パラメータの解釈 ネイマン・ピアソン型統計ではパラメータは定数とみなします。前回の記事でも、モデルの係数はsummary(test)でCoefficients:に確定値、Std.Errorsに標準誤差が得られていました。この結果の解釈の仕方は、 「与えられたデータから推測される係数の値は(確定値)だ。ただし、同じ母集団から同じようにデータを取り直した場合、パラメータは(標準誤差)の分散をもって取得される」 となります。 一方、ベイズ統計では母集団のパラメータの分布が得られることから、 「パラメータがこの範囲である確率は何%だ」 もしくはより直接的に 「パラメータの確率密度関数の近似はこれだ」 といった解釈ができます。 この両者を比較すると、どちらが解釈しやすいでしょうか? 人間の直感で理解しやすいのは後者の場合ではないかと思います。そのため、意思決定のために統計学的な分析を行うとき、ベイズ統計を選ぶことには利点があると考えられます。 有意差問題 ネイマン・ピアソン型統計では平均値の差の検定の際などに有意確率P値に着目し、P値が$\\alpha$よりも小さければ帰無仮説を棄却、そうでなければ対立仮設を採択、といった判断を行います。 実はこの有意差検定、困ったことに、標本サイズを増やせばどんなに小さな平均値間の差であっても有意な差として検出できてしまうという問題があります。 これに対し、ベイズ統計からのアプローチでは、平均値の差という母集団のパラメータの確率分布を推定し、明示することができるため、ビックデータを扱う際にも、微小な平均値の差異は本当に有意なのか？といった問題から脱却することができます。 ベイズ推定では、標本数を増やすと求めたい分布は幅が狭くなっていく(より確信を持った分布を掲示できる)ため、ネイマン・ピアソン型統計よりもビックデータを有効活用できると考えられます。 手法(最尤法とMCMC)による違い ネイマン・ピアソン型統計では最尤法が頻繫に使用されますが、この手法は過学習に陥りやすいという問題があります。また、モデルが複雑な場合、最尤法では局所最適地に陥りやすく、最適化が困難になります。 一方、ベイズ統計では次節で説明するMCMCを利用してパラメータの分布を求めるため、上記の問題が解決できます。 マルコフ連鎖モンテカルロ法(MCMC) ベイズ統計では、パラメータの事後分布を求めることが目標となりますが、これを解析的に求めることは難しく、不可能であることも多いです。そのため、マルコフ連鎖モンテカルロ法(Malcov Chain Monte Carlo method、以下MCMC)というアルゴリズムを用います。 MCMCは、簡単に説明するとある確率分布に従う乱数を発生させるアルゴリズムです。これまでメトロポリス法、ギブスサンプラー、ハミルトニアンモンテカルロ法等様々なアルゴリズムが提案されていますが、ここではメトロポリス法を紹介し、MCMCがどのようなアルゴリズムなのか簡単に説明します。 以下のモデルを考えます。 $$ Y[n] \\sim \\rm{Normal}(\\mu, 1)~~~~n=1,\\ldots,N $$ $$ \\mu \\sim \\rm{Normal}(0, 100) $$ ここで、$Y$:従属変数の観測値、$X$:説明変数の観測値、$N$：サンプルサイズです。 事後確率$P(\\mu|Y)$は下記式で計算できます。 $$ P(\\mu | Y) \\propto P(Y | \\mu)P(\\mu) =\\left[ \\prod_{n=0}^{N} \\rm{Normal}(Y[n] | \\mu, 1)\\right] \\rm{Normal}(\\mu|0,100) $$ このモデルにメトロポリス法を適用した場合、以下のようなアルゴリズムになります。 [メトロポリス法] $\\mu$を任意の初期状態からはじめて、以下を繰り返す。 $\\Delta$を原点対象の確率密度から発生させる。 サンプル候補の$\\mu^{'}$を以下で定める。 $$ \\mu^{'} \\leftarrow \\mu + \\Delta $$ サンプル候補と現在で$P(\\mu|Y)$の比$r$を計算する。 $$ r \\leftarrow \\cfrac{\\left[ \\prod_{n=0}^{N} \\rm{Normal}(Y[n] | \\mu{'}, 1)\\right] × \\rm{Normal}(\\mu{'}|0,100)}{\\left[ \\prod_{n=0}^{N} \\rm{Normal}(Y[n] | \\mu, 1)\\right] × \\rm{Normal}(\\mu|0,100)} $$ $0 \\leq R \u0026lt; 1$の一郎乱数$R$を発生させる。$R\u0026lt;r$なら $$ \\mu \\leftarrow \\mu^{'} $$ とし、そうでなければ現在の状態をそのまま次の状態とし、$\\mu$を一つのmcmcサンプルとして保存する 最後の操作において、$r \\geqq 1$ のとき、$\\mu^{'}$は必ず採択されることになります。一方、$r \u0026lt; 1$のときでも確率$r$で$\\mu^{'}$が採択されるところが重要で、この設定により$\\mu^{'}$の局所的極大値に落ち着くことがなく、永遠にさまよい続けることになります。それでも、広い目で見ると$\\mu^{'}$は(尤度)×(事前分布)が最大になる値付近に近づき、その周辺でサンプリングし続けることになります。 最後に、予測対象である$P(\\mu | Y)$は、収集したMCMCサンプルの分布で近似されることになります。 Stanを用いたMCMCサンプリング Stanは、ベイズモデリングを行うために開発された汎用的な確率的プログラミング言語です。推定計算のアルゴリズムにはハミルトニアンモンテカルロ法の一実装であるNUTSが用いられます。 MCMCによるサンプリングの様相を把握するため、例としてあるデータに対し下記のモデル $$ Y[n] \\sim \\mathrm{Normal}(a + bX[n], \\sigma)~~~~n=1,\\ldots,N $$ を適用し、確率的プログラミング言語Stanを用いてベイズ統計・MCMCを実行したときのtraceplot(MCMCサンプルの値をとった折れ線グラフ)と、MCMCサンプルの分布を以下に示します。 まずは左側のtraceplotを確認します。 パラメータ毎に4つの折れ線がありますが、MCMCではサンプル列をいくつか並列で実行し、事後分布への収束を確認します。この1つのサンプル列をchainと呼び、ここではchain数が4となっています。 またtraceplotの左端を注意深く観察すると、サンプリングの初期ではあさっての値がサンプリングされていることがわかります。これはランダムに設定された初期値の影響を受けている為です。 そのためサンプリング初期の値は一般にサンプルから除外されます。この期間をwarm upと呼び、warm up後のMCMCサンプルが事後分布からサンプリングされたものであると考えます。 上のtraceplotでは設定したwarm up期間を背景を濃くすることで表現しています。 traceplotを見る限り、warm up後のMCMCサンプルは初期値の影響を受けていないことから、正しいwarm up期間を設定できていると分かります。またこれ以上iterationを増やしても事後分布の形状に違いは生まれないように思われます。 次に右側のMCMCサンプルの分布を確認します。 図では4つの確率密度分布が描画されており、これらは各chain毎にwarm upを除いたMCMCサンプルから作成した確率密度分布です。4つの密度分布は微妙な差がありますが、ほぼ同じ分布であることが分かります。 ベイズ統計において求める対象は、パラメータに関する分布であり、実際の分析においては全chainのMCMCサンプルを混合し、一つの分布として扱うことになります。 今回紹介した事例では、4つのchainがほぼ同じ部分をサンプリングし続けていること、chain毎のMCMCサンプルの分布がほぼ同じであることから、このMCMCは不変分布である事後分布に収束したと考えることが出来ます。 モデルや設定によっては上のtraceplotのようにならず、各chainが一つの値に収束しない場合もあります。そのような場合はモデルを再考したりする必要があります。 まとめ 本記事ではベイズ統計について、ネイマン・ピアソン型統計と比較しつつ説明をしました。 どうしても文章ばかりの記事になってしまい、「結局何をしているの？」となってしまったかもしれません。 次回の記事では実際にデータを用いてベイズ統計による分析を実施し、ネイマン・ピアソン型統計からのアプローチとの違いを確認したいと思います。"
  },
  {
    url: "https://sucre-stat.com/2020/05/multinom/",
    title: "multinom()を使った多項ロジスティック回帰",
    date: "2020-05-27T21:13:14-05:00",
    body: "multinom()を使った多項ロジスティック回帰 はじめに 回帰に関する記事です。本記事では多項ロジスティック回帰について扱います。 本記事の目次は以下の通りです。 はじめに 多項ロジスティック回帰の説明 データの入手と内容の確認 分析手法の検討 順序ロジスティック回帰 従属変数を2値に統合し、通常のロジスティック回帰を行う 分析の実行 結果の描画 まとめ 多項ロジスティック回帰の説明 多項ロジスティック回帰(multinomial logisticregression)は3つ以上の値をとる名義尺度\\(Y \\)を従属変数とし、説明変数\\(X\\)から\\(Y \\)のそれぞれの値をとる確率を説明しようとする回帰手法です。 今、$Y = (y_1,\\ldots,y_n,\\ldots, y_N)^T$、$X = (x_1,\\ldots, x_n,\\ldots, x_N)^T$とし、さらに $x_n = (x_{1n},\\ldots,x_{dn},\\ldots, x_{Dn})$とします。ここでNはサンプルサイズ、Dは説明変数の次元です。 $Y$のとる値が2値のみの場合はロジスティック回帰と呼ばれます。これはリンク関数としてロジスティック関数が用いられますが、一方で\\(Y\\)がとることのできる値の数が$K\\ge3$のとき多項ロジスティック回帰が用いられ、この場合ソフトマックス関数が用いられます。 多項ロジスティック回帰のモデル式は以下の通りです。 $$ \\mu_n = \\overrightarrow{a} + \\overrightarrow{b_1}x_{n1} + \\cdots + \\overrightarrow{b_d}x_{nd} + \\cdots + \\overrightarrow{b_D}x_{nD} $$ $$ \\theta_n = \\rm{softmax}(\\mu_n) $$ $$ y_n \\sim \\rm{Categorical}(\\theta_n) $$ $$ (n=1,\\ldots,N) $$ ここで $$ \\mu=(\\mu_1,\\ldots,\\mu_n,\\ldots,\\mu_N) $$ $$ \\theta=(\\theta_1,\\ldots,\\theta_n,\\ldots,\\theta_N) $$ $\\mu_n, \\theta_n,\\overrightarrow{a},\\overrightarrow{b_1},\\ldots,\\overrightarrow{b_D}$は長さKのベクトルです。 $μ$は一般化線形モデルの枠組みでは線形予測子と呼ばれる部分で、ここではK個の線形予測子が準備される形です。 ソフトマックス関数は下記式で与えられます。 $$ \\rm{softmax}(mu_n) = \\left(\\cfrac{\\exp(mu_{1n})}{\\sum_{k=1}^K \\exp(mu_{kn})}\\cdots\\cfrac{\\exp(mu_{Kn})}{\\sum_{k=1}^K \\exp(mu_{kn})} \\right) $$ ソフトマックス関数は各要素が$(0,1)$の範囲をとり合計1になる長さ$K$のベクトルであり、カテゴリカル分布に与える確率ベクトルとして用います。最終的には$Y$が$\\theta_n$を確率ベクトルとしてもつカテゴリカル分布に従うと仮定することになります。 なお、上記のモデルそのままでは$μ$の$K$個の要素が識別不可能であるため$Y$がとりうる$K$個の値それぞれにに対応させることができません。そのため、$K$個の要素のうち基準となる要素を一つ決め、 $μ$の$K$個の要素を識別できるように $$ a_k=b_{1k}=\\ldots=b_{Dk}=0 $$ $$ \\therefore~~ \\mu_{nk}=0~~~(n=1,\\ldots,N) $$ と基準とした要素を0に固定してやる必要があります($k$は0から$K$のどの値でも構いません)。よってパラメータ数は$(D+1)(K−1)$となります。 本記事はこちらのページを参考に作成しました。内容的にはほとんど同じで、つまりただ真似してやってみただけです…。 データの入手と内容の確認 SPSS、Stata等に蓄積されているデータをダウンロードするためのパッケージforeignを使ってデータを入手し、簡単に内容を確認しておきます。 library(foreign) ml \u0026lt;- read.dta(\u0026#34;https://stats.idre.ucla.edu/stat/data/hsbdemo.dta\u0026#34;) head(ml) ## id female ses schtyp prog read write math science socst honors ## 1 45 female low public vocation 34 35 41 29 26 not enrolled ## 2 108 male middle public general 34 33 41 36 36 not enrolled ## 3 15 male high public vocation 39 39 44 26 42 not enrolled ## 4 67 male low public vocation 37 37 42 33 32 not enrolled ## 5 153 male middle public vocation 39 31 40 39 51 not enrolled ## 6 51 female high public general 42 36 42 31 39 not enrolled ## awards cid ## 1 0 1 ## 2 0 1 ## 3 0 1 ## 4 0 1 ## 5 0 1 ## 6 0 1 with(ml, table(ses, prog)) ## prog ## ses general academic vocation ## low 16 19 12 ## middle 20 44 31 ## high 9 42 7 with(ml, do.call(rbind, tapply(write, prog, function(x) c(M=mean(x), SD=sd(x))))) ## M SD ## general 51.33333 9.397775 ## academic 56.25714 7.943343 ## vocation 46.76000 9.318754 このデータは200人の生徒について、性別等の属性や受賞数、読み書きの力を得点化したもの等がまとめられています。 今回は、general、academic、vocationの3つの授業プログラムの中から生徒が選択したプログラムの種類(prog)を従属変数とし、ses(経済的位置の3段階分類)、write(書く力を得点化したもの)を説明変数と設定します。 sesとprogのクロス集計表を見ると、いずれもsesにおいてもacademicが人気ですがses=highの子には特にacademicが人気なようです。 write毎のprogの平均、標準偏差を確認すると、やはりacademicを選んだ生徒は書く力が若干高いようです。 分析手法の検討 分析の目的は生徒の属性や能力が選択するプログラムにどのように影響してくるかを把握することですが、今回適用する多項ロジスティック回帰の他にいくつか別の手法も考えられます。 順序ロジスティック回帰 従属変数を順序データと解釈するモデルです。従属変数を$(Y =1,2,\\ldots,k)$といった順序型の変数とみなしたとき、このモデルから得られる結果は $$P_{(y_n=2,\u0026hellip;,K)} \\sim \\rm{Binomial}(q_{1n}),　q_n = \\rm{inverselogit}(a_1 + b_{1}x_{n1} + b_{2}x_{n2} +\\ldots + b_{D}x_{nD})$$ $$P_{(y_n=3,\u0026hellip;,K)} \\sim \\rm{Binomial}(q_{2n}),　q_n = \\rm{inverselogit}(a_2 + b_{1}x_{n1} + b_{2}x_{n2} +\\ldots + b_{D}x_{nD})$$ $$\\ldots$$ $$P_{(y_n=K)} \\sim \\rm{Binomial}(q_{(K-1)n}),　q_n = \\rm{inverselogit}(a_{K-1} + b_{1}x_{n1} + b_{2}x_{n2} +\\ldots + b_{D}x_{nD})$$ のk-1個の確率に関する回帰式となります。 上記モデルでは、$Y$を一つの順序型変数とみなすという設定に合わせ、解釈上の都合から(?)切片項以外の係数を全回帰式で同一としています。 今回のデータでは説明変数が通常の授業(general)、アカデミックな授業(academic)、職を持つための授業(vocation、高専のようなイメージ？)といった内容のものであるため、順序型データとはみなさないこととします。 従属変数を2値に統合し、通常のロジスティック回帰を行う 多項ロジスティック回帰は得られる結果の解釈が難しいという欠点があるため、より解釈がし易いようにデータを簡略化し、通常のロジスティック回帰に持ち込む方法です。今回の例ではacademicを選択する確率に着目し、generalとvocationを一つにまとめる、といったことが考えられます。 ここでは3つの授業を選択する確率同士の間に説明変数を介してどのような関係があるのかを把握することを選択し、多項ロジスティック回帰を選びます。 分析の実行 nnetパッケージのmultinom()を用いて分析していきます。nnetは最尤法を用いて単層のニュートラルネットワークを実行するためのパッケージで、multinom()は単層のニュートラルネットワークを介して多項対数線形モデルを行う関数です。$x_n$に着目したとき、単層のニュートラルネットワークのK個の中間層を $$ 中間層k = \\exp(\\overrightarrow{a_k} + \\overrightarrow{b_{1k}}x_{n1} + \\cdots + \\overrightarrow{b_{dk}}x_{nd} + \\cdots + \\overrightarrow{b_{Dk}}x_{nD})~~~k=1,\\ldots,K $$ 、出力層を $$ \\left(\\cfrac{exp(中間層1)}{\\sum_{k=1}^K 中間層k} \\cdots\\cfrac{exp(中間層K)}{\\sum_{k=1}^K 中間層k}\\right) $$ としてやれば多項ロジスティック回帰モデルと等価になる(はず…ニュートラルネットはよく知りません)ですので、中身はそのような形になっているものと思われます。 $\\mu$のK個の要素を識別可能とするため、下記の実行では$\\mu_{academic}=0$としています。 またmultinom()はp値を出力してくれないので、両側Z検定を行いp値を算出します。 library(nnet) #academicを基準に設定 ml$prog2 \u0026lt;- relevel(ml$prog, ref = \u0026#34;academic\u0026#34;) test \u0026lt;- multinom(formula = prog2 ~ ses + write, data=ml) ## # weights: 15 (8 variable) ## initial value 219.722458 ## iter 10 value 179.982880 ## final value 179.981726 ## converged summary(test) ## Call: ## multinom(formula = prog2 ~ ses + write, data = ml) ## ## Coefficients: ## (Intercept) sesmiddle seshigh write ## general 2.852198 -0.5332810 -1.1628226 -0.0579287 ## vocation 5.218260 0.2913859 -0.9826649 -0.1136037 ## ## Std. Errors: ## (Intercept) sesmiddle seshigh write ## general 1.166441 0.4437323 0.5142196 0.02141097 ## vocation 1.163552 0.4763739 0.5955665 0.02221996 ## ## Residual Deviance: 359.9635 ## AIC: 375.9635 #両側Z検定の実行 z \u0026lt;- summary(test)$coefficients/summary(test)$standard.errors p \u0026lt;- (1 - pnorm(abs(z),0,1)) p ## (Intercept) sesmiddle seshigh write ## general 7.238305e-03 0.1147190 0.01186928 3.409451e-03 ## vocation 3.649650e-06 0.2703765 0.04947488 1.588023e-07 結果は下記式に帰着します($^{***}$：0.1%有意、$^{**}$：1%有意、$^{*}$：5%有意)。 $$\\cfrac{P(prog=general)}{P(prog=academic)} = \\exp(2.85^{***}-0.53(ses=middle) -1.16^*(ses=high) - 0.06^{***}write)$$ $$\\cfrac{P(prog=vocation)}{P(prog=academic)} = \\exp(5.22^{***}-0.29(ses=middle) -0.98^*(ses=high) - 0.11^{***}write)$$ 上記の結果は、generalを選択する確率とacademicを選択する確率のオッズ比 $$\\cfrac{P(prog=general)}{P(prog=academic)}$$ に着目した場合、下記式のようにwriteの値が1増えるとオッズ比は0.94倍になる、というよう解釈できます。 $$\r\\cfrac{\\cfrac{P(prog=general(write=x+1))}{P(prog=academic(write=x+1))}}{\\cfrac{P(prog=general(write=x))}{P(prog=academic(write=x))}}\r= \\cfrac{\\exp(2.85 - 0.53(ses=middle) - 1.16(ses=high) - 0.06(write=x+1)}{\\exp(2.85 - 0.53(ses=middle) - 1.16(ses=high) - 0.06(write=x))}\r$$\r$$\r= \\exp(-0.06)\r\\fallingdotseq 0.94\r$$\r ロジスティック回帰のモデルは、このように、基準に設定した値を分母としたオッズ比からの解釈がしやすい点が特徴です。 そのほかの係数について確認しておくと、 $\\cfrac{P(prog=vocation)}{P(prog=academic)}$はwriteの値が1増加すると$\\exp(-0.11)\\fallingdotseq0.89$倍になる(有意)。 $\\cfrac{P(prog=general)}{P(prog=academic)}$は$ses=high$のとき、$ses=low$の時の$\\exp(-1.16)\\fallingdotseq0.31$倍の値をとる(有意)。 $\\cfrac{P(prog=vocation)}{P(prog=academic)}$は$ses=high$のとき、$ses=low$の時の$\\exp(-0.98)\\fallingdotseq0.38$倍の値をとる(有意)。 $\\cfrac{P(prog=general)}{P(prog=academic)}$は$ses=middle$のとき、$ses=low$の時の$\\exp(-0.53)\\fallingdotseq0.59$倍の値をとる。ただしこの値は1である可能性を捨てきれない $\\cfrac{P(prog=vocation)}{P(prog=academic)}$は$ses=middle$のとき、$ses=low$の時の$\\exp(-0.29)\\fallingdotseq0.74$倍の値をとる。ただしこの値は1である可能性を捨てきれない といった結果が得られています。 二番目の項目($\\cfrac{P(prog=general)}{P(prog=academic)}$と$ses=high,ses=low$の関係)については下記式から確認できます。 $$ \\cfrac{\\cfrac{P(prog=general(ses=high))}{P(prog=academic(ses=high))}}{\\cfrac{P(prog=general(ses=low))}{P(prog=academic(ses=low))}} = \\cfrac{\\exp(2.85 - 0.53\\times0 - 1.16\\times1 - 0.06(write)}{\\exp(2.85 - 0.53\\times0 - 1.16\\times0 - 0.06(write))} $$ $$ = \\exp(-1.16) \\fallingdotseq 0.31 $$ 結果の描画 結果の描画を行います。ses,writeの値が1組与えられた時の予測値はpredict()関数で算出できます(信頼区間を求めようとしたらnnet::predict()はpredict=“confidence\u0026quot;が使えませんでした…残念)。 以下では予測値の算出を行っていますが、今回のモデルは解釈しやすいように設計されたモデルです。予測用のモデルにが欲しいなら更なる改良モデルが存在します。 library(reshape2) library(ggplot2) library(RColorBrewer) #予測値を計算する点を準備 dwite \u0026lt;- data.frame(ses = rep(c(\u0026#34;low\u0026#34;,\u0026#34;middle\u0026#34;,\u0026#34;high\u0026#34;),each = 41), write = rep(c(30:70),3)) #predict()関数で予測値を計算し、予測を行う点dwiteと結合 pp.wite \u0026lt;- cbind(dwite, predict(test, newdata=dwite, type=\u0026#34;probs\u0026#34;, se = T)) #縦長データに変換し、ggplot()で描画 lpp \u0026lt;- reshape2::melt(pp.wite, id.vars = c(\u0026#34;ses\u0026#34;,\u0026#34;write\u0026#34;),value.name = \u0026#34;probability\u0026#34;) cols \u0026lt;= brewer.pal(3,\u0026#34;Dark2\u0026#34;) p0 \u0026lt;- ggplot(data=lpp,aes(x=write, y=probability,colour=ses)) + geom_line() + facet_grid(variable ~.) + theme_bw(base_size=11) + theme(legend.position = \u0026#34;bottom\u0026#34;) + scale_color_manual(values=cols) + labs(title=\u0026#34;With multinom\u0026#34;) p0 上図では3つの授業が選ばれる確率を別々に描画しています。同じ色の線がとる確率値の割をとると1になります。 図の全体的な傾向と前節で確認した内容に不一致は見られないようです。 まとめ 本記事では多項ロジスティック回帰モデルについて説明しました。 多項ロジスティック回帰は3つ以上の値をとる名義尺度$Y$を従属変数とし、説明変数$X$から$Y$のそれぞれの値をとる確率を説明しようとする回帰手法です。 また多項ロジスティック回帰自体は予測用のモデルではなく、あくまで解釈の為のモデルであることがポイントです。 本モデルを応用した予測用のモデルは今後の記事で紹介したいと思います。"
  },
  {
    url: "https://sucre-stat.com/",
    title: "SUCRE HECACHA",
    date: "2020-05-22T00:00:00Z",
    body: "SUCRE HECACHA"
  },
  {
    url: "https://sucre-stat.com/about/",
    title: "このブログについて",
    date: "2020-05-22T00:00:00Z",
    body: "このブログについて R.moritaです。 京都で悠々自適の生活がしたい若者です。 写真なんかも趣味にしています。 本ブログでは統計学やデータサイエンス等と呼ばれるものについて投稿していきたいと思っています。 ところで、「統計」とは何でしょうか？身の回りで「統計」に関するものといえば、総務省統計局(e-stat)や当局が公開している統計情報などの「収集された情報」を思い浮かばれるかもしれません。 しかし、「統計」モデリング、「統計的」機械学習などの用語があるように「統計」という言葉自体には「確率論に基づき深く調べる」といったニュアンスもあるようです。 私の興味の対象は「統計」のもつ後者の意味合いの方にあり、そちらの意味愛の方を昨今では「データサイエンス」と呼ぶ風潮があるようです。 本ブログの記事は特に断りが無い限りR及びRstudioを用います。2020/05/22時点での各ソフトのVersionは以下の通りです。 Rstudio：ver1.2.1335.0 R：ver3.6.1 Rstan：ver2.19.3 本ブログ内の記事は個人執筆のため、内容に誤りが含まれる場合があります。 指摘・質問歓迎です。お気づきの点がございましたらこちらにご連絡ください。 なお本ブログ内の数式表記ルールはその都度参考にしている文献に大きく影響を受けるため、ページ毎に大きく異なります。どうかお許しください。"
  },
  {
    url: "https://sucre-stat.com/search/data.js",
    title: "",
    date: "0001-01-01T00:00:00Z",
    body: ""
  },
  {
    url: "https://sucre-stat.com/categories/",
    title: "Categories",
    date: "0001-01-01T00:00:00Z",
    body: "Categories"
  },
  {
    url: "https://sucre-stat.com/contact/",
    title: "Contact",
    date: "0001-01-01T00:00:00Z",
    body: "Contact"
  },
  {
    url: "https://sucre-stat.com/search/",
    title: "Searches",
    date: "0001-01-01T00:00:00Z",
    body: "Searches"
  },
];