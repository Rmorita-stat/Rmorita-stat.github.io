<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>
        
        SUCRE HECACHA
        
    </title>
    <meta name="viewport" id="viewport" content="width=device-width, initial-scale=1">
    <link rel='icon' type='image/x-icon' href="https://rmorita-stat.github.io/images/logo2.png" />
    <link rel="apple-touch-icon" href="https://rmorita-stat.github.io/images/logo2.png"><link rel="stylesheet" href="https://rmorita-stat.github.io/scss/style.css">
    
    <link rel="stylesheet" href="https://rmorita-stat.github.io/css/syntax.css">
    <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
    <script src="https://rmorita-stat.github.io/js/highlight.min.js"></script>
    <link rel="stylesheet" href="https://rmorita-stat.github.io/scss/highlight.css">
    
    <link rel="stylesheet" href="https://rmorita-stat.github.io/scss/custom.css">
    
    
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'Your Google Analytics tracking id', 'auto');
        ga('send', 'pageview');
    </script>
    
    
    <meta name="generator" content="Hugo 0.71.0" /></head>


<body>
<div class="header">
    <div class="site-logo__wrap">
        <div id="site-button">
            <div></div>
        </div>
        
        <div class=' site-logo '>
            <a href="https://rmorita-stat.github.io/"><img src="https://rmorita-stat.github.io/images/logo.png" /></a>
        </div>
    </div>
    
<div class=' site-nav u-font ' id="nav-bar">
    
    <div class="site-nav__wrap">
        <a class="site-nav__el" href="/" >HOME</a>
    </div>
    
    <div class="site-nav__wrap">
        <a class="site-nav__el" href="/post" >BLOG</a>
    </div>
    
    <div class="site-nav__wrap">
        <a class="site-nav__el" href="/about" >ABOUT</a>
    </div>
    
    <div class="site-nav__wrap">
        <a class="site-nav__el" href="/tags/" >TAGS</a>
    </div>
    
</div>

</div>
<div class="main">

<div class="main-content">
    <div class="main-content__date">
        <h4 id="date"> 2020.07.12 00:00 </h4>
    </div>
    <div class="main-content__title">
        <h1 id="title">多項ロジスティック回帰・ガウス過程モデル</h1>
    </div>
    <div class="main-content__article">
        <article id="content">
            <h1 id="はじめに">はじめに</h1>
<p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/NE27zGsZ16U" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

いい夢の色は緑色だそうだ。私もうさぎさんにとっての牧草色の夢を見ることもありますが、現実は柵に引っかかってばかりです。</p>
<p>さて、<strong>回帰</strong>に関する記事です。</p>
<p><a href="https://rmorita-stat.github.io/2020/05/multinom/">以前の記事</a>では、対象が3つ以上のクラスに分類されるとき、それぞれのクラスに属する確率を予測するモデルである<strong>多項ロジスティック回帰</strong>について書きました。</p>
<p><a href="https://rmorita-stat.github.io/2020/05/multinom-rstan/">次の記事</a>では、同様のモデルを、<strong>マルコフ連鎖モンテカルロ法</strong>(MCMC)を実行するための汎用ソフトである<strong>Stan</strong>を用いて実装し、<strong>ベイズ統計</strong>の立場から分析しました。MCMCおよびベイズ統計については<a href="https://rmorita-stat.github.io/2020/05/bayesintroduction/">こちらの記事</a>で(走り書きで)書いています。</p>
<p>上で見た記事ではいずれも対象が各クラスに属する確率のオッズ比に着目し、オッズ比の線形性のみを考慮したモデルです。このように統計モデルでは変数の背後に何かしらの分布を想定したり、変数間に線形的な関係を想定したりすることでモデルを構築します。</p>
<p>一方で、特定の分布や関係を仮定せず、与えられたデータに柔軟に対応することのできるモデルも存在します。そのようなモデルの例として<a href="https://rmorita-stat.github.io/2020/06/gaussianprocess/">こちらの記事</a>では<strong>ガウス過程</strong>回帰について取り上げました。</p>
<p>またガウス過程を様々なデータやモデルに応用できるよう、<a href="https://rmorita-stat.github.io/2020/07/gaussianprocess2/">前回の記事</a>では<strong>ガウス過程潜在変数モデル</strong>や<strong>カテゴリカルな変数に対応できるカーネル</strong>、<strong>予測分布の計算方法</strong>について説明しました。</p>
<p>今回の記事はこれらの記事の内容をフル活用し、多項ロジスティック回帰にガウス過程を適用したモデルを実装します。</p>
<p>最終目標は、対象が各クラスに属する確率の予測値を、データに柔軟にフィットさせることです。</p>
<p>本記事の構成は以下の通りとします。</p>
<!-- raw HTML omitted -->
<ul>
<li><a href="#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB">はじめに</a></li>
<li><a href="#%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E5%85%A5%E6%89%8B">データの入手</a></li>
<li><a href="#%E5%A4%9A%E9%A0%85%E3%83%AD%E3%82%B8%E3%82%B9%E3%83%86%E3%82%A3%E3%83%83%E3%82%AF%E3%83%BB%E3%82%AC%E3%82%A6%E3%82%B9%E9%81%8E%E7%A8%8B%E3%83%A2%E3%83%87%E3%83%AB">多項ロジスティック・ガウス過程モデル</a>
<ul>
<li><a href="#%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E7%A2%BA%E8%AA%8D">モデルの確認</a></li>
<li><a href="#%E3%82%AB%E3%83%BC%E3%83%8D%E3%83%AB%E9%96%A2%E6%95%B0%E3%81%AE%E8%A8%AD%E5%AE%9A%E6%96%B9%E6%B3%95">カーネル関数の設定方法</a></li>
<li><a href="#%E3%83%A2%E3%83%87%E3%83%AB%EF%BC%91%E3%81%AE%E5%AE%9F%E8%A3%85%E3%81%A8%E7%B5%90%E6%9E%9C%E3%81%AE%E7%A2%BA%E8%AA%8D">モデル１の実装と結果の確認</a></li>
<li><a href="#%E3%83%A2%E3%83%87%E3%83%AB%EF%BC%92%E3%81%AE%E5%AE%9F%E8%A3%85%E3%81%A8%E7%B5%90%E6%9E%9C%E3%81%AE%E7%A2%BA%E8%AA%8D">モデル２の実装と結果の確認</a></li>
</ul>
</li>
<li><a href="#%E3%81%BE%E3%81%A8%E3%82%81">まとめ</a></li>
</ul>
<!-- raw HTML omitted -->
<p>当初本記事と<a href="https://rmorita-stat.github.io/2020/07/gaussianprocess2/">前回の記事</a>はひとつの記事として公開していましたが、余りにも長すぎる記事だったので、二つに分けて公開しなおしました。</p>
<h1 id="データの入手">データの入手</h1>
<p><a href="https://rmorita-stat.github.io/2020/05/multinom/">以前の記事</a>でRのnnetパッケージを使って多項ロジスティック回帰分析をしたときに用いたものと同じデータを用いますある学校の生徒の属性と各生徒が選択した授業に関するデータです。</p>
<div class="highlight"><pre class="chroma"><code class="language-r" data-lang="r"><span class="nf">library</span><span class="p">(</span><span class="n">foreign</span><span class="p">)</span>
<span class="n">ml</span> <span class="o">&lt;-</span> <span class="nf">read.dta</span><span class="p">(</span><span class="s">&#34;https://stats.idre.ucla.edu/stat/data/hsbdemo.dta&#34;</span><span class="p">)</span>
<span class="nf">head</span><span class="p">(</span><span class="n">ml</span><span class="p">)</span>

<span class="c1">##    id female    ses schtyp     prog read write math science socst       honors</span>
<span class="c1">## 1  45 female    low public vocation   34    35   41      29    26 not enrolled</span>
<span class="c1">## 2 108   male middle public  general   34    33   41      36    36 not enrolled</span>
<span class="c1">## 3  15   male   high public vocation   39    39   44      26    42 not enrolled</span>
<span class="c1">## 4  67   male    low public vocation   37    37   42      33    32 not enrolled</span>
<span class="c1">## 5 153   male middle public vocation   39    31   40      39    51 not enrolled</span>
<span class="c1">## 6  51 female   high public  general   42    36   42      31    39 not enrolled</span>
<span class="c1">##   awards cid</span>
<span class="c1">## 1      0   1</span>
<span class="c1">## 2      0   1</span>
<span class="c1">## 3      0   1</span>
<span class="c1">## 4      0   1</span>
<span class="c1">## 5      0   1</span>
<span class="c1">## 6      0   1</span>

</code></pre></div><p>今回も、general, academic, vocation の3つの授業の中から生徒が選択した結果(prog)を出力（目的変数）、write(書く力を得点化したもの)と家庭の経済状況の指標ses(low, middle, highに分類)の2変数を入力(説明変数)とし、モデルを組み立てていきます。</p>
<h1 id="多項ロジスティックガウス過程モデル">多項ロジスティック・ガウス過程モデル</h1>
<h2 id="モデルの確認">モデルの確認</h2>
<p>出力を$(N×1)$ベクトル$\mathrm{y}=(y_1,\ldots,y_N)^T$、入力を$(N×(I+J))$行列$\mathrm{W}=(\mathrm{w}_1,\ldots, \mathrm{w}_N)^T$とします。</p>
<p>$$
\mathrm{w}_n = (\mathrm{x}_n^T,\mathrm{z}_n^T) \tag{1}
$$</p>
<p>$\mathrm{x}_n$、$\mathrm{z}_n$はそれぞれ要素数$I$の質的変数、要素数$J$の質的変数です。</p>
<p>$$
\left(x_{n1},\ldots,x_{nI}\right)^T=\mathrm{x}_{n}
$$</p>
<p>$$
\left(z_{n1},\ldots,w_{nJ}\right)^T=\mathrm{w}_{n}
$$</p>
<p>$\mathrm{y}$が$K$個の値をとるとき、$\mathrm{y}$が各値をとる確率を表す$(N×K)$行列$\mathrm{\Theta}=(\mathrm{\theta}_1, \ldots, \mathrm{\theta}_K)$を導入します。</p>
<p>ここで$(\theta_{k1},\ldots,\theta_{kN})^T=\mathrm{\theta}_k~~~(k=1,\ldots,K)$です。</p>
<p>$$
\mathrm{y} \sim Categorical(\Theta)\tag{2}
$$</p>
<p>$\Theta$は1行の要素の和をとると1になるので、各要素が$(-\infty,\infty)$の値をとる$(N×K)$行列$\mathrm{P}=(\mathrm{p}_1,\ldots,\mathrm{p}_K)$を導入し、下記のようにします。</p>
<p>ここで、$(p_{k1},\ldots,p_{kN})^T=\mathrm{p}_k~~(k=1,\ldots,K)$です。</p>
<p>$$
(\theta_{1n},\ldots,\theta_{Kn})^T = softmax(\mathrm{P}_n^T)~~~(n=1,\ldots,N) \tag{3}
$$</p>
<p>ここで$(p_{1n},p_{2n},\ldots,p_{Kn})=\mathrm{P}_n$です。</p>
<p>ガウス過程で推定する対象は、上記モデルの$\mathrm{P}$になります。多項ロジスティック回帰では、出力が任意の特定の値をとる確率を固定する必要があったので、それを踏まえて下記のようにおきます。</p>
<p>$$
\mathrm{p}_k = \begin{cases}
0~~~\mathrm{if}~k=1\\<br>
\mathrm{L}\eta_k~~~\mathrm{if}~k=2,\ldots,K
\end{cases}\tag{4}
$$</p>
<p>$$
\mathrm{LL^T} = \mathrm{K}\tag{5}
$$</p>
<p>$$
\eta_k=(\eta_{k1},\ldots,\eta_{kN}) \sim Normal(0,1) ~~(k=2,\ldots,K)\tag{6}
$$</p>
<p>ここで、$\mathrm{K}$は$(N×N)$のカーネル行列で、$(m,n)$成分をカーネル関数$k(\mathrm{w}_m,\mathrm{w}_n)$とします。カーネル関数の設定を工夫することで、線形モデルから得られた知見やデータの特徴(カテゴリカル変数が含まれる点)などをモデルに反映させていきます。</p>
<h2 id="カーネル関数の設定方法">カーネル関数の設定方法</h2>
<p>本記事では2つのカーネル関数を設定し、2段階に分けて多項ロジスティック回帰・ガウス過程モデルを実行します。</p>
<h3 id="モデル１-線形カーネル--isotropic-correlationカーネル">モデル１ 線形カーネル + isotropic correlationカーネル</h3>
<p>量的変数writeの影響は線形カーネルで取り入れ、カテゴリカル変数sesの影響をPDUDEである$\mathrm{T}$で考慮する、という構造です。$\mathrm{T}$の各要素はisotropic correlation functionで出力されます。
<!-- raw HTML omitted -->  <br>
このカーネル関数をロジスティック回帰・ガウス過程モデルに用いることで、これまでの記事<a href="https://rmorita-stat.github.io/2020/05/multinom/">(1)</a>、<a href="https://rmorita-stat.github.io/2020/05/multinom-rstan/">(2)</a>で得られた結果と同じ結果が得られることを確認し、モデルの妥当性チェックを行います。</p>
<p>カーネル関数は下になります。</p>
<p>$$
\theta_1\sum_{i=1}^{I}x_{mi}x_{ni} + \theta_2\sum_{j=1}^J\mathrm{T}(z_{nj},z_{mj}) = k(\mathrm{w}_m,\mathrm{w}_n) \tag{7}
$$</p>
<p>ここで、</p>
<p>$$
\mathrm{T} = \left(
\begin{array}{ccc}
1 &amp; c &amp; \cdots &amp; c \\<br>
c &amp; 1 &amp; \cdots &amp; c  \\<br>
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>
c &amp; c &amp; \cdots &amp; 1
\end{array}
\right)\tag{8}
$$</p>
<p>は、<a href="https://rmorita-stat.github.io/2020/07/gaussianprocess2/">前回の記事</a>の式$(22)$、$(23)$あたりで説明したものす。</p>
<p>ハイパーパラメータは$\theta_1$、$\theta_2$、$c$の3つです。<br>
なお、$(7)$式第一項の線形カーネルの部分は、ガウス過程として扱わないで前回の記事の式$(1&rsquo;)$の$\beta\mathrm{f}(\mathrm{w})$で扱うこともできるのですが、今回はフルガウス過程で実行してみます。</p>
<h3 id="モデル２-線形カーネル--ガウスカーネル--isotropic-correlationカーネル">モデル２ 線形カーネル + (ガウスカーネル × isotropic correlationカーネル)</h3>
<p>量的変数writeの影響をモデル１のように線形的に把握するだけでなく、線形モデルでは誤差として扱われてしまう要素まで結果に取り入れるため、線形カーネルとガウスカーネルを組み合わせて量的変数の影響を予測します。質的変数の影響はモデル１と同様にisotropic correlationカーネルで予測します。</p>
<p>カーネル関数は下になります。</p>
<p>$$
\theta_1\sum_{i=1}^{I}x_{mi}x_{ni} +\theta_2exp\left(-\cfrac{1}{2\rho^2}\sum_{i=1}^{I}(x_{im}-x_{in})^2-\sum_{j=1}^{J}ln\left(\cfrac{1}{c}\right)I[r\neq{s}]\right)　\tag{9}
$$</p>
<p>ハイパーパラメータは$\theta_1$,$\theta2$,$\rho$,$c$の4つです。</p>
<h2 id="モデル１の実装と結果の確認">モデル１の実装と結果の確認</h2>
<p>モデル１を実行するStanコードを以下のようになります。</p>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="c1">//model2
</span><span class="c1"></span><span class="n">data</span><span class="p">{</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">2</span><span class="o">&gt;</span> <span class="n">K</span><span class="p">;</span> <span class="c1">//カテゴリ数
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">N1</span><span class="p">;</span> <span class="c1">//データ数
</span><span class="c1"></span>  <span class="kt">int</span> <span class="n">N2</span><span class="p">;</span> <span class="c1">//予測入力数
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">I</span><span class="p">;</span> <span class="c1">//量的変数の数
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">J</span><span class="p">;</span> <span class="c1">//質的変数の数
</span><span class="c1"></span>  <span class="kt">int</span> <span class="n">M</span><span class="p">[</span><span class="n">J</span><span class="p">];</span> <span class="c1">//各質的変数のカテゴリ数
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">K</span><span class="o">&gt;</span> <span class="n">y</span><span class="p">[</span><span class="n">N1</span><span class="p">];</span> <span class="c1">//出力ラベル
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">&gt;</span> <span class="n">x1_j</span><span class="p">[</span><span class="n">N1</span><span class="p">,</span><span class="n">J</span><span class="p">];</span> <span class="c1">//入力(質的変数)
</span><span class="c1"></span>  <span class="n">vector</span><span class="p">[</span><span class="n">I</span><span class="p">]</span> <span class="n">x1_i</span><span class="p">[</span><span class="n">N1</span><span class="p">];</span><span class="c1">//入力(量的変数)
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">&gt;</span> <span class="n">x2_j</span><span class="p">[</span><span class="n">N2</span><span class="p">,</span><span class="n">J</span><span class="p">];</span> <span class="c1">//予測したい点(質的変数)
</span><span class="c1"></span>  <span class="n">vector</span><span class="p">[</span><span class="n">I</span><span class="p">]</span> <span class="n">x2_i</span><span class="p">[</span><span class="n">N2</span><span class="p">];</span> <span class="c1">//予測したい点(量的変数)
</span><span class="c1"></span><span class="p">}</span>

<span class="n">transformed</span> <span class="n">data</span><span class="p">{</span>
  <span class="n">real</span> <span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-9</span><span class="p">;</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">N</span> <span class="o">=</span> <span class="n">N1</span> <span class="o">+</span> <span class="n">N2</span><span class="p">;</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">&gt;</span> <span class="n">x_j</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">J</span><span class="p">];</span> <span class="c1">//入力(質的変数)と予測入力(質的変数)を縦に繋げたもの
</span><span class="c1"></span>  <span class="n">vector</span><span class="p">[</span><span class="n">I</span><span class="p">]</span> <span class="n">x_i</span><span class="p">[</span><span class="n">N</span><span class="p">];</span> <span class="c1">//入力(量的変数)と予測入力(量的変数)を縦に繋げたもの
</span><span class="c1"></span>
  <span class="c1">//以下でx1_iとx2_i,x1_jとx2_jを縦に結合し、新たな行列x_i,x_jをそれぞれ作成する
</span><span class="c1"></span>  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N1</span><span class="p">){</span>
    <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">J</span><span class="p">){</span>
      <span class="n">x_j</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">x1_j</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N2</span><span class="p">){</span>
    <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">J</span><span class="p">){</span>
      <span class="n">x_j</span><span class="p">[(</span><span class="n">N1</span><span class="o">+</span><span class="n">n</span><span class="p">),</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">x2_j</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N1</span><span class="p">)</span> <span class="n">x_i</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">x1_i</span><span class="p">[</span><span class="n">n</span><span class="p">];</span>  
  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N2</span><span class="p">)</span> <span class="n">x_i</span><span class="p">[</span><span class="n">N1</span><span class="o">+</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">x2_i</span><span class="p">[</span><span class="n">n</span><span class="p">];</span>


<span class="p">}</span>

<span class="n">parameters</span><span class="p">{</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">N</span><span class="p">]</span> <span class="n">eta</span><span class="p">[(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)];</span> <span class="c1">//潜在変数
</span><span class="c1"></span>  <span class="n">vector</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="o">&gt;</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="n">theta</span><span class="p">;</span>
  <span class="n">vector</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">[</span><span class="n">J</span><span class="p">]</span> <span class="n">C</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">transformed</span> <span class="n">parameters</span><span class="p">{</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">N</span><span class="p">]</span> <span class="n">f</span><span class="p">[(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)];</span>
  <span class="n">row_vector</span><span class="p">[</span><span class="n">K</span><span class="p">]</span> <span class="n">p</span><span class="p">[</span><span class="n">N</span><span class="p">];</span> <span class="c1">//ソフトマックス関数に投げる値
</span><span class="c1"></span>
  <span class="c1">//この中でカーネル関数を定義、ガウス過程の関数fを作成
</span><span class="c1"></span>  <span class="p">{</span>
    <span class="n">matrix</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">]</span> <span class="n">L_K</span><span class="p">[(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)];</span>
    <span class="n">matrix</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">]</span><span class="n">linear_kernel</span><span class="p">;</span>
    <span class="n">matrix</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">]</span><span class="n">isotropic_correlation_kernel</span> <span class="o">=</span> <span class="n">rep_matrix</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">);</span><span class="c1">//初期値を0に設定。
</span><span class="c1"></span>    <span class="n">matrix</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">]</span> <span class="n">kernel_matrix</span><span class="p">[(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)];</span>
    <span class="n">matrix</span><span class="p">[</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">),</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span> <span class="n">PDUDE</span><span class="p">[</span><span class="n">J</span><span class="p">];</span>

    <span class="c1">//compound symmetric correlation matrix を作成
</span><span class="c1"></span>    <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">J</span><span class="p">){</span>
      <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)){</span>
      <span class="n">PDUDE</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
      <span class="k">for</span><span class="p">(</span><span class="n">m</span> <span class="n">in</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)){</span>
        <span class="n">PDUDE</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">=</span> <span class="n">C</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
        <span class="n">PDUDE</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">PDUDE</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">];</span>
        <span class="p">}</span>
      <span class="p">}</span>
      <span class="n">PDUDE</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">),</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>


    <span class="c1">//isotropic_correlation_kernelを生成
</span><span class="c1"></span>    <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">J</span><span class="p">){</span>
      <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
        <span class="k">for</span><span class="p">(</span><span class="n">m</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
          <span class="n">isotropic_correlation_kernel</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">+=</span> <span class="n">PDUDE</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">x_j</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">],</span><span class="n">x_j</span><span class="p">[</span><span class="n">m</span><span class="p">,</span><span class="n">j</span><span class="p">]];</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span>

    <span class="c1">//linear_kernel_matrixを生成。切片項はisotropic_correlation_kernelで捉えることにした
</span><span class="c1"></span>    <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
      <span class="k">for</span><span class="p">(</span><span class="n">m</span> <span class="nl">in1</span><span class="p">:</span><span class="n">N</span><span class="p">){</span>
        <span class="n">linear_kernel</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">=</span> <span class="n">dot_product</span><span class="p">(</span><span class="n">x_i</span><span class="p">[</span><span class="n">n</span><span class="p">],</span><span class="n">x_i</span><span class="p">[</span><span class="n">m</span><span class="p">]);</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="c1">//kernel_matrixを作成
</span><span class="c1"></span>    <span class="k">for</span><span class="p">(</span><span class="n">k</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)){</span>
      <span class="n">kernel_matrix</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">linear_kernel</span> <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">isotropic_correlation_kernel</span><span class="p">;</span>
      <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
        <span class="n">kernel_matrix</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="n">delta</span><span class="p">;</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">for</span><span class="p">(</span><span class="n">k</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)){</span>
      <span class="n">L_K</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">cholesky_decompose</span><span class="p">(</span><span class="n">kernel_matrix</span><span class="p">[</span><span class="n">k</span><span class="p">]);</span>
      <span class="n">f</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">L_K</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">eta</span><span class="p">[</span><span class="n">k</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="c1">// pの作成 1列目は0に固定 2列目以降に独立のガウス過程を指定
</span><span class="c1"></span>  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
     <span class="n">p</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
     <span class="k">for</span><span class="p">(</span><span class="n">k</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)){</span>
        <span class="n">p</span><span class="p">[</span><span class="n">n</span><span class="p">,(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">];</span>
     <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="n">model</span><span class="p">{</span>
  <span class="c1">//事前分布
</span><span class="c1"></span>  <span class="n">theta</span> <span class="o">~</span> <span class="n">student_t</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
  <span class="n">C</span> <span class="o">~</span> <span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">);</span>

  <span class="c1">//モデル部分
</span><span class="c1"></span>  <span class="k">for</span><span class="p">(</span><span class="n">k</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)){</span>
    <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
      <span class="n">eta</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">]</span> <span class="o">~</span> <span class="n">std_normal</span><span class="p">();</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N1</span><span class="p">){</span>
    <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">~</span> <span class="n">categorical_logit</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="err">&#39;</span><span class="p">);</span>
  <span class="p">}</span>

<span class="p">}</span>

<span class="n">generated</span> <span class="n">quantities</span><span class="p">{</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">K</span><span class="p">]</span> <span class="n">pred</span><span class="p">[</span><span class="n">N2</span><span class="p">];</span>
  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N2</span><span class="p">){</span>
    <span class="n">pred</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">p</span><span class="p">[(</span><span class="n">N1</span><span class="o">+</span><span class="n">n</span><span class="p">)]</span><span class="err">&#39;</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>

</code></pre></div><p>入力データを命令する<code>data{}</code>ブロックでは、入力データ(<code>x1_i</code>、<code>x1_j</code>)を量的変数・質的変数で分けて指定しています。また、予測したい入力点(<code>x2_i</code>、<code>x2_j</code>)も指定しています。</p>
<p><code>transformes data{}</code>ブロックでは、式$(12)$の計算を実行するため、入力(実現値)と予測したい入力点のデータを量的変数・質的変数毎に縦に繋げています。</p>
<p><code>transformed parameter{}</code>ブロックでは、まず、式$(8)$の行列を<code>PDUDE</code>という呼称で作成しています。次に、<code>issotropic_correlation_kernel</code>として、<code>PDUDE</code>を参照しながらcompound symmetric correlation matrixを作成しています。
<!-- raw HTML omitted -->  <br>
また、<code>linear_kernel</code>として線形カーネルの要素を作成しています。線形カーネルはStanに実行された<code>dot_product()</code>が便利です。
<!-- raw HTML omitted -->  <br>
さらに、<code>kernel_matrix</code>として式$(7)$のカーネル関数を各要素に持つカーネル関数を作成します。
このように、線形カーネル・isotropic_correlation_kernelカーネルを作成し、それらを結合させてカーネル行列を作成し、最後に既述の方法でガウス過程に従う$\mathrm{f}$の定義までを<code>transformed parameter{}</code>で命令しています。</p>
<p><code>model{}</code>ブロックでは、まず事前分布を式$(7)$の$\theta_1$、$\theta_2$、式$(8)$の$c$で、適当に指定しています。
また、前回記事式$(9)$中段の設定を<code>eta ~ std_normal()</code>として指定し、多項ロジスティック回帰モデルの式$(2)$、式$(3)$を<code>y[n] ~ categorical_logit(p[n]')</code>としています。</p>
<p><code>generated quantities{}</code>ブロックでは、<code>model</code>ブロックでは作成しなかった入力点<code>x2_i</code>、<code>x2_j</code>における予測値を<code>pred</code>として指定しています。</p>
<p>このStanファイルを実行するコードは以下になります。</p>
<div class="highlight"><pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># progの3要素を数字に置き換えるための表を作成</span>
<span class="n">progid</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">)</span>
<span class="nf">names</span><span class="p">(</span><span class="n">progid</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;academic&#34;</span><span class="p">,</span><span class="s">&#34;general&#34;</span><span class="p">,</span><span class="s">&#34;vocation&#34;</span><span class="p">)</span>
<span class="c1"># sesの3要素を数字に置き換えるための表を作成</span>
<span class="n">sesid</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">)</span>
<span class="nf">names</span><span class="p">(</span><span class="n">sesid</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;low&#34;</span><span class="p">,</span><span class="s">&#34;middle&#34;</span><span class="p">,</span><span class="s">&#34;high&#34;</span><span class="p">)</span>


<span class="nf">library</span><span class="p">(</span><span class="n">makedummies</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">tidyr</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>

<span class="n">d2</span> <span class="o">&lt;-</span> <span class="n">ml</span> <span class="o">%&gt;%</span> <span class="nf">mutate</span><span class="p">(</span><span class="n">sesid</span> <span class="o">=</span> <span class="n">sesid</span><span class="nf">[paste</span><span class="p">(</span><span class="n">ses</span><span class="p">)</span><span class="n">]</span><span class="p">)</span> <span class="o">%&gt;%</span>
  <span class="nf">mutate</span><span class="p">(</span><span class="n">progid</span> <span class="o">=</span> <span class="n">progid</span><span class="nf">[paste</span><span class="p">(</span><span class="n">prog</span><span class="p">)</span><span class="n">]</span><span class="p">)</span> <span class="o">%&gt;%</span> <span class="nf">mutate</span><span class="p">(</span><span class="n">write</span><span class="o">=</span><span class="p">(</span><span class="n">write</span><span class="o">-</span><span class="nf">mean</span><span class="p">(</span><span class="n">write</span><span class="p">))</span><span class="o">/</span><span class="nf">sd</span><span class="p">(</span><span class="n">write</span><span class="p">))</span> <span class="o">%&gt;%</span> <span class="nf">select</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">sesid</span><span class="p">,</span> <span class="n">write</span><span class="p">,</span> <span class="n">progid</span><span class="p">))</span>

<span class="c1">#x1:入力点</span>
<span class="n">x1_j</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">d2[</span><span class="p">,</span><span class="o">-</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">3</span><span class="p">)</span><span class="n">]</span><span class="p">)</span> <span class="c1"># 入力(質的変数)</span>
<span class="n">x1_i</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">d2[</span><span class="p">,</span><span class="o">-</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">3</span><span class="p">)</span><span class="n">]</span><span class="p">)</span> <span class="c1"># 入力(量的変数)</span>
<span class="n">N1</span> <span class="o">&lt;-</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">x1_i</span><span class="p">)</span>
<span class="c1">#x2:予測入力点</span>
<span class="n">x2_j</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">sesid</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="p">,</span><span class="m">41</span><span class="p">),</span><span class="nf">rep</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">41</span><span class="p">),</span><span class="nf">rep</span><span class="p">(</span><span class="m">3</span><span class="p">,</span><span class="m">41</span><span class="p">)))</span> <span class="c1"># 予測入力点(質的変数)</span>
<span class="n">x2_i</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">write</span> <span class="o">=</span> <span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">30</span><span class="o">:</span><span class="m">70</span><span class="p">),</span><span class="m">3</span><span class="p">)</span><span class="o">-</span><span class="nf">mean</span><span class="p">(</span><span class="n">ml</span><span class="o">$</span><span class="n">write</span><span class="p">))</span><span class="o">/</span><span class="nf">sd</span><span class="p">(</span><span class="n">ml</span><span class="o">$</span><span class="n">write</span><span class="p">))</span> <span class="c1"># 予測入力点(量的変数)</span>
<span class="n">N2</span> <span class="o">&lt;-</span> <span class="nf">nrow</span><span class="p">(</span><span class="n">x2_i</span><span class="p">)</span>

<span class="c1">#y:出力点</span>
<span class="n">y</span> <span class="o">&lt;-</span> <span class="n">d2[</span><span class="p">,</span><span class="m">3</span><span class="n">]</span>
<span class="n">K</span> <span class="o">&lt;-</span> <span class="m">3</span>
<span class="n">J</span> <span class="o">&lt;-</span> <span class="m">1</span> <span class="c1">#質的変数の数</span>
<span class="n">I</span> <span class="o">&lt;-</span> <span class="m">1</span> <span class="c1">#量的変数の数</span>
<span class="n">M</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">)</span> <span class="c1">#各量的変数のカテゴリ数</span>
<span class="nf">dim</span><span class="p">(</span><span class="n">M</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="m">1</span>

<span class="n">data</span> <span class="o">&lt;-</span> <span class="nf">list</span><span class="p">(</span><span class="n">x1_i</span><span class="o">=</span><span class="n">x1_i</span><span class="p">,</span><span class="n">x1_j</span><span class="o">=</span><span class="n">x1_j</span><span class="p">,</span><span class="n">x2_i</span> <span class="o">=</span> <span class="n">x2_i</span><span class="p">,</span><span class="n">x2_j</span><span class="o">=</span><span class="n">x2_j</span><span class="p">,</span><span class="n">N1</span><span class="o">=</span><span class="n">N1</span><span class="p">,</span><span class="n">N2</span><span class="o">=</span><span class="n">N2</span><span class="p">,</span><span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">J</span><span class="o">=</span><span class="n">J</span><span class="p">,</span><span class="n">I</span><span class="o">=</span><span class="n">I</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>

<span class="nf">rstan_options</span><span class="p">(</span><span class="n">auto_write</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
<span class="nf">options</span><span class="p">(</span><span class="n">mc.cores</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">::</span><span class="nf">detectCores</span><span class="p">())</span>
<span class="n">fit_cate1</span> <span class="o">&lt;-</span> <span class="nf">stan</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="s">&#34;model2.stan&#34;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">pars</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;pred&#34;</span><span class="p">,</span><span class="s">&#34;theta&#34;</span><span class="p">,</span><span class="s">&#34;C&#34;</span><span class="p">),</span> <span class="n">warmup</span> <span class="o">=</span> <span class="m">400</span><span class="p">,</span> <span class="n">iter</span> <span class="o">=</span> <span class="m">1500</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="m">4</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="m">1234</span><span class="p">)</span>
</code></pre></div><p>計算にかかった時間はsurface laptop2 Corei5-8250Uで約3000秒でした。
ガウス過程は逆行列の計算などを含むので、工夫をしないとどうしても計算に時間がかかってしまうようです。</p>
<p>ハイパーパラメータの事後分布は以下のようになりました。</p>
<p><img src="/post/multinom-gp/fit_cate1_density.png" alt=""></p>
<p>予測結果は以下のようになりました。描画の為のコードは<a href="https://rmorita-stat.github.io/2020/05/multinom-rstan/">以前の記事</a>を参照してください。</p>
<p><img src="/post/multinom-gp/fit_cate1_res.png" alt=""></p>
<p>rのパッケージnnetのmultinom()関数を使ったときや、Rstanで線形予測子Versionの多項ロジスティック回帰を実行したときの結果と同じ結果が得られていることが分かります。</p>
<p>以上、sotropic correlationカーネルを含んだモデル全体が正常に動くことを確認し、次の分析に進みます。</p>
<h2 id="モデル２の実装と結果の確認">モデル２の実装と結果の確認</h2>
<p>モデル２を実行するStanコードを以下のようになります。</p>
<div class="highlight"><pre class="chroma"><code class="language-c" data-lang="c"><span class="c1">//model3
</span><span class="c1"></span><span class="n">data</span><span class="p">{</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">2</span><span class="o">&gt;</span> <span class="n">K</span><span class="p">;</span> <span class="c1">//カテゴリ数
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">N1</span><span class="p">;</span> <span class="c1">//入力データの数
</span><span class="c1"></span>  <span class="kt">int</span> <span class="n">N2</span><span class="p">;</span> <span class="c1">//予測したい入力点の数
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">I</span><span class="p">;</span> <span class="c1">//量的変数の数
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">J</span><span class="p">;</span> <span class="c1">//質的変数の数
</span><span class="c1"></span>  <span class="kt">int</span> <span class="n">M</span><span class="p">[</span><span class="n">J</span><span class="p">];</span> <span class="c1">//各質的変数のカテゴリ数
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">K</span><span class="o">&gt;</span> <span class="n">y</span><span class="p">[</span><span class="n">N1</span><span class="p">];</span> <span class="c1">//出力ラベル
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">&gt;</span> <span class="n">x1_j</span><span class="p">[</span><span class="n">N1</span><span class="p">,</span><span class="n">J</span><span class="p">];</span> <span class="c1">//入力(質的変数)
</span><span class="c1"></span>  <span class="n">vector</span><span class="p">[</span><span class="n">I</span><span class="p">]</span> <span class="n">x1_i</span><span class="p">[</span><span class="n">N1</span><span class="p">];</span><span class="c1">//入力(量的変数)
</span><span class="c1"></span>  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">&gt;</span> <span class="n">x2_j</span><span class="p">[</span><span class="n">N2</span><span class="p">,</span><span class="n">J</span><span class="p">];</span> <span class="c1">//予測した入力点(質的変数)
</span><span class="c1"></span>  <span class="n">vector</span><span class="p">[</span><span class="n">I</span><span class="p">]</span> <span class="n">x2_i</span><span class="p">[</span><span class="n">N2</span><span class="p">];</span> <span class="c1">//予測したい入力点(量的変数)
</span><span class="c1"></span><span class="p">}</span>

<span class="n">transformed</span> <span class="n">data</span><span class="p">{</span>
  <span class="n">real</span> <span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-9</span><span class="p">;</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span> <span class="n">N</span> <span class="o">=</span> <span class="n">N1</span> <span class="o">+</span> <span class="n">N2</span><span class="p">;</span>
  <span class="kt">int</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">&gt;</span> <span class="n">x_j</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">J</span><span class="p">];</span> <span class="c1">//入力(質的変数)と予測入力(質的変数)を縦に繋げたもの
</span><span class="c1"></span>  <span class="n">vector</span><span class="p">[</span><span class="n">I</span><span class="p">]</span> <span class="n">x_i</span><span class="p">[</span><span class="n">N</span><span class="p">];</span> <span class="c1">//入力(量的変数)と予測入力(量的変数)を縦に繋げたもの
</span><span class="c1"></span>  <span class="n">matrix</span><span class="p">[</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">),</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span> <span class="n">inv_I</span><span class="p">;</span> <span class="c1">//対角成分が0、それ以外が1の行列を生成
</span><span class="c1"></span>
  <span class="c1">//以下でx1_iとx2_i,x1_jとx2_jを縦に結合し、新たな行列x_i,x_jをそれぞれ作成する
</span><span class="c1"></span>  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N1</span><span class="p">){</span>
    <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">J</span><span class="p">){</span>
      <span class="n">x_j</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">x1_j</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N2</span><span class="p">){</span>
    <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">J</span><span class="p">){</span>
      <span class="n">x_j</span><span class="p">[(</span><span class="n">N1</span><span class="o">+</span><span class="n">n</span><span class="p">),</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">x2_j</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N1</span><span class="p">)</span> <span class="n">x_i</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">x1_i</span><span class="p">[</span><span class="n">n</span><span class="p">];</span>  
  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N2</span><span class="p">)</span> <span class="n">x_i</span><span class="p">[</span><span class="n">N1</span><span class="o">+</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">x2_i</span><span class="p">[</span><span class="n">n</span><span class="p">];</span>

  <span class="c1">//inv_Iの作成
</span><span class="c1"></span>  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)){</span>
    <span class="n">inv_I</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="n">m</span> <span class="n">in</span> <span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">:</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)){</span>
      <span class="n">inv_I</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
      <span class="n">inv_I</span><span class="p">[</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="n">inv_I</span><span class="p">[</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">),</span><span class="n">max</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

<span class="p">}</span>

<span class="n">parameters</span><span class="p">{</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">N</span><span class="p">]</span> <span class="n">eta</span><span class="p">[(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)];</span> <span class="c1">//潜在変数
</span><span class="c1"></span>  <span class="n">vector</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="c1">//theta;線形カーネルと「ガウスカーネル・isotropic correlationカーネル」の重みを決定するハイパーパラメータ
</span><span class="c1"></span>  <span class="n">vector</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">[</span><span class="n">J</span><span class="p">]</span> <span class="n">C</span><span class="p">;</span> <span class="c1">//isotropic correlationカーネルのハイパーパラメータ
</span><span class="c1"></span>  <span class="n">real</span><span class="o">&lt;</span><span class="n">lower</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">0.9</span><span class="o">&gt;</span> <span class="n">rho</span><span class="p">;</span> <span class="c1">//ガウスカーネルのshapeパラメータ
</span><span class="c1"></span><span class="p">}</span>

<span class="n">transformed</span> <span class="n">parameters</span><span class="p">{</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">N</span><span class="p">]</span> <span class="n">f</span><span class="p">[(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)];</span>
  <span class="n">row_vector</span><span class="p">[</span><span class="n">K</span><span class="p">]</span> <span class="n">p</span><span class="p">[</span><span class="n">N</span><span class="p">];</span> <span class="c1">//ソフトマックス関数に投げる値
</span><span class="c1"></span>

  <span class="c1">//この中でカーネル関数を定義、ガウス過程に従う関数fを作成
</span><span class="c1"></span>  <span class="p">{</span>
    <span class="n">matrix</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">]</span> <span class="n">L_K</span><span class="p">[(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)];</span> <span class="c1">//カーネル行列をコレスキー分解した行列L。（出力がとる値）-1の数だけ準備する
</span><span class="c1"></span>    <span class="n">matrix</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">]</span><span class="n">linear_kernel</span><span class="p">;</span> <span class="c1">//線形カーネル
</span><span class="c1"></span>    <span class="n">matrix</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">]</span><span class="n">distance_L2_01_kernel</span><span class="p">;</span> <span class="c1">//。ガウスカーネル×isotropic correlation カーネル。logスケールでL2距離と0-1距離の成分を含んでいる
</span><span class="c1"></span>    <span class="n">matrix</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">]</span> <span class="n">kernel_matrix</span><span class="p">[(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)];</span> <span class="c1">//最終的に作成するカーネル関数
</span><span class="c1"></span>

    <span class="c1">//linear_kernelを生成
</span><span class="c1"></span>    <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
      <span class="k">for</span><span class="p">(</span><span class="n">m</span> <span class="nl">in1</span><span class="p">:</span><span class="n">N</span><span class="p">){</span>
        <span class="n">linear_kernel</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">=</span> <span class="n">dot_product</span><span class="p">(</span><span class="n">x_i</span><span class="p">[</span><span class="n">n</span><span class="p">],</span><span class="n">x_i</span><span class="p">[</span><span class="n">m</span><span class="p">]);</span>
      <span class="p">}</span>
    <span class="p">}</span>

    <span class="c1">//distanceL2_01_kernelを生成
</span><span class="c1"></span>    <span class="p">{</span>
      <span class="n">matrix</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">]</span> <span class="n">distance_L2</span><span class="p">;</span> <span class="c1">//L2距離
</span><span class="c1"></span>      <span class="n">matrix</span><span class="p">[</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">]</span> <span class="n">distance_01</span> <span class="o">=</span> <span class="n">rep_matrix</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">);</span> <span class="c1">//inv_Iに依存した0-1距離
</span><span class="c1"></span>
      <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
        <span class="k">for</span><span class="p">(</span><span class="n">m</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
          <span class="n">distance_L2</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">=</span> <span class="n">dot_self</span><span class="p">((</span><span class="n">x_i</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">-</span><span class="n">x_i</span><span class="p">[</span><span class="n">m</span><span class="p">])</span> <span class="p">.</span><span class="o">/</span> <span class="n">rho</span><span class="p">);</span>
        <span class="p">}</span>
      <span class="p">}</span>

      <span class="k">for</span><span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">J</span><span class="p">){</span>
        <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
          <span class="k">for</span><span class="p">(</span><span class="n">m</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
            <span class="n">distance_01</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">+=</span> <span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">C</span><span class="p">[</span><span class="n">j</span><span class="p">])</span><span class="o">*</span><span class="n">inv_I</span><span class="p">[</span><span class="n">x_j</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">j</span><span class="p">],</span><span class="n">x_j</span><span class="p">[</span><span class="n">m</span><span class="p">,</span><span class="n">j</span><span class="p">]];</span>
          <span class="p">}</span>
        <span class="p">}</span>
      <span class="p">}</span>

      <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
        <span class="k">for</span><span class="p">(</span><span class="n">m</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
          <span class="n">distance_L2_01_kernel</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">distance_L2</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">]</span> <span class="o">-</span><span class="n">distance_01</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">]);</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span>


    <span class="c1">//kernel_matrixを作成
</span><span class="c1"></span>    <span class="k">for</span><span class="p">(</span><span class="n">k</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)){</span>
      <span class="n">kernel_matrix</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">linear_kernel</span> <span class="o">+</span> <span class="n">theta</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">distance_L2_01_kernel</span><span class="p">;</span>
      <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
        <span class="n">kernel_matrix</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="n">delta</span><span class="p">;</span>
      <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">for</span><span class="p">(</span><span class="n">k</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)){</span>
      <span class="n">L_K</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">cholesky_decompose</span><span class="p">(</span><span class="n">kernel_matrix</span><span class="p">[</span><span class="n">k</span><span class="p">]);</span>
      <span class="n">f</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">L_K</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">eta</span><span class="p">[</span><span class="n">k</span><span class="p">];</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="c1">// pの作成 1列目は0に固定 2列目以降に独立のガウス過程を指定
</span><span class="c1"></span>  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
     <span class="n">p</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
     <span class="k">for</span><span class="p">(</span><span class="n">k</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)){</span>
        <span class="n">p</span><span class="p">[</span><span class="n">n</span><span class="p">,(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">];</span>
     <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="n">model</span><span class="p">{</span>
  <span class="c1">//事前分布
</span><span class="c1"></span>  <span class="n">theta</span> <span class="o">~</span> <span class="n">student_t</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">);</span>
  <span class="n">rho</span> <span class="o">~</span> <span class="n">inv_gamma</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">);</span>
  <span class="n">C</span> <span class="o">~</span> <span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">);</span>

  <span class="c1">//モデル部分
</span><span class="c1"></span>  <span class="k">for</span><span class="p">(</span><span class="n">k</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="p">(</span><span class="n">K</span><span class="o">-</span><span class="mi">1</span><span class="p">)){</span>
    <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
      <span class="n">eta</span><span class="p">[</span><span class="n">k</span><span class="p">,</span><span class="n">n</span><span class="p">]</span> <span class="o">~</span> <span class="n">std_normal</span><span class="p">();</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N1</span><span class="p">){</span>
    <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">~</span> <span class="n">categorical_logit</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="err">&#39;</span><span class="p">);</span>
  <span class="p">}</span>

<span class="p">}</span>

<span class="n">generated</span> <span class="n">quantities</span><span class="p">{</span>
  <span class="n">vector</span><span class="p">[</span><span class="n">K</span><span class="p">]</span> <span class="n">pred</span><span class="p">[</span><span class="n">N2</span><span class="p">];</span>
  <span class="k">for</span><span class="p">(</span><span class="n">n</span> <span class="n">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N2</span><span class="p">){</span>
    <span class="n">pred</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">p</span><span class="p">[(</span><span class="n">N1</span><span class="o">+</span><span class="n">n</span><span class="p">)]</span><span class="err">&#39;</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div><p>モデル１との違いは、<code>transformed parameters{}</code>ブロックにおけるカーネル行列作成の部分と、<code>model{}</code>ブロックにおける事前分布設定の部分になります。</p>
<p><code>transformed parameters{}</code>ブロックでは、<code>linear_kernel</code>として式$(9)$第1項の部分（線形カーネル）の$\theta_1$を除いた部分を、<code>distance_L2_01_kernel</code>として式$(9)$第2項の$\theta_2$を除いた部分を作成しています。また<code>distance_L2_01_kernel</code>は、<code>distance_L2</code>として$\sum_{i=1}^{I}(x_{im}-x_{in})^2$を、<code>distance_01_kernel</code>として$\sum_{j=1}^{J}ln\left(\cfrac{1}{c}\right)I[r\neq{s}]$をそれぞれ作成し、それらを式$(9)$に従って合成することで作成しています。</p>
<p>ハイパーパラメータの事前分布の設定はかなり苦戦しました。最終的に以下の事前分布を採用しています。</p>
<p>$$
\theta_1 \sim Student\verb|_|t(4,1,2) ~~~\theta_1 \geq 1
$$
$$
\theta_2 \sim Student\verb|_|t(4,1,2) ~~~\theta_2 \geq 1
$$
$$
\rho \sim invGamma(0.1,0.1)~~~0 \leq \rho \leq 0.9
$$
$$
c \sim Normal(0,0.1)
$$</p>
<p>$\theta_1$、$\theta_2$については弱情報事前分布として、自由度4、期待値1、スケールパラメータ1の半t分布を採用しています。
<!-- raw HTML omitted -->  <br>
$\rho$については、Stanマニュアルを参照して、0付近の値を避けることができつつも小さな値にとがった山を持ち、かつ十分大きな値にも対応可能な逆ガンマ分布を採用しています。
<!-- raw HTML omitted -->  <br>
$c$については、0付近の値をとることが想定されるため、期待値0、標準偏差0.1の切断正規分布を採用しています。</p>
<p>様々な事前分布を試していたのですが、ガウスカーネルにおいて、shapeパラメータ$\rho$とrateパラメータ$\theta$の比が重要なようで、shapeパラメータに比べてrateパラメータが十分大きいと、出力値の変化の傾きが小さくなり、前回記事の式$(1)$の誤差項を捉えてくれなくなってしまいます。この点についてはStanマニュアルにも以下の記載があります。</p>
<blockquote>
<p>Perhaps most importantly, the parameter $\rho$ and $\alpha$ are weakly identified Zhang(2004). The ratio of the rwo parameters is well-identified&hellip;</p>
</blockquote>
<p>今回の場合、$\rho$に値の上限を設定しないとどうしても$\rho$が大きくなってしまい、予測結果もモデル式１と変わらなくなってしまいました。しかしそれはこのモデルの意図した結果ではありません。</p>
<p>以前の[ガウス過程のシミュレーション結果](<a href="https://rmorita-stat.github.io/2020/06/gaussianprocess/#">https://rmorita-stat.github.io/2020/06/gaussianprocess/#</a> ガウス過程のシミュレーション)を見ると、標準化されたデータの場合、shapeパラメータ、rateパラメータともに1前後でちょうどよいガウス過程からの出力が得られそうであることが確認できます。よって、今回はrateパラメータに0.9の上限を設け、shapeパラメータも下限値1を設定することで、少し変化の傾きが急な出力を得られるように強要することにします。</p>
<p>上記のStanファイルを実行するコードは以下になります。</p>
<div class="highlight"><pre class="chroma"><code class="language-r" data-lang="r"><span class="n">data</span> <span class="o">&lt;-</span> <span class="nf">list</span><span class="p">(</span><span class="n">x1_i</span><span class="o">=</span><span class="n">x1_i</span><span class="p">,</span><span class="n">x1_j</span><span class="o">=</span><span class="n">x1_j</span><span class="p">,</span><span class="n">x2_i</span> <span class="o">=</span> <span class="n">x2_i</span><span class="p">,</span><span class="n">x2_j</span><span class="o">=</span><span class="n">x2_j</span><span class="p">,</span><span class="n">N1</span><span class="o">=</span><span class="n">N1</span><span class="p">,</span><span class="n">N2</span><span class="o">=</span><span class="n">N2</span><span class="p">,</span><span class="n">K</span><span class="o">=</span><span class="n">K</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">J</span><span class="o">=</span><span class="n">J</span><span class="p">,</span><span class="n">I</span><span class="o">=</span><span class="n">I</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
<span class="nf">rstan_options</span><span class="p">(</span><span class="n">auto_write</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
<span class="nf">options</span><span class="p">(</span><span class="n">mc.cores</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">::</span><span class="nf">detectCores</span><span class="p">())</span>
<span class="n">fit_cate2</span> <span class="o">&lt;-</span> <span class="nf">stan</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="s">&#34;model3.stan&#34;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">pars</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;pred&#34;</span><span class="p">,</span><span class="s">&#34;rho&#34;</span><span class="p">,</span><span class="s">&#34;theta&#34;</span><span class="p">,</span><span class="s">&#34;C&#34;</span><span class="p">),</span> <span class="n">warmup</span> <span class="o">=</span> <span class="m">400</span><span class="p">,</span> <span class="n">iter</span> <span class="o">=</span> <span class="m">1500</span><span class="p">,</span> <span class="n">chains</span><span class="o">=</span><span class="m">4</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="m">1234</span><span class="p">)</span>
</code></pre></div><p>計算にかかったた時間は確かおよそ9800秒でした。2時間以上かかっていますね。PCもうなり声をあげていたので冷却対策など必要かもしれません。</p>
<p>ハイパーパラメータの事後分布は以下のようになります。</p>
<div class="highlight"><pre class="chroma"><code class="language-r" data-lang="r"><span class="n">posterior_fit0_2</span> <span class="o">&lt;-</span> <span class="n">rstan</span><span class="o">::</span><span class="nf">extract</span><span class="p">(</span><span class="n">fit_cate2</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">bayesplot</span><span class="p">)</span>
<span class="n">plot_title</span> <span class="o">&lt;-</span> <span class="nf">ggtitle</span><span class="p">(</span><span class="s">&#34;Posterior distribution of hyper parameters&#34;</span><span class="p">,</span> <span class="s">&#34;with medians and 95% intervals&#34;</span><span class="p">)</span>
<span class="n">p1</span> <span class="o">&lt;-</span> <span class="nf">mcmc_areas</span><span class="p">(</span><span class="nf">as.matrix</span><span class="p">(</span><span class="n">fit_cate2</span><span class="p">),</span>
                <span class="n">regex_pars</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;theta&#34;</span><span class="p">),</span><span class="n">prob</span><span class="o">=</span><span class="m">0.95</span><span class="p">,</span> <span class="n">area_method</span> <span class="o">=</span> <span class="s">&#34;equal height&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_y_discrete</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s">&#34;theta1&#34;</span><span class="p">,</span><span class="s">&#34;theta2&#34;</span><span class="p">))</span> <span class="o">+</span> <span class="nf">theme_bw</span><span class="p">(</span><span class="n">base_size</span><span class="o">=</span><span class="m">12</span><span class="p">)</span>
<span class="n">p2</span> <span class="o">&lt;-</span> <span class="nf">mcmc_areas</span><span class="p">(</span><span class="nf">as.matrix</span><span class="p">(</span><span class="n">fit_cate2</span><span class="p">),</span>
                <span class="n">regex_pars</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;C&#34;</span><span class="p">,</span><span class="s">&#34;rho&#34;</span><span class="p">),</span><span class="n">prob</span><span class="o">=</span><span class="m">0.95</span><span class="p">,</span> <span class="n">area_method</span> <span class="o">=</span> <span class="s">&#34;equal height&#34;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">scale_y_discrete</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s">&#34;c&#34;</span><span class="p">,</span><span class="s">&#34;rho&#34;</span><span class="p">))</span> <span class="o">+</span>
   <span class="nf">theme_bw</span><span class="p">(</span><span class="n">base_size</span><span class="o">=</span><span class="m">12</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">gridExtra</span><span class="p">)</span>

<span class="n">g1</span> <span class="o">&lt;-</span> <span class="nf">ggplot_gtable</span><span class="p">(</span><span class="nf">ggplot_build</span><span class="p">(</span><span class="n">p1</span><span class="p">))</span>
<span class="n">g2</span> <span class="o">&lt;-</span> <span class="nf">ggplot_gtable</span><span class="p">(</span><span class="nf">ggplot_build</span><span class="p">(</span><span class="n">p2</span><span class="p">))</span>
<span class="n">Width</span> <span class="o">&lt;-</span> <span class="nf">unit.pmax</span><span class="p">(</span><span class="n">g1</span><span class="o">$</span><span class="n">widths</span><span class="p">,</span> <span class="n">g2</span><span class="o">$</span><span class="n">widths</span><span class="p">)</span>
<span class="n">Height</span> <span class="o">&lt;-</span> <span class="nf">unit.pmin</span><span class="p">(</span><span class="n">g1</span><span class="o">$</span><span class="n">heights</span><span class="p">,</span> <span class="n">g2</span><span class="o">$</span><span class="n">heights</span><span class="p">)</span>
<span class="n">g1</span><span class="o">$</span><span class="n">widths</span> <span class="o">&lt;-</span> <span class="n">Width</span>
<span class="n">g2</span><span class="o">$</span><span class="n">widths</span> <span class="o">&lt;-</span> <span class="n">Width</span>
<span class="n">g1</span><span class="o">$</span><span class="n">heights</span> <span class="o">&lt;-</span> <span class="n">Height</span>
<span class="n">g2</span><span class="o">$</span><span class="n">heights</span> <span class="o">&lt;-</span> <span class="n">Height</span>
<span class="n">p</span> <span class="o">&lt;-</span> <span class="n">gridExtra</span><span class="o">::</span><span class="nf">grid.arrange</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span><span class="n">g2</span><span class="p">,</span><span class="n">ncol</span><span class="o">=</span><span class="m">1</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="s">&#34;Posterior distribution of hyper parameters (with medians and 95% intervals)&#34;</span><span class="p">)</span>

</code></pre></div><p><img src="/post/multinom-gp/fit_cate2_density.png" alt=""></p>
<p>$\rho$が頑張って大きな値をとろうとしている様子が見えますが、そこは抑えてもらっています。何だかかわいそう&hellip;</p>
<p>最後に、予測結果を描画します。</p>
<p><img src="/post/multinom-gp/fit_cate2_res.png" alt=""></p>
<p>線形モデルでは読み取ることが出来なかった傾向がうまく捉えられています。例えば、読み書きの能力が50前後のses=lowの生徒はgeneralの授業をとる傾向にあること、読み書きの能力が45前後のses=highの生徒はacademicの授業をとる確率とvocationの授業をとる確率が同程度である様子などが確認できます。</p>
<p><strong>It&rsquo;s so brilliant</strong>&gt;🐢</p>
<p>このように、線形モデルでは誤差として結果に反映されなかった事象もうまくとらえることが出来るのがガウス過程の魅力です。パラメータの事後分布や推測値よりデータの生成過程を考察する、という目的には不向きかもしれませんが、予測の観点から見れば非常に便利ではないでしょうか？。</p>
<h1 id="まとめ">まとめ</h1>
<p>今回はガウス過程を多項ロジスティック回帰に取り込んだモデルの実装を行いました。その過程で、ガウス過程潜在変数モデルやカテゴリカルデータを取り入れたガウス過程等、前回の記事で説明したガウス過程の応用手法を用い、それらが正常に機能することを確かめました。</p>
<p>また、ガウス過程のように特定の分布を想定しないで、データに応じてモデルの複雑さを決定するパラメータを調整するベイズモデルは<strong>ノンパラメトリックベイズモデル</strong>と呼ばれています。</p>
<p>この記事で、以前に述べたガウス過程の活用方法の１つ目(下記)を紹介した形です。</p>
<ul>
<li>一般化線形モデルの線形予測子をガウス過程に置き換え、柔軟なモデルに豹変させる</li>
</ul>
<p>多項ロジスティック回帰の記事も3つ目になりましたが、これで最後になります。最近はアウトプットに力を注いでいて投稿頻度も多かったですが、今後暫くはインプットに集中したいと考えており、投稿しない月が続くかもしれません。</p>
<p>Enjoy Stan!</p>

        </article>
    </div>
    <div class="main-content__tags u-font">
        
        
        <span><a href="https://rmorita-stat.github.io/tags/%E5%9B%9E%E5%B8%B0">回帰</a></span>
        
        <span><a href="https://rmorita-stat.github.io/tags/%E3%82%AC%E3%82%A6%E3%82%B9%E9%81%8E%E7%A8%8B">ガウス過程</a></span>
        
        <span><a href="https://rmorita-stat.github.io/tags/rstan">rstan</a></span>
        
        <span><a href="https://rmorita-stat.github.io/tags/%E3%83%8E%E3%83%B3%E3%83%91%E3%83%A9%E3%83%A1%E3%83%88%E3%83%AA%E3%83%83%E3%82%AF%E3%83%99%E3%82%A4%E3%82%BA%E3%83%A2%E3%83%87%E3%83%AB">ノンパラメトリックベイズモデル</a></span>
        
        
    </div>
</div>
<div class="main-profile">
    <div class="main-profile__avatar">
        
    </div>
    <div class="main-profile__body">
        <div class="main-profile__author">
            
            <span> R.morita </span>
            
        </div>
        <div class="main-profile__description">
            
            <p> 洛中で6年間大学生活を過ごし、今は難波の地で働いています。統計、ロードバイク、古墳が好きです。 </p>
            
        </div>
    </div>
</div>
<div class="main-line"></div>
<div class="main-pn">
    
    <a class="previous" href="https://rmorita-stat.github.io/2020/07/gaussianprocess2/">
        <div class="pn-dec"></div>
        <div class="pn-els">
            <div class="pn-el__1"> 2020.07.11 00:00 </div>
            <div class="pn-el__2"> ガウス過程の応用 </div>
        </div>
    </a>
    
    
    <a class="next" href="https://rmorita-stat.github.io/2020/10/modeling/">
        <div class="pn-dec"></div>
        <div class="pn-els">
            <div class="pn-el__1"> 2020.10.03 00:00 </div>
            <div class="pn-el__2"> モデリングと情報量基準その１～モデリングとは？～ </div>
        </div>
    </a>
    
</div>

<footer>
  <script type="text/javascript">
 MathJax = {
   tex: {
     inlineMath: [['$','$'], ['\\(','\\)']],
     processEscapes: true,
     tags: "ams",
     autoload: {
       color: [],
       colorV2: ['color']
     },
     packages: {'[+]': ['noerrors']}
   },
   chtml: {
     matchFontHeight: true,
     displayAlign: "left",
     displayIndent: "2em"
   },
   options: {
     skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
     renderActions: {
        
       find_script_mathtex: [10, function (doc) {
         for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
           const display = !!node.type.match(/; *mode=display/);
           const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
           const text = document.createTextNode('');
           node.parentNode.replaceChild(text, node);
           math.start = {node: text, delim: '', n: 0};
           math.end = {node: text, delim: '', n: 0};
           doc.math.push(math);
         }
       }, '']
     }
   },
   loader: {
     load: ['[tex]/noerrors']
   }
 };
</script>
<script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script"></script>
</footer>

</div>
<div class="footer">
    <div class="copyright-wrap">
        <p class="copyright u-font">
            
            &#169;
            2020
            
            <a href="https://github.com/Rmorita-stat/doc" target="_blank">R.morita&#46;</a>
            Theme <a href="https://github.com/iCyris/hugo-theme-yuki" target="_blank">yuki</a>&#46;
            Powered by Hugo&#46;
            
            
        </p>
    </div>
</div>
</body>
<script src="https://rmorita-stat.github.io/js/page.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

